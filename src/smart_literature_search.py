#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ–‡çŒ®æ£€ç´¢å’Œç­›é€‰ç³»ç»Ÿ
æ•´åˆç”¨æˆ·æ„å›¾åˆ†æã€PubMedæ£€ç´¢ã€æœŸåˆŠæ•°æ®åŒ¹é…å’Œç»“æœå¯¼å‡ºåŠŸèƒ½
"""

import sys
import os
import argparse
from datetime import datetime
from typing import List, Dict, Optional

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from data_processor import JournalDataProcessor
from intent_analyzer import IntentAnalyzer, SearchCriteria
from pubmed_search import PubMedSearcher
from literature_filter import LiteratureFilter
from review_outline_generator import ReviewOutlineGenerator


class SmartLiteratureSearchSystem:
    """æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ç³»ç»Ÿ"""
    
    def __init__(self, ai_config_name: str = None, interactive_ai: bool = True):
        """
        åˆå§‹åŒ–ç³»ç»Ÿ
        
        Args:
            ai_config_name: AIé…ç½®åç§°
            interactive_ai: æ˜¯å¦äº¤äº’å¼é…ç½®AIæ¨¡å‹
        """
        self.ai_config_name = ai_config_name
        self.interactive_ai = interactive_ai
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.data_processor = None
        self.intent_analyzer = None
        self.pubmed_searcher = None
        self.literature_filter = None
        self.outline_generator = None  # æ–°å¢å¤§çº²ç”Ÿæˆå™¨
        
        # ç³»ç»ŸçŠ¶æ€
        self.data_ready = False
        
    def initialize_system(self):
        """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
        print("æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ç³»ç»Ÿ...")
        
        # 1. æ£€æŸ¥å’Œå¤„ç†æœŸåˆŠæ•°æ®
        self._ensure_journal_data()
        
        # 2. åˆå§‹åŒ–æ„å›¾åˆ†æå™¨
        try:
            self.intent_analyzer = IntentAnalyzer(
                self.ai_config_name, 
                interactive=self.interactive_ai
            )
            print("âœ“ AIæ„å›¾åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âœ— AIæ„å›¾åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            print("æç¤º: è¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®AIæ¥å£ (è¿è¡Œ python ai_client.py è¿›è¡Œé…ç½®)")
            return False
        
        # 3. åˆå§‹åŒ–PubMedæœç´¢å™¨
        self.pubmed_searcher = PubMedSearcher()
        print("âœ“ PubMedæœç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # 4. åˆå§‹åŒ–æ–‡çŒ®ç­›é€‰å™¨
        try:
            self.literature_filter = LiteratureFilter()
            print("âœ“ æ–‡çŒ®ç­›é€‰å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âœ— æ–‡çŒ®ç­›é€‰å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
        
        # 5. åˆå§‹åŒ–ç»¼è¿°å¤§çº²ç”Ÿæˆå™¨
        try:
            self.outline_generator = ReviewOutlineGenerator(self.ai_config_name)
            print("âœ“ ç»¼è¿°å¤§çº²ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âœ— ç»¼è¿°å¤§çº²ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            print("æç¤º: å¤§çº²ç”ŸæˆåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†æ–‡çŒ®æ£€ç´¢åŠŸèƒ½æ­£å¸¸")
        
        self.data_ready = True
        print("ğŸ‰ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!\n")
        return True
    
    def _ensure_journal_data(self):
        """ç¡®ä¿æœŸåˆŠæ•°æ®å·²å¤„ç†"""
        zky_file = "data/processed_zky_data.csv"
        jcr_file = "data/processed_jcr_data.csv"
        
        if not (os.path.exists(zky_file) and os.path.exists(jcr_file)):
            print("æ£€æµ‹åˆ°æœŸåˆŠæ•°æ®æœªå¤„ç†ï¼Œæ­£åœ¨å¤„ç†...")
            try:
                self.data_processor = JournalDataProcessor()
                self.data_processor.process_separate()
                print("âœ“ æœŸåˆŠæ•°æ®å¤„ç†å®Œæˆ")
            except Exception as e:
                print(f"âœ— æœŸåˆŠæ•°æ®å¤„ç†å¤±è´¥: {e}")
                return False
        else:
            print("âœ“ æœŸåˆŠæ•°æ®å·²å°±ç»ª")
        
        return True
    
    def search_literature(self, user_input: str, max_results: int = 100) -> Optional[tuple]:
        """
        æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ - è‡ªåŠ¨è¾“å‡ºCSVå’ŒJSONä¸¤ç§æ ¼å¼
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„æ£€ç´¢éœ€æ±‚
            max_results: æœ€å¤§æ£€ç´¢ç»“æœæ•°
            
        Returns:
            (csv_path, json_path) å…ƒç»„ï¼ŒåŒ…å«ä¸¤ç§æ ¼å¼çš„æ–‡ä»¶è·¯å¾„
        """
        if not self.data_ready:
            print("ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œ initialize_system()")
            return None
        
        print(f"[FIND] å¼€å§‹æ™ºèƒ½æ–‡çŒ®æ£€ç´¢")
        print(f"ç”¨æˆ·éœ€æ±‚: {user_input}")
        print("=" * 60)
        
        # æ­¥éª¤1: æ„å›¾åˆ†æ
        print("\n[LIST] æ­¥éª¤1: åˆ†æç”¨æˆ·æ„å›¾...")
        try:
            criteria = self.intent_analyzer.analyze_intent(user_input)
            self.intent_analyzer.print_analysis_result(criteria)
        except Exception as e:
            print(f"æ„å›¾åˆ†æå¤±è´¥: {e}")
            # ä½¿ç”¨åŸºç¡€æœç´¢æ¡ä»¶
            criteria = SearchCriteria(query=user_input)
        
        # æ­¥éª¤2: æ„å»ºæ£€ç´¢è¯å¹¶æœç´¢
        print("\n[SEARCH] æ­¥éª¤2: æ‰§è¡ŒPubMedæ£€ç´¢...")
        query = self.intent_analyzer.build_pubmed_query(criteria)
        print(f"æœ€ç»ˆæ£€ç´¢è¯: {query}")
        
        try:
            # ç¬¬ä¸€æ¬¡æ£€ç´¢ï¼šä¸è·å–æ‘˜è¦ï¼Œåªè·å–åŸºæœ¬ä¿¡æ¯
            pmids = self.pubmed_searcher.search_articles(
                query=query,
                max_results=max_results,
                sort_by='relevance'
            )
            
            if not pmids:
                print("æœªæ‰¾åˆ°ä»»ä½•æ–‡çŒ®")
                return None
            
            print(f"æ‰¾åˆ° {len(pmids)} ç¯‡æ–‡çŒ®")
            
            # è·å–åŸºæœ¬ä¿¡æ¯ï¼ˆä¸åŒ…å«æ‘˜è¦ï¼‰
            print("è·å–æ–‡çŒ®åŸºæœ¬ä¿¡æ¯...")
            basic_articles = self._fetch_basic_info(pmids)
            
        except Exception as e:
            print(f"PubMedæ£€ç´¢å¤±è´¥: {e}")
            return None
        
        # æ­¥éª¤3: æ–‡çŒ®ç­›é€‰ï¼ˆåªç­›é€‰æœŸåˆŠç›¸å…³æ¡ä»¶ï¼‰
        print(f"\n[STAT] æ­¥éª¤3: ç­›é€‰æœŸåˆŠæ¡ä»¶...")
        try:
            filtered_articles = self.literature_filter.filter_articles(basic_articles, criteria)
            
            if not filtered_articles:
                print("æ²¡æœ‰æ–‡çŒ®é€šè¿‡æœŸåˆŠç­›é€‰æ¡ä»¶")
                return None
            
            self.literature_filter.print_filter_statistics(
                len(basic_articles), len(filtered_articles), criteria
            )
            
        except Exception as e:
            print(f"æ–‡çŒ®ç­›é€‰å¤±è´¥: {e}")
            return None
        
        # æ­¥éª¤4: è·å–ç­›é€‰åæ–‡çŒ®çš„æ‘˜è¦
        print(f"\n[FILE] æ­¥éª¤4: è·å–ç­›é€‰åæ–‡çŒ®çš„è¯¦ç»†ä¿¡æ¯...")
        try:
            filtered_pmids = [article['pmid'] for article in filtered_articles]
            detailed_articles = self.pubmed_searcher.fetch_article_details(filtered_pmids)
            
            # åˆå¹¶ç­›é€‰ä¿¡æ¯å’Œè¯¦ç»†ä¿¡æ¯
            enhanced_articles = self._merge_article_info(filtered_articles, detailed_articles)
            
        except Exception as e:
            print(f"è·å–è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
            enhanced_articles = filtered_articles
        
        # æ­¥éª¤5: åˆ†æå’Œå¯¼å‡ºç»“æœ
        print(f"\n[TREND] æ­¥éª¤5: åˆ†æå’Œå¯¼å‡ºç»“æœ...")
        self.literature_filter.analyze_filtered_results(enhanced_articles)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼ˆåŒ…å«ç”¨æˆ·è¾“å…¥å…³é”®è¯ï¼‰
        output_file = self._generate_filename(user_input)
        
        # ç”Ÿæˆå¸¦æ–‡ä»¶å¤¹è·¯å¾„çš„è¾“å‡ºæ–‡ä»¶å
        literature_output_path = os.path.join("æ–‡çŒ®æ£€ç´¢ç»“æœ", output_file)
        
        # åŒæ—¶å¯¼å‡ºJSONå’ŒCSVä¸¤ç§æ ¼å¼
        json_path = self.literature_filter.export_filtered_results(
            enhanced_articles, 'json', literature_output_path
        )
        csv_path = self.literature_filter.export_filtered_results(
            enhanced_articles, 'csv', literature_output_path
        )
        
        print(f"\nğŸ‰ æ£€ç´¢å®Œæˆ! å…±æ‰¾åˆ° {len(enhanced_articles)} ç¯‡ç¬¦åˆæ¡ä»¶çš„æ–‡çŒ®")
        print(f"[FILE] JSONæ ¼å¼: {json_path}")
        print(f"[STAT] CSVæ ¼å¼: {csv_path}")
        
        # è¿”å›ä¸¤ç§æ ¼å¼çš„æ–‡ä»¶è·¯å¾„
        return csv_path, json_path
    
    def generate_review_outline(self, json_file_path: str, research_topic: str) -> Optional[str]:
        """
        åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç»¼è¿°å¤§çº²
        
        Args:
            json_file_path: æ–‡çŒ®æ£€ç´¢ç»“æœJSONæ–‡ä»¶è·¯å¾„
            research_topic: ç ”ç©¶ä¸»é¢˜
            total_word_count: ç›®æ ‡æ€»å­—æ•°
            
        Returns:
            ç”Ÿæˆçš„å¤§çº²æ–‡ä»¶è·¯å¾„
        """
        if not self.outline_generator:
            print("[FAIL] ç»¼è¿°å¤§çº²ç”Ÿæˆå™¨æœªåˆå§‹åŒ–")
            return None
        
        try:
            print(f"[FIND] æ­£åœ¨åŸºäºæ–‡çŒ®æ•°æ®ç”Ÿæˆç»¼è¿°å¤§çº²...")
            print(f"ä¸»é¢˜: {research_topic}")
            print("=" * 60)
            
            # ç”Ÿæˆå¤§çº²
            outline = self.outline_generator.generate_outline_from_json(
                json_file_path, research_topic
            )
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åå’Œè·¯å¾„
            import re
            safe_topic = re.sub(r'[^\w\s-]', '', research_topic).replace(' ', '_')[:20]
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            outline_filename = f"ç»¼è¿°å¤§çº²â€”{safe_topic}-{timestamp}.md"
            outline_file = os.path.join("ç»¼è¿°å¤§çº²", outline_filename)
            
            # ä¿å­˜å¤§çº²
            self.outline_generator.save_outline(outline, outline_file)
            
            print(f"\n[NOTE] å¤§çº²ç”Ÿæˆå®Œæˆ!")
            print(f"å¤§çº²å·²ä¿å­˜åˆ°: {outline_file}")
            
            return outline_file
            
        except Exception as e:
            print(f"[FAIL] å¤§çº²ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def search_and_generate_outline(self, user_input: str, max_results: int = 100) -> Optional[str]:
        """
        ä¸€é”®å®Œæˆæ–‡çŒ®æ£€ç´¢å’Œç»¼è¿°å¤§çº²ç”Ÿæˆ
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„æ£€ç´¢éœ€æ±‚
            max_results: æœ€å¤§æ£€ç´¢ç»“æœæ•°
            
        Returns:
            å¤§çº²æ–‡ä»¶è·¯å¾„
        """
        # æ­¥éª¤1: è¿›è¡Œæ–‡çŒ®æ£€ç´¢ï¼ˆåŒæ—¶ç”ŸæˆJSONå’ŒCSVï¼‰
        search_result = self.search_literature(user_input, max_results)
        
        if not search_result:
            print("[FAIL] æ–‡çŒ®æ£€ç´¢å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå¤§çº²")
            return None
        
        # å¤„ç†è¿”å›ç»“æœï¼ˆç°åœ¨æ€»æ˜¯è¿”å›ä¸¤ä¸ªè·¯å¾„ï¼‰
        if isinstance(search_result, tuple):
            csv_file, json_file = search_result
        else:
            # å‘åå…¼å®¹ï¼Œå¦‚æœåªè¿”å›å•ä¸ªæ–‡ä»¶
            csv_file = json_file = search_result
        
        # æ­¥éª¤2: ä½¿ç”¨JSONæ–‡ä»¶ç”Ÿæˆç»¼è¿°å¤§çº²
        if self.outline_generator and json_file:
            print(f"\n[NOTE] å¼€å§‹ç”Ÿæˆç»¼è¿°å¤§çº²...")
            print(f"[FILE] ä½¿ç”¨æ•°æ®æ–‡ä»¶: {json_file}")
            outline_file = self.generate_review_outline(json_file, user_input)
            
            if outline_file:
                print(f"\nğŸ‰ å®Œæ•´æµç¨‹å®Œæˆ!")
                print(f"[STAT] CSVæ•°æ®æ–‡ä»¶: {csv_file}")
                print(f"[FILE] JSONæ•°æ®æ–‡ä»¶: {json_file}")
                print(f"[NOTE] ç»¼è¿°å¤§çº²æ–‡ä»¶: {outline_file}")
                return outline_file
            else:
                print("[FAIL] å¤§çº²ç”Ÿæˆå¤±è´¥")
                return None
        else:
            print("[WARN]  å¤§çº²ç”Ÿæˆå™¨ä¸å¯ç”¨")
            return None
    
    def _generate_filename(self, user_input: str) -> str:
        """
        æ ¹æ®ç”¨æˆ·è¾“å…¥ç”Ÿæˆæ™ºèƒ½æ–‡ä»¶å
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„æ£€ç´¢éœ€æ±‚
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        """
        import re
        from datetime import datetime
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # æå–å…³é”®åŒ»å­¦æœ¯è¯­å’Œé‡è¦è¯æ±‡
        medical_keywords = {
            # å¸¸è§ç–¾ç—…
            'ç³–å°¿ç—…': 'diabetes', 'é«˜è¡€å‹': 'hypertension', 'ç™Œç—‡': 'cancer',
            'è‚¿ç˜¤': 'tumor', 'å¿ƒè„ç—…': 'cardiac', 'é˜¿å°”èŒ¨æµ·é»˜': 'alzheimer',
            'ç»“æ ¸ç—…': 'tuberculosis', 'ç»“æ ¸': 'tuberculosis', 'è‚ºç‚': 'pneumonia',
            'å“®å–˜': 'asthma', 'æŠ‘éƒç—‡': 'depression', 'ç„¦è™‘': 'anxiety',
            'è„‘æ¢—': 'stroke', 'ä¸­é£': 'stroke', 'å† å¿ƒç—…': 'coronary',
            # æ²»ç–—æ–¹æ³•
            'æ²»ç–—': 'treatment', 'è¯ç‰©': 'drug', 'ç–«è‹—': 'vaccine',
            'æ‰‹æœ¯': 'surgery', 'æ”¾ç–—': 'radiotherapy', 'åŒ–ç–—': 'chemotherapy',
            # ç”Ÿç‰©åŒ»å­¦
            'å…ç–«': 'immune', 'åŸºå› ': 'gene', 'è›‹ç™½è´¨': 'protein',
            'ç»†èƒ': 'cell', 'åˆ†å­': 'molecular', 'ç—…æ¯’': 'virus',
            # æ„ŸæŸ“ç›¸å…³
            'æ„ŸæŸ“': 'infection', 'æ½œä¼': 'latent', 'ç—…åŸ': 'pathogen'
        }
        
        # ç‰¹æ®Šæœ¯è¯­å¤„ç†ï¼ˆå½±å“å› å­ã€åˆ†åŒºç­‰ï¼‰
        special_terms = {
            'IF': 'if', 'JCR': 'jcr', 'Q1': 'q1', 'Q2': 'q2', 'Q3': 'q3', 'Q4': 'q4',
            'å½±å“å› å­': 'if', 'ä¸­ç§‘é™¢': 'cas', 'åˆ†åŒº': 'zone', 'æœŸåˆŠ': 'journal',
            'é«˜å½±å“å› å­': 'high_if', 'é¡¶çº§æœŸåˆŠ': 'top_journal', 'é«˜åˆ†': 'high_score'
        }
        
        # åˆ†åˆ«æ”¶é›†ä¸åŒç±»å‹çš„å…³é”®è¯
        medical_terms = []  # åŒ»å­¦æœ¯è¯­
        condition_terms = []  # æ¡ä»¶æœ¯è¯­ï¼ˆæ—¶é—´ã€åˆ†åŒºã€å½±å“å› å­ç­‰ï¼‰
        
        input_upper = user_input.upper()
        input_lower = user_input.lower()
        
        # 1. ä¼˜å…ˆæå–åŒ»å­¦æœ¯è¯­
        for chinese_term, english_term in medical_keywords.items():
            if chinese_term in user_input or english_term in input_lower:
                if english_term not in medical_terms:  # é¿å…é‡å¤
                    medical_terms.append(english_term)
                if len(medical_terms) >= 2:  # æœ€å¤šä¿ç•™2ä¸ªåŒ»å­¦æœ¯è¯­
                    break
        
        # 2. æå–ç‰¹æ®Šæœ¯è¯­ï¼ˆå½±å“å› å­ã€åˆ†åŒºç­‰ï¼‰
        for special_term, english_term in special_terms.items():
            if special_term in user_input or special_term.upper() in input_upper:
                if english_term not in condition_terms:  # é¿å…é‡å¤
                    condition_terms.append(english_term)
        
        # 3. æå–æ•°å­—æ¡ä»¶ï¼ˆå¦‚ IF>5, è¿‘5å¹´ç­‰ï¼‰
        number_patterns = [
            (r'IF\s*[>â‰¥]\s*(\d+(?:\.\d+)?)', lambda m: f'if_gt_{m.group(1).replace(".", "_")}'),
            (r'IF\s*[<â‰¤]\s*(\d+(?:\.\d+)?)', lambda m: f'if_lt_{m.group(1).replace(".", "_")}'),
            (r'å½±å“å› å­\s*[>â‰¥å¤§äº]\s*(\d+(?:\.\d+)?)', lambda m: f'if_gt_{m.group(1).replace(".", "_")}'),
            (r'è¿‘(\d+)å¹´', lambda m: f'recent_{m.group(1)}y'),
            (r'æœ€è¿‘(\d+)å¹´', lambda m: f'last_{m.group(1)}y'),
            (r'(\d+)åŒº', lambda m: f'zone_{m.group(1)}'),
            (r'Q(\d)', lambda m: f'q{m.group(1)}')
        ]
        
        for pattern, formatter in number_patterns:
            matches = re.finditer(pattern, user_input, re.IGNORECASE)
            for match in matches:
                formatted_term = formatter(match)
                if formatted_term not in condition_terms:  # é¿å…é‡å¤
                    condition_terms.append(formatted_term)
        
        # 4. æ™ºèƒ½å»é‡å’Œç»„åˆå…³é”®è¯
        # ç§»é™¤é‡å¤çš„åŸºç¡€è¯ï¼ˆå¦‚å½“æœ‰if_gt_5æ—¶ç§»é™¤ifï¼‰
        filtered_condition_terms = []
        for term in condition_terms:
            has_more_specific = False
            for other_term in condition_terms:
                if other_term != term and other_term.startswith(term + '_'):
                    has_more_specific = True
                    break
            if not has_more_specific:
                filtered_condition_terms.append(term)
        
        # ç»„åˆï¼šåŒ»å­¦æœ¯è¯­ï¼ˆæœ€å¤š2ä¸ªï¼‰+ æ¡ä»¶æœ¯è¯­ï¼ˆæœ€å¤š2ä¸ªï¼‰
        keywords = medical_terms[:2] + filtered_condition_terms[:2]
        
        # 5. å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä¸“ä¸šæœ¯è¯­ï¼Œæå–æ™®é€šå…³é”®è¯
        if not keywords:
            # ç§»é™¤å¸¸è§çš„è¿æ¥è¯å’Œæ ‡ç‚¹
            stop_words = {'çš„', 'åœ¨', 'ä¸­', 'å’Œ', 'ä¸', 'æˆ–', 'åŠ', 'æ˜¯', 'äº†', 'æœ‰', 'å¯¹', 'ä¸º', 
                         'the', 'in', 'of', 'and', 'or', 'for', 'with', 'by', 'a', 'an', 'to',
                         'è¦æ±‚', 'æœŸåˆŠ', 'æ–‡çŒ®', 'ç ”ç©¶', 'æœ€æ–°', 'ç›¸å…³'}
            
            # æ¸…ç†æ–‡æœ¬ï¼Œä¿ç•™ä¸­è‹±æ–‡å’Œæ•°å­—ï¼Œä½†ç§»é™¤ç‰¹æ®Šç¬¦å·
            cleaned_input = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', user_input)
            words = [w.strip() for w in cleaned_input.split() if w.strip()]
            
            for word in words:
                if len(word) > 1 and word.lower() not in stop_words:
                    if any('\u4e00' <= c <= '\u9fff' for c in word):
                        # ä¸­æ–‡è¯æ±‡ï¼Œå–å‰4ä¸ªå­—ç¬¦
                        keywords.append(word[:4])
                    else:
                        # è‹±æ–‡è¯æ±‡ï¼Œå–å‰8ä¸ªå­—ç¬¦
                        keywords.append(word[:8].lower())
                    
                    if len(keywords) >= 3:
                        break
        
        # ç»„åˆæ–‡ä»¶å - ç›´æ¥ä½¿ç”¨ä¸»é¢˜è¯+æ—¶é—´æˆ³
        # ç®€åŒ–ç”¨æˆ·è¾“å…¥ä¸ºåˆæ³•çš„æ–‡ä»¶å
        safe_topic = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', user_input).strip()
        safe_topic = re.sub(r'\s+', '_', safe_topic)  # æ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿
        
        # é™åˆ¶é•¿åº¦é¿å…æ–‡ä»¶åè¿‡é•¿
        if len(safe_topic) > 30:
            safe_topic = safe_topic[:30]
        
        # å¦‚æœå¤„ç†åä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
        if not safe_topic:
            safe_topic = "literature_search"
        
        filename = f"{safe_topic}_{timestamp}"
        
        return filename
    
    def _fetch_basic_info(self, pmids: List[str]) -> List[Dict]:
        """è·å–åŸºæœ¬ä¿¡æ¯ï¼ˆä¸å«æ‘˜è¦ï¼‰"""
        articles = []
        
        # ç®€åŒ–ç‰ˆè·å–ä¿¡æ¯ï¼Œä¸»è¦è·å–PMID, æ ‡é¢˜, æœŸåˆŠ, ISSNç­‰
        for pmid in pmids:
            article = {
                'pmid': pmid,
                'title': '',
                'journal': '',
                'issn': '',
                'eissn': '',
                'publication_date': '',
                'doi': '',
                'authors': [],
                'authors_str': '',
                'keywords': [],
                'keywords_str': '',
                'abstract': ''  # åˆå§‹ä¸ºç©º
            }
            articles.append(article)
        
        # å°è¯•æ‰¹é‡è·å–åŸºæœ¬ä¿¡æ¯
        try:
            detailed_articles = self.pubmed_searcher.fetch_article_details(pmids)
            
            # åˆ›å»ºPMIDåˆ°æ–‡ç« çš„æ˜ å°„
            pmid_to_article = {article['pmid']: article for article in detailed_articles}
            
            # æ›´æ–°åŸºæœ¬ä¿¡æ¯
            for article in articles:
                pmid = article['pmid']
                if pmid in pmid_to_article:
                    detailed_article = pmid_to_article[pmid]
                    article.update({
                        'title': detailed_article.get('title', ''),
                        'journal': detailed_article.get('journal', ''),
                        'issn': detailed_article.get('issn', ''),
                        'eissn': detailed_article.get('eissn', ''),
                        'publication_date': detailed_article.get('publication_date', ''),
                        'doi': detailed_article.get('doi', ''),
                        'authors': detailed_article.get('authors', []),
                        'authors_str': detailed_article.get('authors_str', ''),
                        'keywords': detailed_article.get('keywords', []),
                        'keywords_str': detailed_article.get('keywords_str', '')
                    })
        
        except Exception as e:
            print(f"è·å–åŸºæœ¬ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        
        return articles
    
    def _merge_article_info(self, filtered_articles: List[Dict], 
                          detailed_articles: List[Dict]) -> List[Dict]:
        """åˆå¹¶ç­›é€‰ä¿¡æ¯å’Œè¯¦ç»†ä¿¡æ¯"""
        # åˆ›å»ºPMIDåˆ°è¯¦ç»†ä¿¡æ¯çš„æ˜ å°„
        pmid_to_detailed = {article['pmid']: article for article in detailed_articles}
        
        merged_articles = []
        for filtered_article in filtered_articles:
            pmid = filtered_article['pmid']
            
            # ä»è¯¦ç»†ä¿¡æ¯ä¸­è·å–æ‘˜è¦
            if pmid in pmid_to_detailed:
                detailed_article = pmid_to_detailed[pmid]
                filtered_article['abstract'] = detailed_article.get('abstract', '')
            
            merged_articles.append(filtered_article)
        
        return merged_articles
    
    def interactive_search(self):
        """äº¤äº’å¼æ£€ç´¢"""
        if not self.data_ready:
            if not self.initialize_system():
                return
        
        print("[AI] æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ç³»ç»Ÿ")
        print("è¾“å…¥ 'quit' é€€å‡ºï¼Œ'help' æŸ¥çœ‹å¸®åŠ©ï¼Œ'config' ç®¡ç†AIé…ç½®")
        print("-" * 50)
        
        while True:
            try:
                user_input = input("\nè¯·æè¿°æ‚¨çš„æ–‡çŒ®æ£€ç´¢éœ€æ±‚: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() == 'quit':
                    print("æ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ç³»ç»Ÿ!")
                    break
                
                if user_input.lower() == 'help':
                    self._show_help()
                    continue
                
                if user_input.lower() == 'config':
                    self._manage_ai_config()
                    continue
                
                # è·å–æ£€ç´¢å‚æ•°
                max_results = self._get_max_results()
                
                # è¯¢é—®æ˜¯å¦éœ€è¦ç”Ÿæˆç»¼è¿°å¤§çº²ï¼ˆé»˜è®¤ä¸ºæ˜¯ï¼‰
                generate_outline = True  # é»˜è®¤ç”Ÿæˆå¤§çº²
                if self.outline_generator:
                    outline_choice = input("\næ˜¯å¦ç”Ÿæˆç»¼è¿°å¤§çº²? (y/n) [y]: ").strip().lower()
                    generate_outline = outline_choice not in ['n', 'no']  # é»˜è®¤ä¸ºæ˜¯ï¼Œåªæœ‰æ˜ç¡®è¯´ä¸æ‰ä¸ç”Ÿæˆ
                
                # æ‰§è¡Œæ£€ç´¢æˆ–ä¸€é”®æ£€ç´¢+å¤§çº²ç”Ÿæˆ
                if generate_outline:
                    outline_file = self.search_and_generate_outline(user_input, max_results)
                    if outline_file:
                        print(f"\n[OK] æ–‡çŒ®æ£€ç´¢å’Œå¤§çº²ç”Ÿæˆå®Œæˆ!")
                        print(f"[NOTE] ç»¼è¿°å¤§çº²å·²ä¿å­˜åˆ°: {outline_file}")
                    else:
                        print("\n[FAIL] å¤§çº²ç”Ÿæˆå¤±è´¥")
                else:
                    # æ™®é€šæ–‡çŒ®æ£€ç´¢ï¼ˆç°åœ¨åŒæ—¶ç”ŸæˆJSONå’ŒCSVï¼‰
                    search_result = self.search_literature(user_input, max_results)
                    
                    if search_result:
                        # å¤„ç†è¿”å›ç»“æœ
                        if isinstance(search_result, tuple):
                            csv_file, json_file = search_result
                            print(f"\n[OK] æ£€ç´¢æˆåŠŸ!")
                            print(f"[STAT] CSVæ ¼å¼: {csv_file}")
                            print(f"[FILE] JSONæ ¼å¼: {json_file}")
                        else:
                            # å‘åå…¼å®¹
                            csv_file = json_file = search_result
                            print(f"\n[OK] æ£€ç´¢æˆåŠŸ! ç»“æœå·²ä¿å­˜åˆ°: {search_result}")
                        
                        # è¯¢é—®æ˜¯å¦åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆå¤§çº²ï¼ˆé»˜è®¤ä¸ºæ˜¯ï¼‰
                        if self.outline_generator and json_file:
                            post_outline = input("\næ˜¯å¦åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç»¼è¿°å¤§çº²? (y/n) [y]: ").strip().lower()
                            if post_outline not in ['n', 'no']:  # é»˜è®¤ä¸ºæ˜¯
                                outline_file = self.generate_review_outline(json_file, user_input)
                                if outline_file:
                                    print(f"[NOTE] ç»¼è¿°å¤§çº²å·²ä¿å­˜åˆ°: {outline_file}")
                    else:
                        print("\n[FAIL] æ£€ç´¢å¤±è´¥æˆ–æ— ç»“æœ")
                
            except KeyboardInterrupt:
                print("\n\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
                break
            except Exception as e:
                print(f"\nå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    
    def _get_max_results(self) -> int:
        """è·å–æœ€å¤§ç»“æœæ•°"""
        while True:
            try:
                max_str = input("æœ€å¤§æ£€ç´¢ç»“æœæ•° [50]: ").strip()
                if not max_str:
                    return 50
                max_results = int(max_str)
                if max_results > 0:
                    return max_results
                else:
                    print("è¯·è¾“å…¥æ­£æ•´æ•°")
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
    
    def _manage_ai_config(self):
        """ç®¡ç†AIé…ç½®"""
        print("\n[CONFIG]  AIé…ç½®ç®¡ç†")
        print("1. æŸ¥çœ‹å½“å‰ç¼“å­˜é…ç½®")
        print("2. æ¸…é™¤ç¼“å­˜é…ç½®")
        print("3. é‡æ–°é…ç½®AIæ¨¡å‹")
        print("4. è¿”å›")
        
        choice = input("è¯·é€‰æ‹© (1-4): ").strip()
        
        if choice == '1':
            IntentAnalyzer.show_cached_config()
        elif choice == '2':
            if self.intent_analyzer:
                self.intent_analyzer.clear_config_cache()
            else:
                # ç›´æ¥æ¸…é™¤ç¼“å­˜æ–‡ä»¶
                try:
                    if os.path.exists(IntentAnalyzer.CONFIG_CACHE_FILE):
                        os.remove(IntentAnalyzer.CONFIG_CACHE_FILE)
                        print("[OK] é…ç½®ç¼“å­˜å·²æ¸…é™¤")
                    else:
                        print("â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°é…ç½®ç¼“å­˜æ–‡ä»¶")
                except Exception as e:
                    print(f"[FAIL] æ¸…é™¤é…ç½®ç¼“å­˜å¤±è´¥: {e}")
        elif choice == '3':
            print("[CONFIG]  é‡æ–°é…ç½®AIæ¨¡å‹...")
            try:
                self.intent_analyzer = IntentAnalyzer(
                    self.ai_config_name, 
                    interactive=True
                )
                print("[OK] AIæ¨¡å‹é…ç½®å®Œæˆ")
            except Exception as e:
                print(f"[FAIL] AIæ¨¡å‹é…ç½®å¤±è´¥: {e}")
        elif choice == '4':
            return
        else:
            print("[FAIL] æ— æ•ˆé€‰æ‹©")
    
    def _show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("""
ğŸ“– ä½¿ç”¨å¸®åŠ©:

[FIND] æ£€ç´¢ç¤ºä¾‹:
  "ç³–å°¿ç—…æ²»ç–—çš„æœ€æ–°ç ”ç©¶ï¼Œè¦æ±‚æ˜¯è¿‘5å¹´çš„é«˜å½±å“å› å­æœŸåˆŠæ–‡çŒ®"
  "COVID-19ç–«è‹—æ•ˆåŠ›ç ”ç©¶ï¼Œ2020å¹´ä»¥æ¥çš„æ–‡çŒ®"
  "é«˜è¡€å‹è¯ç‰©æ²»ç–—ï¼Œè¦æ±‚1åŒºæˆ–2åŒºæœŸåˆŠ"

[CONFIG] ç³»ç»Ÿå‘½ä»¤:
  help - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  config - ç®¡ç†AIæ¨¡å‹é…ç½®ï¼ˆæŸ¥çœ‹/æ¸…é™¤ç¼“å­˜ã€é‡æ–°é…ç½®ï¼‰
  quit - é€€å‡ºç³»ç»Ÿ

[LIST] é…ç½®ç¼“å­˜åŠŸèƒ½:
  - é¦–æ¬¡ä½¿ç”¨ä¼šè¦æ±‚é€‰æ‹©AIæ¨¡å‹å’Œå‚æ•°
  - é…ç½®ä¼šè‡ªåŠ¨ç¼“å­˜ï¼Œä¸‹æ¬¡å¯åŠ¨æ—¶è¯¢é—®æ˜¯å¦å¤ç”¨
  - å¯é€šè¿‡ 'config' å‘½ä»¤ç®¡ç†ç¼“å­˜é…ç½®

[STAT] ç­›é€‰æ¡ä»¶æ”¯æŒ:
  - å¹´ä»½é™åˆ¶: "è¿‘å¹´æ¥"ã€"è¿‘3å¹´"ã€"2020å¹´ä»¥æ¥"ç­‰
  - å½±å“å› å­: "é«˜å½±å“å› å­"ã€"é¡¶çº§æœŸåˆŠ"ç­‰  
  - ä¸­ç§‘é™¢åˆ†åŒº: "1åŒº"ã€"é«˜çº§æœŸåˆŠ"ç­‰
  - JCRåˆ†åŒº: "Q1æœŸåˆŠ"ç­‰

[SAVE] è¾“å‡ºæ ¼å¼: JSON å’Œ CSV ä¸¤ç§æ ¼å¼å¯é€‰
        """)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ™ºèƒ½æ–‡çŒ®æ£€ç´¢å’Œç­›é€‰ç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python smart_literature_search.py                    # äº¤äº’å¼æ¨¡å¼ï¼ˆè‡ªåŠ¨è¾“å‡ºCSVå’ŒJSONï¼‰
  python smart_literature_search.py -q "ç³–å°¿ç—…æ²»ç–—ç ”ç©¶" # ç›´æ¥æ£€ç´¢æ¨¡å¼ï¼ˆè‡ªåŠ¨è¾“å‡ºCSVå’ŒJSONï¼‰
  python smart_literature_search.py -q "COVID-19ç–«è‹—" -n 20  # æŒ‡å®šç»“æœæ•°é‡
  python smart_literature_search.py -q "é«˜è¡€å‹æ²»ç–—" --generate-outline  # ä¸€é”®æ£€ç´¢+å¤§çº²ç”Ÿæˆ
  python smart_literature_search.py --outline-from-file literature.json --outline-topic "ç³–å°¿ç—…æ²»ç–—"  # ä»å·²æœ‰æ–‡ä»¶ç”Ÿæˆå¤§çº²
        """
    )
    
    parser.add_argument('-q', '--query', help='ç›´æ¥æ£€ç´¢çš„æŸ¥è¯¢è¯­å¥')
    parser.add_argument('-n', '--max-results', type=int, default=50, 
                       help='æœ€å¤§ç»“æœæ•°é‡ (é»˜è®¤: 50)')
    parser.add_argument('--ai-config', help='æŒ‡å®šAIé…ç½®åç§°')
    parser.add_argument('--non-interactive-ai', action='store_true',
                       help='éäº¤äº’å¼AIé…ç½®ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹å’Œå‚æ•°ï¼‰')
    parser.add_argument('--init-only', action='store_true', 
                       help='ä»…åˆå§‹åŒ–ç³»ç»Ÿï¼Œä¸è¿›è¡Œæ£€ç´¢')
    
    # å¤§çº²ç”Ÿæˆç›¸å…³å‚æ•°
    parser.add_argument('--generate-outline', action='store_true',
                       help='ç”Ÿæˆç»¼è¿°å¤§çº²ï¼ˆéœ€è¦JSONæ ¼å¼è¾“å‡ºï¼‰')
    parser.add_argument('--outline-from-file', help='ä»ç°æœ‰JSONæ–‡ä»¶ç”Ÿæˆå¤§çº²')
    parser.add_argument('--outline-topic', help='å¤§çº²ä¸»é¢˜ï¼ˆé…åˆ--outline-from-fileä½¿ç”¨ï¼‰')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºç³»ç»Ÿå®ä¾‹
        system = SmartLiteratureSearchSystem(
            args.ai_config, 
            interactive_ai=not args.non_interactive_ai
        )
        
        if args.init_only:
            # ä»…åˆå§‹åŒ–
            system.initialize_system()
            return
        
        # ä»ç°æœ‰æ–‡ä»¶ç”Ÿæˆå¤§çº²
        if args.outline_from_file:
            if not args.outline_topic:
                print("[FAIL] ä½¿ç”¨ --outline-from-file æ—¶å¿…é¡»æä¾› --outline-topic")
                sys.exit(1)
            
            if not system.initialize_system():
                sys.exit(1)
            
            outline_file = system.generate_review_outline(
                args.outline_from_file, args.outline_topic
            )
            
            if outline_file:
                print(f"\n[NOTE] å¤§çº²ç”Ÿæˆå®Œæˆ! æ–‡ä»¶: {outline_file}")
            else:
                print("\n[FAIL] å¤§çº²ç”Ÿæˆå¤±è´¥")
                sys.exit(1)
            return
        
        if args.query:
            # ç›´æ¥æ£€ç´¢æ¨¡å¼
            if not system.initialize_system():
                sys.exit(1)
            
            # å¦‚æœéœ€è¦ç”Ÿæˆå¤§çº²ï¼Œä½¿ç”¨ä¸€é”®æµç¨‹
            if args.generate_outline:
                outline_file = system.search_and_generate_outline(
                    args.query, args.max_results
                )
                
                if outline_file:
                    print(f"\nğŸ‰ æ£€ç´¢å’Œå¤§çº²ç”Ÿæˆå®Œæˆ!")
                    print(f"[NOTE] ç»¼è¿°å¤§çº²æ–‡ä»¶: {outline_file}")
                else:
                    print("\n[FAIL] æ£€ç´¢æˆ–å¤§çº²ç”Ÿæˆå¤±è´¥")
                    sys.exit(1)
            else:
                # æ™®é€šæ£€ç´¢ï¼ˆåŒæ—¶ç”ŸæˆCSVå’ŒJSONï¼‰
                search_result = system.search_literature(
                    args.query, args.max_results
                )
                
                if search_result:
                    if isinstance(search_result, tuple):
                        csv_file, json_file = search_result
                        print(f"\nğŸ‰ æ£€ç´¢å®Œæˆ!")
                        print(f"[STAT] CSVæ ¼å¼: {csv_file}")
                        print(f"[FILE] JSONæ ¼å¼: {json_file}")
                    else:
                        # å‘åå…¼å®¹
                        print(f"\nğŸ‰ æ£€ç´¢å®Œæˆ! ç»“æœæ–‡ä»¶: {search_result}")
                else:
                    print("\n[FAIL] æ£€ç´¢å¤±è´¥æˆ–æ— ç»“æœ")
                    sys.exit(1)
        else:
            # äº¤äº’å¼æ¨¡å¼
            system.interactive_search()
    
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()