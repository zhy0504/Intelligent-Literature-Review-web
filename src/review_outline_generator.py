#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒ»å­¦æ–‡çŒ®ç»¼è¿°å¤§çº²ç”Ÿæˆå™¨
åŸºäºæ–‡çŒ®æ‘˜è¦ç”Ÿæˆç»“æ„åŒ–çš„ç»¼è¿°å†™ä½œå¤§çº²å’Œå­—æ•°è§„åˆ’
"""

import json
import os
import re
import time
import threading
import hashlib
from typing import Dict, List, Optional, Tuple
from collections import Counter, defaultdict
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
from ai_client import AIClient, ConfigManager, ChatMessage
from prompts_manager import PromptsManager


class OutlineGeneratorConfig:
    """å¤§çº²ç”Ÿæˆå™¨é…ç½®ç±»"""
    def __init__(self):
        self.max_workers = 4  # æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        self.cache_size = 500  # ç¼“å­˜å¤§å°
        self.cache_ttl = 7200  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰- 2å°æ—¶
        # self.max_abstracts = 100  # ç§»é™¤å›ºå®šé™åˆ¶ï¼Œæ ¹æ®è¾“å…¥å¤„ç†
        self.batch_size = 50  # æ‰¹å¤„ç†å¤§å°
        self.enable_parallel = True  # å¯ç”¨å¹¶è¡Œå¤„ç†
        self.enable_caching = True  # å¯ç”¨ç¼“å­˜
        self.retry_attempts = 3  # é‡è¯•æ¬¡æ•°
        self.memory_limit_mb = 300  # å†…å­˜é™åˆ¶ï¼ˆMBï¼‰


class OutlineCache:
    """å¤§çº²ç”Ÿæˆç»“æœç¼“å­˜ç®¡ç†å™¨"""
    def __init__(self, config: OutlineGeneratorConfig):
        self.config = config
        self.cache = {}
        self.access_times = {}
        self.lock = threading.Lock()
        self.stats = {'hits': 0, 'misses': 0, 'evictions': 0}
    
    def _generate_key(self, abstracts_hash: str, research_topic: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{abstracts_hash}:{research_topic}"
        return hashlib.sha256(content.encode('utf-8')).hexdigest()
    
    def _hash_abstracts(self, abstracts: List[str]) -> str:
        """ç”Ÿæˆæ‘˜è¦åˆ—è¡¨çš„å“ˆå¸Œå€¼"""
        content = "|".join(sorted(abstracts))
        return hashlib.sha256(content.encode('utf-8')).hexdigest()
    
    def get(self, abstracts: List[str], research_topic: str) -> Optional[str]:
        """è·å–ç¼“å­˜çš„å¤§çº²ç»“æœ"""
        if not self.config.enable_caching:
            return None
            
        abstracts_hash = self._hash_abstracts(abstracts)
        key = self._generate_key(abstracts_hash, research_topic)
        
        with self.lock:
            if key in self.cache:
                # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                if time.time() - self.access_times[key] < self.config.cache_ttl:
                    self.access_times[key] = time.time()
                    self.stats['hits'] += 1
                    return self.cache[key]
                else:
                    # è¿‡æœŸåˆ é™¤
                    del self.cache[key]
                    del self.access_times[key]
                    self.stats['evictions'] += 1
            
            self.stats['misses'] += 1
            return None
    
    def put(self, abstracts: List[str], research_topic: str, outline: str):
        """å­˜å‚¨å¤§çº²ç»“æœ"""
        if not self.config.enable_caching:
            return
            
        abstracts_hash = self._hash_abstracts(abstracts)
        key = self._generate_key(abstracts_hash, research_topic)
        
        with self.lock:
            # æ£€æŸ¥ç¼“å­˜å¤§å°
            if len(self.cache) >= self.config.cache_size:
                # LRUæ·˜æ±°
                oldest_key = min(self.access_times.keys(), key=self.access_times.get)
                del self.cache[oldest_key]
                del self.access_times[oldest_key]
                self.stats['evictions'] += 1
            
            self.cache[key] = outline
            self.access_times[key] = time.time()
    
    def get_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total_requests = self.stats['hits'] + self.stats['misses']
        hit_rate = self.stats['hits'] / total_requests if total_requests > 0 else 0
        
        return {
            'cache_size': len(self.cache),
            'max_cache_size': self.config.cache_size,
            'hits': self.stats['hits'],
            'misses': self.stats['misses'],
            'evictions': self.stats['evictions'],
            'hit_rate': hit_rate
        }


@dataclass
class OutlineSection:
    """å¤§çº²ç« èŠ‚"""
    title: str
    word_count: int
    level: int = 1
    subsections: List['OutlineSection'] = None
    
    def __post_init__(self):
        if self.subsections is None:
            self.subsections = []


class ReviewOutlineGenerator:
    """ç»¼è¿°å¤§çº²ç”Ÿæˆå™¨"""
    
    def __init__(self, ai_config_name: str = None, generator_config: OutlineGeneratorConfig = None):
        """
        åˆå§‹åŒ–å¤§çº²ç”Ÿæˆå™¨
        
        Args:
            ai_config_name: AIé…ç½®åç§°
            generator_config: ç”Ÿæˆå™¨é…ç½®
        """
        self.ai_config_name = ai_config_name
        self.generator_config = generator_config or OutlineGeneratorConfig()
        self.config_manager = ConfigManager()
        self.ai_client = AIClient()
        
        # åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨
        self.prompts_manager = PromptsManager()
        
        # åˆå§‹åŒ–ç¼“å­˜
        self.outline_cache = OutlineCache(self.generator_config)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_outlines_generated': 0,
            'total_generation_time': 0,
            'cache_hits': 0,
            'parallel_batches': 0,
            'abstracts_processed': 0,
            'ai_calls': 0,
            'errors': 0,
            'retries': 0
        }
        
        # é€‰æ‹©AIé…ç½®
        self.config = self._select_config()
        if self.config:
            self.adapter = self.ai_client.create_adapter(self.config)
            
            # å°è¯•ä½¿ç”¨æ„å›¾åˆ†æå™¨çš„ç¼“å­˜é…ç½®ï¼Œç¡®ä¿å®Œå…¨ä¸€è‡´
            cached_model = self._load_cached_model_config()
            if cached_model:
                self.model_id = cached_model['model_id']
                # ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°ï¼Œåªè°ƒæ•´streamä¸ºTrueä»¥æ”¯æŒæµå¼è¾“å‡º
                self.model_parameters = cached_model['parameters'].copy()
                self.model_parameters['stream'] = True  # å¤§çº²ç”Ÿæˆä½¿ç”¨æµå¼è¾“å‡º
                print(f"[OK] ä½¿ç”¨ç¼“å­˜æ¨¡å‹é…ç½®: {self.model_id} (å‚æ•°ä¸æ„å›¾åˆ†æå™¨å®Œå…¨ä¸€è‡´)")
            else:
                # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                print("[WARN] æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ç¼“å­˜ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self.model_id = "gemini-2.5-pro"
                self.model_parameters = {
                    "temperature": 0.1,
                    "stream": True,
                    "max_tokens": None
                }
        else:
            raise RuntimeError("æœªæ‰¾åˆ°å¯ç”¨çš„AIé…ç½®")
        
        print(f"å¹¶è¡Œå¤„ç†: {'å¯ç”¨' if self.generator_config.enable_parallel else 'ç¦ç”¨'}")
        print(f"ç¼“å­˜ç³»ç»Ÿ: {'å¯ç”¨' if self.generator_config.enable_caching else 'ç¦ç”¨'}")
    
    def _load_cached_model_config(self) -> Optional[Dict]:
        """åŠ è½½ç¼“å­˜çš„æ¨¡å‹é…ç½®"""
        cache_file = "ai_model_cache.json"
        if os.path.exists(cache_file):
            try:
                import json
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"åŠ è½½æ¨¡å‹é…ç½®ç¼“å­˜å¤±è´¥: {e}")
        return None
    
    def _select_config(self):
        """é€‰æ‹©AIé…ç½®"""
        configs = self.config_manager.list_configs()
        if not configs:
            return None
        if self.ai_config_name:
            return self.config_manager.get_config(self.ai_config_name)
        else:
            return self.config_manager.get_config(configs[0])
    
    def _get_default_model(self):
        """ä»ç«¯ç‚¹è·å–æ¨¡å‹å¹¶è®©ç”¨æˆ·é€‰æ‹©"""
        try:
            models = self.adapter.get_available_models()
            if not models:
                print("[FAIL] ç«¯ç‚¹æœªè¿”å›å¯ç”¨æ¨¡å‹")
                return None
            
            # æŸ¥æ‰¾ gemini-2.5-pro æ¨¡å‹çš„ç´¢å¼•
            preferred_index = None
            for i, model in enumerate(models):
                if "gemini-2.5-pro" in model.id.lower():
                    preferred_index = i + 1  # æ˜¾ç¤ºçš„åºå·æ˜¯ä»1å¼€å§‹çš„
                    break
            
            print(f"[FIND] ä»ç«¯ç‚¹è·å–åˆ° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹:")
            for i, model in enumerate(models, 1):
                prefix = "ğŸŒŸ " if preferred_index == i else "  "
                print(f"{prefix}{i}. {model.id}")
            
            # è®¾ç½®é»˜è®¤é€‰é¡¹æç¤º
            default_choice = f"[{preferred_index}]" if preferred_index else "[1]"
            default_index = preferred_index - 1 if preferred_index else 0
            
            while True:
                try:
                    choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(models)}) {default_choice}: ").strip()
                    if not choice:
                        selected_index = default_index  # é»˜è®¤é€‰æ‹©
                    else:
                        selected_index = int(choice) - 1
                    
                    if 0 <= selected_index < len(models):
                        selected_model = models[selected_index]
                        print(f"[OK] å·²é€‰æ‹©æ¨¡å‹: {selected_model.id}")
                        return selected_model.id
                    else:
                        print(f"è¯·è¾“å…¥ 1-{len(models)} ä¹‹é—´çš„æ•°å­—")
                except (ValueError, EOFError):
                    # å¦‚æœæ˜¯æ— è¾“å…¥ç¯å¢ƒæˆ–è¾“å…¥é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤é€‰æ‹©
                    selected_model = models[default_index]
                    print(f"[OK] è‡ªåŠ¨é€‰æ‹©é»˜è®¤æ¨¡å‹: {selected_model.id}")
                    return selected_model.id
                    
        except Exception as e:
            print(f"\n[ERROR] è·å–AIæ¨¡å‹å¤±è´¥: {e}")
            print("è¿™é€šå¸¸è¡¨ç¤ºAIæœåŠ¡è¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ‚¨çš„AIé…ç½®")
            return None
    
    def generate_outline_from_json(self, json_file_path: str, research_topic: str) -> str:
        """
        ä»JSONæ–‡ä»¶ç”Ÿæˆç»¼è¿°å¤§çº²
        
        Args:
            json_file_path: æ–‡çŒ®JSONæ–‡ä»¶è·¯å¾„
            research_topic: ç ”ç©¶ä¸»é¢˜
            
        Returns:
            ç”Ÿæˆçš„å¤§çº²markdownæ–‡æœ¬
        """
        # 1. è¯»å–JSONæ–‡çŒ®æ•°æ®
        literature_data = self._load_literature_json(json_file_path)
        
        # 2. æå–æ‘˜è¦ä¿¡æ¯
        abstracts = self._extract_abstracts(literature_data)
        
        if not abstracts:
            print("è­¦å‘Š: æœªæ‰¾åˆ°æ‘˜è¦ä¿¡æ¯ï¼Œå°†åŸºäºæ ‡é¢˜ç”Ÿæˆå¤§çº²")
            abstracts = self._extract_titles(literature_data)
        
        # 3. ç”Ÿæˆå¤§çº²
        outline = self._generate_outline_with_ai(abstracts, research_topic)
        
        return outline
    
    def generate_outline_from_data_optimized(self, literature_data: List[Dict], research_topic: str) -> str:
        """
        ä¼˜åŒ–çš„ä»æ–‡çŒ®æ•°æ®ç”Ÿæˆç»¼è¿°å¤§çº²æ–¹æ³•
        
        Args:
            literature_data: æ–‡çŒ®æ•°æ®åˆ—è¡¨
            research_topic: ç ”ç©¶ä¸»é¢˜
            
        Returns:
            ç”Ÿæˆçš„å¤§çº²markdownæ–‡æœ¬
        """
        start_time = time.time()
        
        print(f"\nå¼€å§‹ç”Ÿæˆå¤§çº²ï¼Œæ–‡çŒ®æ•°é‡: {len(literature_data)}")
        print(f"å¹¶è¡Œå¤„ç†: {'å¯ç”¨' if self.generator_config.enable_parallel else 'ç¦ç”¨'}")
        
        # å¹¶è¡Œæå–æ–‡çŒ®ä¿¡æ¯
        abstracts, titles = self._extract_literature_info_parallel(literature_data)
        
        if not abstracts:
            print("è­¦å‘Š: æœªæ‰¾åˆ°æ‘˜è¦ä¿¡æ¯ï¼Œå°†åŸºäºæ ‡é¢˜ç”Ÿæˆå¤§çº²")
            abstracts = titles
        
        # æ£€æŸ¥ç¼“å­˜
        cached_outline = self.outline_cache.get(abstracts, research_topic)
        if cached_outline:
            self.performance_stats['cache_hits'] += 1
            print("[OK] å‘½ä¸­ç¼“å­˜ï¼Œç›´æ¥è¿”å›å¤§çº²ç»“æœ")
            return cached_outline
        
        # ç”Ÿæˆå¤§çº²
        outline = self._generate_outline_with_ai_optimized(abstracts, research_topic)
        
        # ç¼“å­˜ç»“æœ
        if outline:
            self.outline_cache.put(abstracts, research_topic, outline)
        
        # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
        generation_time = time.time() - start_time
        self.performance_stats['total_generation_time'] += generation_time
        self.performance_stats['total_outlines_generated'] += 1
        self.performance_stats['abstracts_processed'] += len(abstracts)
        
        print(f"å¤§çº²ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {generation_time:.2f}ç§’")
        
        return outline
    
    def _extract_literature_info_parallel(self, literature_data: List[Dict]) -> Tuple[List[str], List[str]]:
        """å¹¶è¡Œæå–æ–‡çŒ®ä¿¡æ¯"""
        if self.generator_config.enable_parallel and len(literature_data) > self.generator_config.batch_size:
            # å¹¶è¡Œå¤„ç†
            return self._extract_info_parallel(literature_data)
        else:
            # ä¸²è¡Œå¤„ç†
            abstracts = self._extract_abstracts_optimized(literature_data)
            titles = self._extract_titles_optimized(literature_data)
            return abstracts, titles
    
    def _extract_info_parallel(self, literature_data: List[Dict]) -> Tuple[List[str], List[str]]:
        """å¹¶è¡Œæå–æ‘˜è¦å’Œæ ‡é¢˜"""
        batch_size = self.generator_config.batch_size
        batches = [literature_data[i:i + batch_size] for i in range(0, len(literature_data), batch_size)]
        
        all_abstracts = []
        all_titles = []
        
        with ThreadPoolExecutor(max_workers=self.generator_config.max_workers) as executor:
            # æäº¤æ‰€æœ‰æ‰¹æ¬¡ä»»åŠ¡
            future_to_batch = {
                executor.submit(self._process_literature_batch, batch): batch 
                for batch in batches
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_batch):
                try:
                    batch_abstracts, batch_titles = future.result()
                    all_abstracts.extend(batch_abstracts)
                    all_titles.extend(batch_titles)
                    self.performance_stats['parallel_batches'] += 1
                except Exception as e:
                    print(f"å¤„ç†æ–‡çŒ®æ‰¹æ¬¡å¤±è´¥: {e}")
                    self.performance_stats['errors'] += 1
        
        return all_abstracts, all_titles
    
    def _process_literature_batch(self, batch: List[Dict]) -> Tuple[List[str], List[str]]:
        """å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡çš„æ–‡çŒ®"""
        abstracts = self._extract_abstracts_optimized(batch)
        titles = self._extract_titles_optimized(batch)
        return abstracts, titles
    
    def generate_outline_from_data(self, literature_data: List[Dict], research_topic: str) -> str:
        """å…¼å®¹æ€§æ–¹æ³•"""
        return self.generate_outline_from_data_optimized(literature_data, research_topic)
    
    def _load_literature_json(self, json_file_path: str) -> List[Dict]:
        """åŠ è½½JSONæ–‡çŒ®æ•°æ®"""
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # å¦‚æœæ˜¯æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ç³»ç»Ÿå¯¼å‡ºçš„æ ¼å¼
            if isinstance(data, dict) and 'articles' in data:
                return data['articles']
            # å¦‚æœç›´æ¥æ˜¯æ–‡ç« åˆ—è¡¨
            elif isinstance(data, list):
                return data
            else:
                raise ValueError("ä¸æ”¯æŒçš„JSONæ ¼å¼")
                
        except Exception as e:
            raise RuntimeError(f"è¯»å–JSONæ–‡ä»¶å¤±è´¥: {e}")
    
    def _extract_abstracts_optimized(self, literature_data: List[Dict]) -> List[str]:
        """ä¼˜åŒ–çš„æ‘˜è¦æå–æ–¹æ³•"""
        abstracts = []
        
        # å¯èƒ½çš„æ‘˜è¦å­—æ®µåï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        abstract_fields = ['æ‘˜è¦', 'abstract', 'Abstract', 'summary', 'Summary', 'description', 'Description']
        
        for article in literature_data:
            try:
                abstract = ''
                
                # å°è¯•ä¸åŒçš„æ‘˜è¦å­—æ®µå
                for field in abstract_fields:
                    if field in article:
                        field_value = article.get(field) or ''
                        if isinstance(field_value, str) and field_value.strip():
                            abstract = field_value.strip()
                            if len(abstract) > 50:  # æ‰¾åˆ°æœ‰æ•ˆæ‘˜è¦å°±è·³å‡º
                                break
                
                # æ™ºèƒ½ç­›é€‰ï¼šåªä¿ç•™æœ‰å®é™…å†…å®¹çš„æ‘˜è¦
                if abstract and len(abstract) > 50:
                    # æ¸…ç†æ‘˜è¦æ–‡æœ¬
                    cleaned_abstract = self._clean_abstract_text(abstract)
                    if cleaned_abstract:
                        abstracts.append(cleaned_abstract)
            except Exception as e:
                print(f"æå–æ‘˜è¦å¤±è´¥: {e}")
                self.performance_stats['errors'] += 1
        
        # æ™ºèƒ½é€‰æ‹©ï¼šé™åˆ¶æ•°é‡å¹¶ä¼˜åŒ–è´¨é‡
        return self._select_best_abstracts(abstracts)
    
    def _clean_abstract_text(self, abstract: str) -> str:
        """æ¸…ç†æ‘˜è¦æ–‡æœ¬"""
        try:
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
            abstract = re.sub(r'\s+', ' ', abstract)
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
            abstract = re.sub(r'[^\w\s\u4e00-\u9fff.,;:!?()-]', '', abstract)
            # æˆªæ–­è¿‡é•¿çš„æ‘˜è¦
            if len(abstract) > 2000:
                abstract = abstract[:2000] + "..."
            return abstract.strip()
        except Exception:
            return abstract
    
    def _select_best_abstracts(self, abstracts: List[str]) -> List[str]:
        """æ™ºèƒ½é€‰æ‹©æœ€ä½³æ‘˜è¦"""
        # ç§»é™¤max_abstractsé™åˆ¶ï¼Œå¤„ç†æ‰€æœ‰æ‘˜è¦
        if not abstracts:
            return abstracts
        
        # æŒ‰é•¿åº¦å’Œè´¨é‡æ’åº
        scored_abstracts = []
        for abstract in abstracts:
            score = self._score_abstract(abstract)
            scored_abstracts.append((score, abstract))
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æ‘˜è¦ï¼ˆå…¨éƒ¨å¤„ç†ï¼‰
        scored_abstracts.sort(reverse=True)
        return [abstract for score, abstract in scored_abstracts]
    
    def _score_abstract(self, abstract: str) -> float:
        """ä¸ºæ‘˜è¦è¯„åˆ†"""
        score = 0.0
        
        # é•¿åº¦è¯„åˆ†
        length = len(abstract)
        if 100 <= length <= 800:
            score += 0.3
        elif 50 <= length <= 1500:
            score += 0.2
        
        # å†…å®¹è´¨é‡è¯„åˆ†
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
        keywords = ['study', 'research', 'analysis', 'results', 'conclusion', 'findings', 
                   'ç ”ç©¶', 'åˆ†æ', 'ç»“æœ', 'ç»“è®º', 'å‘ç°']
        keyword_count = sum(1 for keyword in keywords if keyword.lower() in abstract.lower())
        score += min(keyword_count * 0.1, 0.3)
        
        # ç»“æ„è¯„åˆ†
        if '.' in abstract and len(abstract.split('.')) > 3:
            score += 0.2
        
        return score
    
    def _extract_abstracts(self, literature_data: List[Dict]) -> List[str]:
        """å…¼å®¹æ€§æ–¹æ³•"""
        return self._extract_abstracts_optimized(literature_data)
    
    def _extract_titles_optimized(self, literature_data: List[Dict]) -> List[str]:
        """ä¼˜åŒ–çš„æ ‡é¢˜æå–æ–¹æ³•"""
        titles = []
        
        for article in literature_data:
            try:
                # å®‰å…¨åœ°è·å–æ ‡é¢˜ï¼Œå¤„ç† None å€¼
                title = article.get('title') or ''
                if isinstance(title, str) and title.strip():
                    # æ¸…ç†æ ‡é¢˜æ–‡æœ¬
                    cleaned_title = self._clean_title_text(title.strip())
                    if cleaned_title:
                        titles.append(cleaned_title)
            except Exception as e:
                print(f"æå–æ ‡é¢˜å¤±è´¥: {e}")
                self.performance_stats['errors'] += 1
        
        return titles
    
    def _clean_title_text(self, title: str) -> str:
        """æ¸…ç†æ ‡é¢˜æ–‡æœ¬"""
        try:
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
            title = re.sub(r'\s+', ' ', title)
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
            title = re.sub(r'[^\w\s\u4e00-\u9fff.,;:!?()-]', '', title)
            # æˆªæ–­è¿‡é•¿çš„æ ‡é¢˜
            if len(title) > 300:
                title = title[:300] + "..."
            return title.strip()
        except Exception:
            return title
    
    def _extract_titles(self, literature_data: List[Dict]) -> List[str]:
        """å…¼å®¹æ€§æ–¹æ³•"""
        return self._extract_titles_optimized(literature_data)
    
    def _generate_outline_with_ai_optimized(self, abstracts: List[str], research_topic: str) -> str:
        """ä¼˜åŒ–çš„AIå¤§çº²ç”Ÿæˆæ–¹æ³•ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
        
        # æ„å»ºæç¤ºè¯
        prompt = self._build_outline_prompt_optimized(abstracts, research_topic)
        
        # æ„å»ºæ¶ˆæ¯
        messages = [ChatMessage(role="user", content=prompt)]
        
        # é‡è¯•æœºåˆ¶
        last_error = None
        for attempt in range(self.generator_config.retry_attempts):
            try:
                self.performance_stats['ai_calls'] += 1
                
                # è°ƒç”¨AIç”Ÿæˆå¤§çº²
                response = self.adapter.send_message(
                    messages,
                    self.model_id,
                    self.model_parameters
                )
                
                # æ ¼å¼åŒ–å“åº”
                outline = self.ai_client.format_response(response, self.adapter.config.api_type)
                
                # æ¸…ç†AIå¼•å¯¼è¯­
                outline = self._clean_ai_intro(outline)
                
                # éªŒè¯å¤§çº²è´¨é‡
                if self._validate_outline(outline):
                    print(f"[SUCCESS] å¤§çº²ç”ŸæˆæˆåŠŸï¼Œé€šè¿‡è´¨é‡éªŒè¯")
                    return outline
                else:
                    print(f"å¤§çº²è´¨é‡éªŒè¯å¤±è´¥ï¼Œå°è¯• {attempt + 1}/{self.generator_config.retry_attempts}")
                    print(f"[DEBUG] ç”Ÿæˆçš„å¤§çº²é•¿åº¦: {len(outline)} å­—ç¬¦")
                    print(f"[DEBUG] å¤§çº²å‰200å­—ç¬¦: {outline[:200]}")
                    last_error = "å¤§çº²è´¨é‡éªŒè¯å¤±è´¥"
                    
            except Exception as e:
                last_error = str(e)
                print(f"AIå¤§çº²ç”Ÿæˆå¤±è´¥ (å°è¯• {attempt + 1}/{self.generator_config.retry_attempts}): {e}")
                self.performance_stats['retries'] += 1
                
                # æŒ‡æ•°é€€é¿
                if attempt < self.generator_config.retry_attempts - 1:
                    delay = min(2 ** attempt, 10)
                    time.sleep(delay)
        
        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›å¢å¼ºçš„åŸºç¡€å¤§çº²æ¨¡æ¿
        print(f"æ‰€æœ‰AIç”Ÿæˆå°è¯•å¤±è´¥ï¼Œä½¿ç”¨å¢å¼ºçš„åŸºç¡€å¤§çº²æ¨¡æ¿")
        print(f"[INFO] åŸºç¡€æ¨¡æ¿åŒ…å«7ä¸ªä¸»è¦éƒ¨åˆ†å’Œè¯¦ç»†å­ç‚¹ï¼Œä»èƒ½æä¾›å®Œæ•´çš„ç»¼è¿°ç»“æ„æŒ‡å¯¼")
        self.performance_stats['errors'] += 1
        return self._generate_basic_outline(research_topic)
    
    def _validate_outline(self, outline: str) -> bool:
        """éªŒè¯å¤§çº²è´¨é‡"""
        if not outline or len(outline.strip()) < 50:  # é™ä½é•¿åº¦è¦æ±‚ä¸º50å­—ç¬¦ï¼Œä¸ä¸»ç³»ç»Ÿä¸€è‡´
            print(f"[DEBUG] å¤§çº²éªŒè¯å¤±è´¥: é•¿åº¦ä¸è¶³ï¼Œå½“å‰é•¿åº¦={len(outline.strip())}")
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦ç»“æ„
        required_sections = ['å¼•è¨€', 'ç»“è®º', 'æ€»ç»“']
        has_required = any(section in outline for section in required_sections)
        print(f"[DEBUG] å¿…è¦ç»“æ„æ£€æŸ¥: {has_required}, æ£€æŸ¥å†…å®¹: {[section for section in required_sections if section in outline]}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å±‚çº§ç»“æ„
        has_hierarchy = '##' in outline or '###' in outline or '-' in outline
        print(f"[DEBUG] å±‚çº§ç»“æ„æ£€æŸ¥: {has_hierarchy}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å­—æ•°å»ºè®® - æ”¾å®½è¦æ±‚ï¼Œåªéœ€è¦åŒ…å«"å­—"å³å¯
        has_word_count = 'å­—' in outline
        print(f"[DEBUG] å­—æ•°å»ºè®®æ£€æŸ¥: {has_word_count}")
        
        print(f"[DEBUG] å¤§çº²éªŒè¯ç»“æœ: å¿…è¦ç»“æ„={has_required}, å±‚çº§ç»“æ„={has_hierarchy}, å­—æ•°å»ºè®®={has_word_count}")
        print(f"[DEBUG] å¤§çº²å‰500å­—ç¬¦: {outline[:500]}")
        
        return has_required and has_hierarchy and has_word_count
    
    def _clean_ai_intro(self, content: str) -> str:
        """æ¸…ç†AIç”Ÿæˆå†…å®¹å‰é¢çš„å¼•å¯¼è¯­"""
        if not content:
            return content
        
        lines = content.split('\n')
        cleaned_lines = []
        start_found = False
        
        # å®šä¹‰å¯èƒ½çš„å¼•å¯¼è¯­æ¨¡å¼
        intro_patterns = [
            'å¥½çš„ï¼Œä½œä¸º',
            'ä½œä¸º',
            'æ ¹æ®æ‚¨æä¾›çš„',
            'åŸºäºæ‚¨æä¾›çš„',
            'æˆ‘å·²å¯¹æ‚¨æä¾›çš„',
            'æˆ‘å°†ä¸ºæ‚¨',
            'ä»¥ä¸‹æ˜¯',
            'ç°åœ¨æˆ‘ä¸ºæ‚¨',
            'åŸºäºä»¥ä¸Š',
            'æ ¹æ®ä»¥ä¸Š'
        ]
        
        for line in lines:
            line = line.strip()
            
            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°å¼€å§‹ä½ç½®ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å¼•å¯¼è¯­
            if not start_found:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¤§çº²çš„å¼€å§‹æ ‡è®°
                if (line.startswith('#') or 
                    line.startswith('##') or 
                    line.startswith('- ') or
                    line.startswith('1.') or
                    line.startswith('ä¸€ã€') or
                    line.startswith('äºŒã€')):
                    start_found = True
                    cleaned_lines.append(line)
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¼•å¯¼è¯­
                elif any(pattern in line for pattern in intro_patterns):
                    # è·³è¿‡å¼•å¯¼è¯­è¡Œ
                    continue
                # å¦‚æœä¸æ˜¯ç©ºè¡Œä¸”ä¸æ˜¯å¼•å¯¼è¯­ï¼Œå¯èƒ½æ˜¯å†…å®¹çš„ä¸€éƒ¨åˆ†
                elif line and not any(pattern in line for pattern in intro_patterns):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å®é™…å†…å®¹æ ‡è®°
                    if ('##' in line or 'å­—' in line or 'å¼•è¨€' in line or 'ç»“è®º' in line):
                        start_found = True
                        cleaned_lines.append(line)
            else:
                # å·²ç»æ‰¾åˆ°å¼€å§‹ä½ç½®ï¼Œä¿ç•™æ‰€æœ‰åç»­å†…å®¹
                cleaned_lines.append(line)
        
        # é‡æ–°ç»„åˆå†…å®¹
        cleaned_content = '\n'.join(cleaned_lines).strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¿”å›åŸå§‹å†…å®¹
        if not cleaned_content:
            return content
        
        return cleaned_content
    
    def _build_outline_prompt_optimized(self, abstracts: List[str], research_topic: str) -> str:
        """ä¼˜åŒ–çš„æç¤ºè¯æ„å»ºæ–¹æ³•"""
        
        # å¤„ç†æ‰€æœ‰ä¼ å…¥çš„æ‘˜è¦ï¼Œä¸è®¾ä¸Šé™
        abstracts_text = "\n\n".join([f"æ‘˜è¦{i+1}: {abstract}" for i, abstract in enumerate(abstracts)])
        
        # ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿
        try:
            prompt = self.prompts_manager.get_outline_generation_prompt(
                topic=research_topic,
                literature_summary=abstracts_text
            )
            return prompt
        except Exception as e:
            print(f"[WARN] ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯å¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤æç¤ºè¯: {e}")
            
            # å›é€€åˆ°é»˜è®¤æç¤ºè¯
            actual_total_count = len(abstracts)
            prompt = f"""
# ä»»åŠ¡ï¼šç”ŸæˆåŒ»å­¦æ–‡çŒ®ç»¼è¿°å†™ä½œå¤§çº²

## 1. è§’è‰²ä¸ç›®æ ‡
ä½ å°†æ‰®æ¼”ä¸€ä½ **åŒ»å­¦æ–‡çŒ®ç»“æ„åŒ–æç‚¼ä¸è§„åˆ’å¸ˆ**ï¼Œä½ çš„æ ¸å¿ƒç›®æ ‡æ˜¯åŸºäºæä¾›çš„{actual_total_count}ç¯‡åŒ»å­¦æ–‡çŒ®æ‘˜è¦å’ŒåŸå§‹æ£€ç´¢ä¸»é¢˜ï¼Œæ„å»ºä¸€ä»½ç»“æ„å®Œæ•´ã€é€»è¾‘æ¸…æ™°çš„ä¸­æ–‡ç»¼è¿°å†™ä½œå¤§çº²ï¼Œå¹¶ä¸ºæ¯ä¸ªéƒ¨åˆ†è§„åˆ’åˆç†çš„å­—æ•°ã€‚

## 2. èƒŒæ™¯ä¸ä¸Šä¸‹æ–‡
- **æ ¸å¿ƒä¸»é¢˜**: {research_topic}
- **æ–‡çŒ®æ•°é‡**: {actual_total_count}ç¯‡
- **åˆ†ææ·±åº¦**: åŸºäºæ‘˜è¦å†…å®¹è¿›è¡Œç»“æ„åŒ–åˆ†æ

## 3. å…³é”®æ­¥éª¤
1. **ä¸»é¢˜åˆ†æä¸æç‚¼**: æ·±å…¥åˆ†ææ–‡çŒ®æ‘˜è¦ä¸­çš„æ‰€æœ‰å†…å®¹
2. **ç»“æ„æ„å»ºä¸æ’åº**: ä»¥æ ¸å¿ƒä¸»é¢˜ä¸ºä¸­å¿ƒä¸»çº¿ç»„ç»‡å†…å®¹
3. **å®Œæ•´å¤§çº²è§„åˆ’**: åŒ…å«å¼•è¨€ã€ä¸»ä½“ã€ç»“è®ºçš„å®Œæ•´æ¡†æ¶
4. **å­—æ•°æƒé‡åˆ†é…**: æ ¹æ®å†…å®¹é‡è¦æ€§åˆ†é…åˆç†å­—æ•°

## 4. è¾“å‡ºè¦æ±‚
- **æ ¼å¼**: Markdownå±‚çº§åˆ—è¡¨
- **é£æ ¼**: ä¸“ä¸šã€å­¦æœ¯ã€ç®€æ´
- **å­—æ•°èŒƒå›´**: å»ºè®®æ€»å­—æ•°3000-8000å­—
- **ç»“æ„è¦æ±‚**: å¿…é¡»åŒ…å«å¼•è¨€ã€æ ¸å¿ƒä¸»ä½“ã€ç»“è®ºä¸å±•æœ›
- **å­—æ•°æ ‡æ³¨**: æ¯ä¸ªéƒ¨åˆ†åå¿…é¡»æ ‡æ³¨å»ºè®®å­—æ•°

## 5. æ–‡çŒ®æ‘˜è¦å†…å®¹
{abstracts_text}

è¯·åŸºäºä»¥ä¸Šå†…å®¹ç”Ÿæˆç»“æ„åŒ–çš„å¤§çº²ã€‚
"""
            return prompt
    
    def _generate_outline_with_ai(self, abstracts: List[str], research_topic: str) -> str:
        """å…¼å®¹æ€§æ–¹æ³•"""
        return self._generate_outline_with_ai_optimized(abstracts, research_topic)
    
    def _build_outline_prompt(self, abstracts: List[str], research_topic: str) -> str:
        """æ„å»ºAIæç¤ºè¯"""
        
        # å¤„ç†æ‰€æœ‰æ‘˜è¦ï¼Œä¸è®¾ä¸Šé™
        abstracts_text = "\n\n".join([f"æ‘˜è¦{i+1}: {abstract}" for i, abstract in enumerate(abstracts)])
        
        prompt = f"""
# ä»»åŠ¡ï¼šç”ŸæˆåŒ»å­¦æ–‡çŒ®ç»¼è¿°å†™ä½œå¤§çº²

## 1. è§’è‰²ä¸ç›®æ ‡
ä½ å°†æ‰®æ¼”ä¸€ä½ **åŒ»å­¦æ–‡çŒ®ç»“æ„åŒ–æç‚¼ä¸è§„åˆ’å¸ˆ**ï¼Œä½ çš„æ ¸å¿ƒç›®æ ‡æ˜¯åŸºäºæä¾›çš„{len(abstracts)}ç¯‡åŒ»å­¦æ–‡çŒ®æ‘˜è¦å’ŒåŸå§‹æ£€ç´¢ä¸»é¢˜ï¼Œæ„å»ºä¸€ä»½ç»“æ„å®Œæ•´ã€é€»è¾‘æ¸…æ™°çš„ä¸­æ–‡ç»¼è¿°å†™ä½œå¤§çº²ï¼Œå¹¶ä¸ºæ¯ä¸ªéƒ¨åˆ†è§„åˆ’åˆç†çš„å­—æ•°ã€‚

## 2. èƒŒæ™¯ä¸ä¸Šä¸‹æ–‡
ä½ å°†æ”¶åˆ°ä¸¤ä»½å…³é”®ä¿¡æ¯ï¼š
1. **æ–‡çŒ®æ‘˜è¦**: {len(abstracts)}ç¯‡åŒ»å­¦æ–‡çŒ®æ‘˜è¦çš„åˆå¹¶å†…å®¹ï¼Œè¿™æ˜¯ä½ åˆ†æçš„æ ¸å¿ƒææ–™ã€‚
2. **æ ¸å¿ƒä¸»é¢˜**: ç”¨æˆ·çš„åŸå§‹æ£€ç´¢ä¸»é¢˜ï¼Œè¿™æ˜¯ç»¼è¿°éœ€è¦å›´ç»•çš„æ ¸å¿ƒä¸»çº¿ã€‚

## 3. å…³é”®æ­¥éª¤
åœ¨ä½ çš„åˆ›ä½œè¿‡ç¨‹ä¸­ï¼Œè¯·éµå¾ªä»¥ä¸‹å†…éƒ¨æ­¥éª¤æ¥æ„æ€å’Œæ‰“ç£¨ä½œå“ï¼š
1. **ä¸»é¢˜åˆ†æä¸æç‚¼**: æ·±å…¥åˆ†ææ–‡çŒ®æ‘˜è¦ä¸­çš„æ‰€æœ‰å†…å®¹ã€‚è¯†åˆ«å¹¶æç‚¼å‡ºåå¤å‡ºç°çš„æ ¸å¿ƒè®®é¢˜ã€å…³é”®å‘ç°ã€ç ”ç©¶æ–¹æ³•æˆ–äº‰è®®ç‚¹ã€‚è¿™äº›å°†æ„æˆç»¼è¿°çš„æ ¸å¿ƒä¸»ä½“éƒ¨åˆ†ã€‚
2. **ç»“æ„æ„å»ºä¸æ’åº**: ä»¥æ ¸å¿ƒä¸»é¢˜ä¸ºä¸­å¿ƒä¸»çº¿ï¼Œå°†ä¸Šä¸€æ­¥æç‚¼å‡ºçš„æ ¸å¿ƒè®®é¢˜ç»„ç»‡æˆä¸€ä¸ªé€»è¾‘è¿è´¯çš„åºåˆ—ã€‚è®¾è®¡å‡ºèƒ½å¤Ÿåæ˜ å†…å®¹å†…åœ¨è”ç³»ï¼ˆå¦‚ï¼šä»é—®é¢˜åˆ°è§£å†³æ–¹æ¡ˆï¼Œä»åŸºç¡€åˆ°åº”ç”¨ï¼‰çš„ä¸»ä½“éƒ¨åˆ†æ ‡é¢˜ã€‚
3. **å®Œæ•´å¤§çº²è§„åˆ’**: åœ¨æ ¸å¿ƒä¸»ä½“éƒ¨åˆ†å‰åï¼Œåˆ†åˆ«åŠ å…¥æ ‡å‡†çš„"å¼•è¨€"å’Œ"ç»“è®ºä¸å±•æœ›"ï¼ˆæˆ–"æ€»ç»“"ã€"è®¨è®ºä¸ç»“è®º"ç­‰ï¼‰éƒ¨åˆ†ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„ç»¼è¿°æ¡†æ¶ã€‚ç¡®ä¿å¼•è¨€èƒ½æ¦‚è¿°èƒŒæ™¯å’Œç›®çš„ï¼Œç»“è®ºèƒ½æ€»ç»“è¦ç‚¹å¹¶æå‡ºæœªæ¥æ–¹å‘ã€‚
4. **å­—æ•°æƒé‡åˆ†é…**: è¯„ä¼°å¤§çº²ä¸­æ¯ä¸ªéƒ¨åˆ†ï¼ˆå¼•è¨€ã€å„ä¸»ä½“éƒ¨åˆ†ã€ç»“è®ºï¼‰çš„å†…å®¹æ‰¿è½½é‡å’Œé‡è¦æ€§ã€‚æ ¹æ®å…¶æƒé‡å’Œç»¼è¿°çš„å®é™…éœ€è¦ï¼Œä¸ºæ¯ä¸ªéƒ¨åˆ†åˆ†é…åˆç†çš„å»ºè®®å­—æ•°ï¼Œä»¥æŒ‡å¯¼åç»­çš„å†™ä½œã€‚

## 4. è¾“å‡ºè¦æ±‚
- **æ ¼å¼**: Markdownå±‚çº§åˆ—è¡¨ã€‚
- **é£æ ¼**: ä¸“ä¸šã€å­¦æœ¯ã€ç®€æ´ã€‚
- **çº¦æŸ**:
    - å¤§çº²å¿…é¡»åŒ…å«å¼•è¨€ã€æ ¸å¿ƒä¸»ä½“ï¼ˆå¯å¤šéƒ¨åˆ†ï¼‰ã€ç»“è®ºä¸å±•æœ›ã€‚
    - æ ¸å¿ƒä¸»ä½“çš„æ ‡é¢˜å’Œç»“æ„å¿…é¡»ç›´æ¥æºè‡ªå¯¹æ–‡çŒ®æ‘˜è¦çš„åˆ†æç»“æœï¼Œå¹¶å›´ç»•æ ¸å¿ƒä¸»é¢˜å±•å¼€ã€‚
    - æ¯ä¸ªæ ‡é¢˜åå¿…é¡»ç´§è·Ÿæ‹¬å·ï¼Œæ³¨æ˜å»ºè®®å­—æ•°ï¼Œæ ¼å¼ä¸º `(å»ºè®®çº¦ XXX å­—)`ã€‚
    - æ ¹æ®ä¸»é¢˜çš„å¤æ‚ç¨‹åº¦å’Œæ–‡çŒ®å†…å®¹çš„ä¸°å¯Œæ€§ï¼ŒAIè‡ªä¸»å†³å®šåˆé€‚çš„æ€»å­—æ•°å’Œå„éƒ¨åˆ†å­—æ•°åˆ†é…ã€‚
    - **æœ€ç»ˆè¾“å‡º**: ä½ çš„æœ€ç»ˆå›å¤åº”ä»…åŒ…å«ç”Ÿæˆçš„å¤§çº²æœ¬èº«ã€‚ç»å¯¹ç¦æ­¢åŒ…å«ä»»ä½•å¼•å¯¼è¯­ã€è§£é‡Šã€ç†ç”±ã€åˆ†ææˆ–å…¶ä»–éå¤§çº²å†…å®¹ã€‚ç›´æ¥ä»"å¼•è¨€"å¼€å§‹è¾“å‡ºã€‚

## 5. åˆ†æææ–™

**æ ¸å¿ƒä¸»é¢˜**: {research_topic}

**æ–‡çŒ®æ‘˜è¦å†…å®¹**:
{abstracts_text}

è¯·åŸºäºä»¥ä¸Šææ–™ï¼Œç”Ÿæˆç»“æ„åŒ–çš„ç»¼è¿°å¤§çº²ã€‚
"""
        
        return prompt
    
    def _generate_basic_outline(self, research_topic: str) -> str:
        """ç”ŸæˆåŸºç¡€å¤§çº²æ¨¡æ¿ï¼ˆAIå¤±è´¥æ—¶çš„åå¤‡æ–¹æ¡ˆï¼‰"""
        
        outline = f"""## å¼•è¨€ (å»ºè®®çº¦ 800 å­—)

## {research_topic}çš„ç ”ç©¶ç°çŠ¶ (å»ºè®®çº¦ 1500 å­—)

## {research_topic}çš„ä¸»è¦æ–¹æ³•ä¸æŠ€æœ¯ (å»ºè®®çº¦ 1500 å­—)

## {research_topic}çš„ä¸´åºŠåº”ç”¨ä¸æ•ˆæœ (å»ºè®®çº¦ 1200 å­—)

## ç»“è®ºä¸å±•æœ› (å»ºè®®çº¦ 600 å­—)
"""
        
        return outline
    
    def save_outline(self, outline: str, output_file: str):
        """ä¿å­˜å¤§çº²åˆ°æ–‡ä»¶"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(outline)
            print(f"å¤§çº²å·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"ä¿å­˜å¤§çº²å¤±è´¥: {e}")
    
    def get_performance_report(self) -> Dict:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        cache_stats = self.outline_cache.get_stats() if hasattr(self, 'outline_cache') else {}
        
        return {
            'total_outlines_generated': self.performance_stats['total_outlines_generated'],
            'total_generation_time': self.performance_stats['total_generation_time'],
            'average_generation_time': self.performance_stats['total_generation_time'] / max(self.performance_stats['total_outlines_generated'], 1),
            'cache_hits': self.performance_stats['cache_hits'],
            'parallel_batches': self.performance_stats['parallel_batches'],
            'abstracts_processed': self.performance_stats['abstracts_processed'],
            'ai_calls': self.performance_stats['ai_calls'],
            'errors': self.performance_stats['errors'],
            'retries': self.performance_stats['retries'],
            'cache_stats': cache_stats
        }
    
    def print_performance_report(self):
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        report = self.get_performance_report()
        
        print("\n=== å¤§çº²ç”Ÿæˆå™¨æ€§èƒ½æŠ¥å‘Š ===")
        print(f"ç”Ÿæˆå¤§çº²æ€»æ•°: {report['total_outlines_generated']}")
        print(f"æ€»ç”Ÿæˆæ—¶é—´: {report['total_generation_time']:.2f}ç§’")
        print(f"å¹³å‡ç”Ÿæˆæ—¶é—´: {report['average_generation_time']:.2f}ç§’/ä¸ª")
        print(f"ç¼“å­˜å‘½ä¸­æ¬¡æ•°: {report['cache_hits']}")
        print(f"å¹¶è¡Œå¤„ç†æ‰¹æ¬¡æ•°: {report['parallel_batches']}")
        print(f"å¤„ç†æ‘˜è¦æ€»æ•°: {report['abstracts_processed']}")
        print(f"AIè°ƒç”¨æ¬¡æ•°: {report['ai_calls']}")
        print(f"é”™è¯¯æ¬¡æ•°: {report['errors']}")
        print(f"é‡è¯•æ¬¡æ•°: {report['retries']}")
        
        if 'cache_stats' in report:
            cache_stats = report['cache_stats']
            print(f"ç¼“å­˜å¤§å°: {cache_stats['cache_size']}/{cache_stats['max_cache_size']}")
            print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:.2%}")
        
        print("=" * 30)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†ç¼“å­˜
            if hasattr(self, 'outline_cache'):
                self.outline_cache.cache.clear()
                self.outline_cache.access_times.clear()
            
            # æ‰“å°æ€§èƒ½æŠ¥å‘Š
            if self.performance_stats['total_outlines_generated'] > 0:
                self.print_performance_report()
                
        except Exception as e:
            print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='åŒ»å­¦æ–‡çŒ®ç»¼è¿°å¤§çº²ç”Ÿæˆå™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python review_outline_generator.py -f literature.json -t "ç³–å°¿ç—…æ²»ç–—" -w 8000
  python review_outline_generator.py -f literature.json -t "COVID-19ç–«è‹—" -w 6000 -o outline.md
        """
    )
    
    parser.add_argument('-f', '--file', required=True, help='æ–‡çŒ®JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-t', '--topic', required=True, help='ç ”ç©¶ä¸»é¢˜')
    parser.add_argument('-w', '--words', type=int, default=8000, help='ç›®æ ‡æ€»å­—æ•° (é»˜è®¤: 8000)')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨ç”Ÿæˆ)')
    parser.add_argument('--ai-config', help='æŒ‡å®šAIé…ç½®åç§°')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        generator = ReviewOutlineGenerator(args.ai_config)
        
        # ç”Ÿæˆå¤§çº²
        print(f"æ­£åœ¨åŸºäºæ–‡çŒ® '{args.file}' ç”Ÿæˆä¸»é¢˜ä¸º '{args.topic}' çš„ç»¼è¿°å¤§çº²...")
        outline = generator.generate_outline_from_json(args.file, args.topic, args.words)
        
        # è¾“å‡ºç»“æœ
        if args.output:
            generator.save_outline(outline, args.output)
        else:
            # ç”Ÿæˆé»˜è®¤æ–‡ä»¶åå’Œè·¯å¾„
            import re
            import os
            from datetime import datetime
            safe_topic = re.sub(r'[^\w\s-]', '', args.topic).replace(' ', '_')
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            outline_filename = f"ç»¼è¿°å¤§çº²â€”{safe_topic}-{timestamp}.md"
            output_file = os.path.join("ç»¼è¿°å¤§çº²", outline_filename)
            generator.save_outline(outline, output_file)
        
        print("\nç”Ÿæˆçš„å¤§çº²:")
        print("=" * 60)
        print(outline)
        
    except Exception as e:
        print(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {e}")


if __name__ == "__main__":
    main()