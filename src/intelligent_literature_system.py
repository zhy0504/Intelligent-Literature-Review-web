#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ä¸ç»¼è¿°ç”Ÿæˆç³»ç»Ÿ - ä¸»ç¨‹åºå…¥å£ v2.0
å®Œæ•´å·¥ä½œæµç¨‹ï¼šç”¨æˆ·è¾“å…¥ â†’ æ„å›¾åˆ†æ â†’ æ–‡çŒ®æ£€ç´¢ â†’ æ™ºèƒ½ç­›é€‰ â†’ å¤§çº²ç”Ÿæˆ â†’ æ–‡ç« ç”Ÿæˆ
ä¼˜åŒ–ç‰¹æ€§ï¼šå¹¶è¡Œåˆå§‹åŒ–ã€æ™ºèƒ½ç¼“å­˜ã€æ–­ç‚¹ç»­ä¼ ã€æ€§èƒ½ç›‘æ§ã€é”™è¯¯æ¢å¤
"""

import os
import sys
import json
import argparse
import time
import asyncio
import threading
import traceback
from datetime import datetime
from typing import Dict, List, Optional, Any, Union
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd

# å¯¼å…¥æ‰€æœ‰åŠŸèƒ½æ¨¡å—
from intent_analyzer import IntentAnalyzer, SearchCriteria
from pubmed_search import PubMedSearcher
from literature_filter import LiteratureFilter, FilterConfig, JournalInfoCache
from review_outline_generator import ReviewOutlineGenerator
from medical_review_generator import MedicalReviewGenerator
from data_processor import JournalDataProcessor


class SystemCleaner:
    """ç³»ç»Ÿæ¸…ç†å™¨ - å¯åŠ¨æ—¶æ¸…ç†æ®‹ç•™æ–‡ä»¶"""
    
    @staticmethod
    def cleanup_on_startup(verbose: bool = True):
        """å¯åŠ¨æ—¶æ¸…ç†æ®‹ç•™æ–‡ä»¶"""
        cleanup_patterns = [
            "system_state.json",           # çŠ¶æ€æ–‡ä»¶
            "temp_literature_*.json",      # ä¸´æ—¶æ–‡çŒ®æ–‡ä»¶
            "temp_outline_*.md",           # ä¸´æ—¶å¤§çº²æ–‡ä»¶
            "temp_*.json",                 # å…¶ä»–ä¸´æ—¶jsonæ–‡ä»¶
            "temp_*.md",                   # å…¶ä»–ä¸´æ—¶markdownæ–‡ä»¶
            "*.cache",                     # ç¼“å­˜æ–‡ä»¶
        ]
        
        cleaned_files = []
        
        try:
            # è·å–å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
            current_dir = Path(".")
            
            for pattern in cleanup_patterns:
                # ä½¿ç”¨globåŒ¹é…æ–‡ä»¶æ¨¡å¼
                matching_files = list(current_dir.glob(pattern))
                
                for file_path in matching_files:
                    try:
                        if file_path.exists() and file_path.is_file():
                            file_path.unlink()  # åˆ é™¤æ–‡ä»¶
                            cleaned_files.append(str(file_path))
                            if verbose:
                                print(f"[CLEANUP] æ¸…ç†æ®‹ç•™æ–‡ä»¶: {file_path}")
                    except Exception as e:
                        if verbose:
                            print(f"[WARN] æ¸…ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
            if cleaned_files and verbose:
                print(f"[OK] å¯åŠ¨æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {len(cleaned_files)} ä¸ªæ®‹ç•™æ–‡ä»¶")
            elif verbose:
                print("[OK] å¯åŠ¨æ£€æŸ¥å®Œæˆï¼Œæ— éœ€æ¸…ç†æ®‹ç•™æ–‡ä»¶")
                
        except Exception as e:
            if verbose:
                print(f"[WARN] å¯åŠ¨æ¸…ç†è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {e}")
        
        return cleaned_files
    
    @staticmethod
    def manual_cleanup(verbose: bool = True):
        """æ‰‹åŠ¨å…¨é¢æ¸…ç† - åŒ…æ‹¬ç¼“å­˜å’ŒçŠ¶æ€"""
        try:
            # é¦–å…ˆè°ƒç”¨å¯åŠ¨æ¸…ç†
            cleaned_files = SystemCleaner.cleanup_on_startup(verbose=False)
            
            # é¢å¤–æ¸…ç†ç¼“å­˜ç›®å½•
            cache_dir = Path("./cache")
            if cache_dir.exists():
                cache_files = list(cache_dir.glob("*.cache"))
                for cache_file in cache_files:
                    try:
                        cache_file.unlink()
                        cleaned_files.append(str(cache_file))
                        if verbose:
                            print(f"[CLEANUP] æ¸…ç†ç¼“å­˜æ–‡ä»¶: {cache_file}")
                    except Exception as e:
                        if verbose:
                            print(f"[WARN] æ¸…ç†ç¼“å­˜æ–‡ä»¶å¤±è´¥ {cache_file}: {e}")
            
            # æ¸…ç†AIæ¨¡å‹ç¼“å­˜
            ai_cache_file = Path("ai_model_cache.json")
            if ai_cache_file.exists():
                try:
                    ai_cache_file.unlink()
                    cleaned_files.append(str(ai_cache_file))
                    if verbose:
                        print(f"[CLEANUP] æ¸…ç†AIæ¨¡å‹ç¼“å­˜: {ai_cache_file}")
                except Exception as e:
                    if verbose:
                        print(f"[WARN] æ¸…ç†AIæ¨¡å‹ç¼“å­˜å¤±è´¥: {e}")
            
            if verbose:
                print(f"[OK] æ‰‹åŠ¨æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {len(cleaned_files)} ä¸ªæ–‡ä»¶")
            
            return cleaned_files
            
        except Exception as e:
            if verbose:
                print(f"[ERROR] æ‰‹åŠ¨æ¸…ç†å¤±è´¥: {e}")
            return []


class SystemError(Exception):
    """ç³»ç»Ÿé”™è¯¯å¼‚å¸¸ç±»"""
    def __init__(self, component: str, error_type: str, message: str, solution: str = None):
        self.component = component
        self.error_type = error_type
        self.message = message
        self.solution = solution
        super().__init__(f"[{component}] {error_type}: {message}")


class PerformanceMonitor:
    """ä¼˜åŒ–çš„æ€§èƒ½ç›‘æ§å™¨ - åŒºåˆ†ä¸²è¡Œå’Œå¹¶è¡Œæ“ä½œ"""
    def __init__(self):
        self.metrics = {}
        self.start_times = {}
        self.operation_counts = {}
        # åŒºåˆ†å¹¶è¡Œå’Œä¸²è¡Œæ“ä½œ
        self.parallel_operations = set()  # å¹¶è¡Œæ“ä½œé›†åˆ
        self.workflow_operations = {'å®Œæ•´å·¥ä½œæµç¨‹'}  # å·¥ä½œæµç¨‹æ“ä½œ
        self.component_operations = {'ç»„ä»¶åˆå§‹åŒ–'}  # ç»„ä»¶åˆå§‹åŒ–æ“ä½œ
    
    def start_timing(self, operation: str, is_parallel: bool = False):
        """
        å¼€å§‹è®¡æ—¶
        
        Args:
            operation: æ“ä½œåç§°
            is_parallel: æ˜¯å¦ä¸ºå¹¶è¡Œæ“ä½œ
        """
        self.start_times[operation] = time.time()
        self.operation_counts[operation] = self.operation_counts.get(operation, 0) + 1
        
        if is_parallel:
            self.parallel_operations.add(operation)
    
    def end_timing(self, operation: str) -> float:
        """ç»“æŸè®¡æ—¶å¹¶è¿”å›è€—æ—¶"""
        if operation in self.start_times:
            duration = time.time() - self.start_times[operation]
            self.metrics[operation] = self.metrics.get(operation, 0) + duration
            del self.start_times[operation]
            return duration
        return 0.0
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–çš„æ€§èƒ½æŠ¥å‘Š"""
        # åˆ†ç±»æ“ä½œ
        workflow_metrics = {op: time for op, time in self.metrics.items() 
                          if op in self.workflow_operations}
        component_metrics = {op: time for op, time in self.metrics.items() 
                           if op in self.component_operations}
        serial_metrics = {op: time for op, time in self.metrics.items() 
                         if op not in self.workflow_operations 
                         and op not in self.component_operations
                         and op not in self.parallel_operations}
        parallel_metrics = {op: time for op, time in self.metrics.items() 
                          if op in self.parallel_operations}
        
        # è®¡ç®—ä¸åŒç±»å‹çš„æ€»æ—¶é—´
        serial_total = sum(serial_metrics.values())
        parallel_total = max(parallel_metrics.values()) if parallel_metrics else 0
        actual_workflow_time = sum(workflow_metrics.values())
        
        return {
            'actual_total_time': actual_workflow_time,  # å®é™…æ€»æ—¶é—´ï¼ˆå¢™é’Ÿæ—¶é—´ï¼‰
            'serial_total_time': serial_total,          # ä¸²è¡Œæ“ä½œæ€»æ—¶é—´
            'parallel_total_time': parallel_total,      # å¹¶è¡Œæ“ä½œæœ€å¤§æ—¶é—´
            'operation_times': self.metrics,
            'operation_counts': self.operation_counts,
            'operation_categories': {
                'workflow': list(workflow_metrics.keys()),
                'serial': list(serial_metrics.keys()),
                'parallel': list(parallel_metrics.keys()),
                'component': list(component_metrics.keys())
            },
            'average_times': {op: self.metrics[op] / self.operation_counts[op] 
                            for op in self.metrics if op in self.operation_counts},
            'bottlenecks': self._identify_bottlenecks()
        }
    
    def _identify_bottlenecks(self) -> List[str]:
        """è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ - æ’é™¤å·¥ä½œæµç¨‹æ€»æ—¶é—´"""
        if not self.metrics:
            return []
        
        # æ’é™¤å·¥ä½œæµç¨‹æ“ä½œï¼Œåªåˆ†æå…·ä½“ä¸šåŠ¡æ“ä½œ
        filtered_times = {op: self.metrics[op] / self.operation_counts[op] 
                         for op in self.metrics 
                         if op in self.operation_counts 
                         and op not in self.workflow_operations}
        
        if not filtered_times:
            return []
        
        # æ‰¾å‡ºè€—æ—¶æœ€é•¿çš„æ“ä½œä½œä¸ºç“¶é¢ˆ
        sorted_operations = sorted(filtered_times.items(), key=lambda x: x[1], reverse=True)
        
        # å–å‰é¢å ç”¨æ—¶é—´è¾ƒå¤šçš„æ“ä½œä½œä¸ºç“¶é¢ˆ
        if len(sorted_operations) >= 2:
            return [op for op, _ in sorted_operations[:2]]
        elif sorted_operations:
            return [sorted_operations[0][0]]
        else:
            return []


class StateManager:
    """çŠ¶æ€ç®¡ç†å™¨ - æ”¯æŒæ–­ç‚¹ç»­ä¼ """
    def __init__(self, state_file: str = "system_state.json"):
        self.state_file = Path(state_file)
        self.current_state = {}
        self.lock = threading.Lock()
    
    def save_state(self, state_data: Dict):
        """ä¿å­˜å½“å‰çŠ¶æ€"""
        with self.lock:
            self.current_state.update(state_data)
            self.current_state['timestamp'] = datetime.now().isoformat()
            
            try:
                with open(self.state_file, 'w', encoding='utf-8') as f:
                    json.dump(self.current_state, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"çŠ¶æ€ä¿å­˜å¤±è´¥: {e}")
    
    def load_state(self) -> Dict:
        """åŠ è½½ä¹‹å‰çš„çŠ¶æ€"""
        with self.lock:
            if self.state_file.exists():
                try:
                    with open(self.state_file, 'r', encoding='utf-8') as f:
                        self.current_state = json.load(f)
                except Exception as e:
                    print(f"çŠ¶æ€åŠ è½½å¤±è´¥: {e}")
                    self.current_state = {}
            return self.current_state.copy()
    
    def can_resume(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¢å¤"""
        state = self.load_state()
        return len(state) > 0 and state.get('processing', False)
    
    def clear_state(self):
        """æ¸…é™¤çŠ¶æ€"""
        with self.lock:
            self.current_state = {}
            if self.state_file.exists():
                self.state_file.unlink()


class IntelligentCache:
    """æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ"""
    def __init__(self, cache_dir: str = "./cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.search_cache = {}
        self.ai_response_cache = {}
        self.cache_ttl = 3600  # 1å°æ—¶ç¼“å­˜
    
    def get_cached_search(self, query: str, max_results: int) -> Optional[Dict]:
        """è·å–ç¼“å­˜çš„æœç´¢ç»“æœ"""
        cache_key = f"{query}_{max_results}"
        if cache_key in self.search_cache:
            cache_data = self.search_cache[cache_key]
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            cache_time = datetime.fromisoformat(cache_data['timestamp'])
            if (datetime.now() - cache_time).total_seconds() < self.cache_ttl:
                return cache_data
            else:
                del self.search_cache[cache_key]
        return None
    
    def cache_search_result(self, query: str, max_results: int, results: List):
        """ç¼“å­˜æœç´¢ç»“æœ"""
        cache_key = f"{query}_{max_results}"
        self.search_cache[cache_key] = {
            'results': results,
            'timestamp': datetime.now().isoformat(),
            'count': len(results)
        }
    
    def get_cached_ai_response(self, prompt_hash: str) -> Optional[str]:
        """è·å–ç¼“å­˜çš„AIå“åº”"""
        cached_data = self.ai_response_cache.get(prompt_hash)
        
        if cached_data and isinstance(cached_data, dict):
            response = cached_data.get('response')
            return response
        elif cached_data is not None:
            return cached_data
        
        return None
    
    def cache_ai_response(self, prompt_hash: str, response: str):
        """ç¼“å­˜AIå“åº”"""
        self.ai_response_cache[prompt_hash] = {
            'response': response,
            'timestamp': datetime.now().isoformat()
        }
    
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        self.search_cache.clear()
        self.ai_response_cache.clear()
        for cache_file in self.cache_dir.glob("*.cache"):
            cache_file.unlink()


class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""
    def __init__(self, total_steps: int, description: str = "ç³»ç»Ÿå¤„ç†"):
        self.total_steps = total_steps
        self.current_step = 0
        self.description = description
        self.start_time = time.time()
        self.step_times = {}
        # è€ç‹ç‰¹è‰²ï¼šå¯åŠ¨åŠ¨ç”»
        self._show_startup_animation(description)

    def _show_startup_animation(self, description: str):
        """æ˜¾ç¤ºè€ç‹ç‰Œå¯åŠ¨åŠ¨ç”»"""
        import sys
        animation_chars = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
        print(f"\nğŸ”¥ {description} å¯åŠ¨ä¸­", end="", flush=True)

        for i in range(10):
            print(f" {animation_chars[i % len(animation_chars)]}", end="", flush=True)
            time.sleep(0.1)
            print("\b" * 2, end="", flush=True)

        print(" âœ… å¯åŠ¨å®Œæˆ!")
        print("=" * 60)
    
    def update_progress_only(self, step_name: str, status: str, progress: float):
        """ä»…æ›´æ–°è¿›åº¦ï¼Œä¸é€’å¢æ­¥éª¤è®¡æ•°ï¼ˆç”¨äºæ‰¹å¤„ç†è¿‡ç¨‹ï¼‰"""
        elapsed = time.time() - self.start_time
        progress_bar = self._generate_progress_bar(progress)

        # è®¡ç®—é€Ÿåº¦å’Œå‰©ä½™æ—¶é—´ä¼°ç®—
        speed_info = self._calculate_speed_info(progress, elapsed)

        # ç¾åŒ–çš„è¿›åº¦æ˜¾ç¤º - è€ç‹é£æ ¼
        print(f"ğŸ”¥ [{self.current_step}/{self.total_steps}] {step_name}: {status}")
        print(f"   {progress_bar}")
        print(f"   â±ï¸  ç”¨æ—¶: {elapsed:.1f}s | {speed_info}")
    
    def update(self, step_name: str, status: str = "å¤„ç†ä¸­", progress: float = None, increment_step: bool = True):
        """æ›´æ–°è¿›åº¦"""
        if increment_step:
            self.current_step += 1
        elapsed = time.time() - self.start_time
        self.step_times[step_name] = elapsed

        # å¦‚æœæä¾›äº†å…·ä½“çš„è¿›åº¦å€¼ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨æ­¥éª¤è¿›åº¦
        if progress is not None:
            display_progress = progress
        else:
            display_progress = (self.current_step / self.total_steps) * 100

        progress_bar = self._generate_progress_bar(display_progress)

        # è®¡ç®—é€Ÿåº¦å’Œå‰©ä½™æ—¶é—´ä¼°ç®—
        speed_info = self._calculate_speed_info(display_progress, elapsed)

        # ç¾åŒ–çš„è¿›åº¦æ˜¾ç¤º - è€ç‹é£æ ¼
        print(f"ğŸ¯ [{self.current_step}/{self.total_steps}] {step_name}: {status}")
        print(f"   {progress_bar}")
        print(f"   â±ï¸  ç”¨æ—¶: {elapsed:.1f}s | {speed_info}")

        if self.current_step == self.total_steps and increment_step:
            print(f"\nğŸ‰ {self.description}å®Œæˆï¼æ€»ç”¨æ—¶: {elapsed:.1f}s")
            print("=" * 60)
    
    def _generate_progress_bar(self, percentage: float, width: int = 40) -> str:
        """ç”Ÿæˆç‰›é€¼çš„ç¾åŒ–è¿›åº¦æ¡ - è€ç‹å‡ºå“å¿…å±ç²¾å“"""
        # ç¡®ä¿ç™¾åˆ†æ¯”åœ¨æœ‰æ•ˆèŒƒå›´å†…
        percentage = max(0, min(100, percentage))

        # è®¡ç®—å¡«å……çš„è¿›åº¦æ¡å—æ•°
        filled = int(width * percentage / 100)

        # å¤šç§è¿›åº¦æ¡æ ·å¼ - è€ç‹ç»™ä½ æ•´ç‚¹èŠ±æ´»
        styles = {
            'gradient': [' ', 'â–‘', 'â–’', 'â–“', 'â–ˆ'],  # æ¸å˜æ–¹å—
            'arrows': ['â†', 'â†–', 'â†‘', 'â†—', 'â†’'],   # ç®­å¤´æ–¹å‘
            'circles': ['â—‹', 'â—”', 'â—‘', 'â—•', 'â—'],   # åœ†ç‚¹å¡«å……
            'blocks': ['â–¡', 'â–«', 'â–ª', 'â– '],         # æ–¹å—æ ·å¼
            'stars': ['â˜†', 'â˜†', 'â˜…'],               # æ˜Ÿæ˜Ÿæ ·å¼
        }

        # é€‰æ‹©æ ·å¼ - æ ¹æ®è¿›åº¦é˜¶æ®µè‡ªåŠ¨åˆ‡æ¢
        if percentage < 25:
            style_name = 'circles'
        elif percentage < 50:
            style_name = 'gradient'
        elif percentage < 75:
            style_name = 'blocks'
        else:
            style_name = 'stars'

        current_style = styles[style_name]

        # æ„å»ºè¿›åº¦æ¡ä¸»ä½“
        bar_parts = []

        # æ·»åŠ èµ·å§‹æ ‡è®°
        bar_parts.append('ğŸš€')

        # æ„å»ºè¿›åº¦æ¡å†…å®¹
        for i in range(width):
            if i < filled:
                # æ ¹æ®ä½ç½®é€‰æ‹©æ ·å¼å­—ç¬¦
                style_index = min(int((i / width) * len(current_style)), len(current_style) - 1)
                bar_parts.append(current_style[style_index])
            else:
                # ç©ºç™½éƒ¨åˆ†ä½¿ç”¨æµ…è‰²å­—ç¬¦
                bar_parts.append('Â·')

        # æ·»åŠ ç»“æŸæ ‡è®°
        bar_parts.append('ğŸ¯')

        # ç»„åˆè¿›åº¦æ¡
        bar = ''.join(bar_parts)

        # æ·»åŠ ç™¾åˆ†æ¯”æ˜¾ç¤ºå’Œè£…é¥°
        if percentage < 10:
            percent_str = f"  {percentage:.1f}%"
        elif percentage < 100:
            percent_str = f" {percentage:.1f}%"
        else:
            percent_str = f"{percentage:.1f}%"

        # å½©è‰²æ”¯æŒæ£€æŸ¥
        use_color = self._supports_color()

        if use_color:
            # åº”ç”¨å½©è‰²ä»£ç 
            if percentage < 25:
                color_code = "\033[91m"  # çº¢è‰²
            elif percentage < 50:
                color_code = "\033[93m"  # é»„è‰²
            elif percentage < 75:
                color_code = "\033[94m"  # è“è‰²
            else:
                color_code = "\033[92m"  # ç»¿è‰²
            reset_code = "\033[0m"
            return f"â”¤{color_code}{bar}{reset_code}â”œ{color_code}{percent_str}{reset_code}"
        else:
            return f"â”¤{bar}â”œ{percent_str}"

    def _supports_color(self) -> bool:
        """æ£€æŸ¥ç»ˆç«¯æ˜¯å¦æ”¯æŒå½©è‰²è¾“å‡º"""
        import os
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ”¯æŒå½©è‰²çš„ç»ˆç«¯
            return (hasattr(os, 'isatty') and os.isatty(1)) or os.getenv('FORCE_COLOR') is not None
        except:
            return False

    def _calculate_speed_info(self, progress: float, elapsed: float) -> str:
        """è®¡ç®—é€Ÿåº¦ä¿¡æ¯å’Œå‰©ä½™æ—¶é—´ä¼°ç®— - è€ç‹æ™ºèƒ½ç®—æ³•"""
        if progress <= 0 or elapsed < 0.1:
            return "âš¡ å¯åŠ¨ä¸­..."

        # è®¡ç®—é€Ÿåº¦ï¼ˆæ¯ç§’è¿›åº¦ç™¾åˆ†æ¯”ï¼‰
        speed = progress / elapsed

        # è®¡ç®—å‰©ä½™æ—¶é—´ä¼°ç®—
        if speed > 0:
            remaining_progress = 100 - progress
            eta_seconds = remaining_progress / speed

            # ç¾åŒ–æ—¶é—´æ˜¾ç¤º
            if eta_seconds < 60:
                eta_str = f"{eta_seconds:.0f}ç§’"
            elif eta_seconds < 3600:
                eta_str = f"{eta_seconds/60:.1f}åˆ†é’Ÿ"
            else:
                eta_str = f"{eta_seconds/3600:.1f}å°æ—¶"

            # è®¡ç®—çŠ¶æ€æŒ‡ç¤ºå™¨
            if speed > 10:
                speed_indicator = "ğŸš€ æé€Ÿ"
                speed_desc = f"é€Ÿåº¦: {speed:.1f}%/s"
            elif speed > 5:
                speed_indicator = "âš¡ å¿«é€Ÿ"
                speed_desc = f"é€Ÿåº¦: {speed:.1f}%/s"
            elif speed > 1:
                speed_indicator = "ğŸ¢ æ­£å¸¸"
                speed_desc = f"é€Ÿåº¦: {speed:.1f}%/s"
            else:
                speed_indicator = "ğŸŒ çˆ¬è¡Œ"
                speed_desc = f"é€Ÿåº¦: {speed:.1f}%/s"

            return f"{speed_indicator} | {speed_desc} | å‰©ä½™: {eta_str}"
        else:
            return "â¸ï¸ è®¡ç®—ä¸­..."

    def get_step_time(self, step_name: str) -> float:
        """è·å–ç‰¹å®šæ­¥éª¤çš„ç”¨æ—¶"""
        return self.step_times.get(step_name, 0.0)


class SimpleOutlineGenerator:
    """ç®€å•å¤§çº²ç”Ÿæˆå™¨ - ä½œä¸ºReviewOutlineGeneratorçš„å¤‡é€‰"""
    
    def generate_outline_from_data(self, literature_data: List[Dict], research_topic: str) -> str:
        """ç”Ÿæˆç®€å•çš„å¤§çº²"""
        return f"""# {research_topic} - ç»¼è¿°å¤§çº²

## ä¸€ã€å¼•è¨€
- ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰
- ç ”ç©¶ç°çŠ¶æ¦‚è¿°
- æœ¬æ–‡ç ”ç©¶ç›®çš„

## äºŒã€ä¸»è¦ç ”ç©¶å†…å®¹
- æ ¸å¿ƒæ¦‚å¿µç•Œå®š
- ç ”ç©¶æ–¹æ³•åˆ†æ
- ä¸»è¦å‘ç°æ€»ç»“

## ä¸‰ã€è®¨è®ºä¸åˆ†æ
- ç ”ç©¶ç»“æœè§£è¯»
- ä¸ç°æœ‰ç ”ç©¶æ¯”è¾ƒ
- ç ”ç©¶å±€é™æ€§

## å››ã€ç»“è®ºä¸å±•æœ›
- ä¸»è¦ç»“è®º
- ç ”ç©¶åˆ›æ–°ç‚¹
- æœªæ¥ç ”ç©¶æ–¹å‘

## å‚è€ƒæ–‡çŒ®
- åŸºäºæä¾›çš„{len(literature_data)}ç¯‡æ–‡çŒ®
"""

class IntelligentLiteratureSystem:
    """æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ä¸ç»¼è¿°ç”Ÿæˆç³»ç»Ÿ v2.0"""
    
    def __init__(self, ai_config_name: str = None, interactive_mode: bool = True, 
                 enable_cache: bool = True, enable_state: bool = True):
        """
        åˆå§‹åŒ–ç³»ç»Ÿ
        
        Args:
            ai_config_name: AIé…ç½®åç§°
            interactive_mode: æ˜¯å¦å¯ç”¨äº¤äº’å¼æ¨¡å¼
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
            enable_state: æ˜¯å¦å¯ç”¨çŠ¶æ€ç®¡ç†
        """
        # ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨æ¸…ç†æ®‹ç•™æ–‡ä»¶
        print("æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ä¸ç»¼è¿°ç”Ÿæˆç³»ç»Ÿ v2.0")
        print("=" * 60)
        SystemCleaner.cleanup_on_startup(verbose=True)
        print("=" * 60)
        
        self.ai_config_name = ai_config_name
        self.interactive_mode = interactive_mode
        self.enable_cache = enable_cache
        self.enable_state = enable_state
        
        # åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
        self.intent_analyzer = None
        self.pubmed_searcher = None
        self.literature_filter = None
        self.outline_generator = None
        self.review_generator = None
        self.data_processor = None
        
        # ç³»ç»ŸçŠ¶æ€
        self.search_criteria = None
        self.literature_results = []
        self.filtered_results = []
        self.outline_content = ""
        
        # å¢å¼ºåŠŸèƒ½
        self.performance_monitor = PerformanceMonitor()
        self.state_manager = StateManager() if enable_state else None
        self.cache_system = IntelligentCache() if enable_cache else None
        
        # é…ç½®é€‰é¡¹
        self.chunk_size = 200  # æ•°æ®å¤„ç†å—å¤§å°
        self.batch_delay = 5.0  # æ‰¹æ¬¡é—´å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        self.max_retries = 3   # æœ€å¤§é‡è¯•æ¬¡æ•°
        
        print(f"é…ç½®: AI={ai_config_name or 'é»˜è®¤'}, äº¤äº’={interactive_mode}, ç¼“å­˜={enable_cache}, çŠ¶æ€={enable_state}")
    
    async def initialize_components(self) -> bool:
        """å¹¶è¡Œåˆå§‹åŒ–æ‰€æœ‰ç³»ç»Ÿç»„ä»¶"""
        import threading
        from queue import Queue
        
        # åˆ›å»ºçº¿ç¨‹å®‰å…¨çš„è¾“å‡ºé˜Ÿåˆ—
        output_queue = Queue()
        output_lock = threading.Lock()
        
        def safe_print(message):
            """çº¿ç¨‹å®‰å…¨çš„è¾“å‡ºå‡½æ•°"""
            with output_lock:
                print(message)
        
        print("\n[PACKAGE] æ­£åœ¨å¹¶è¡Œåˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
        
        self.performance_monitor.start_timing("ç»„ä»¶åˆå§‹åŒ–")
        progress_tracker = ProgressTracker(6, "ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–")
        
        try:
            # æ˜¾ç¤ºåˆå§‹è¿›åº¦
            safe_print("[0/6] ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–: å¼€å§‹åˆå§‹åŒ–...")
            safe_print("[..........................] 0.0% - ç”¨æ—¶: 0.0s")
            
            # å…ˆå•ç‹¬åˆå§‹åŒ–æ„å›¾åˆ†æå™¨ï¼ˆé¿å…äº¤äº’ç•Œé¢æ··ä¹±ï¼‰
            print("\n[PRIORITY] ä¼˜å…ˆåˆå§‹åŒ–äº¤äº’ç»„ä»¶...")
            intent_success = self._init_intent_analyzer_safe()
            progress_tracker.update("æ„å›¾åˆ†æå™¨", "åˆå§‹åŒ–æˆåŠŸ" if intent_success else "åˆå§‹åŒ–å¤±è´¥")
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œåˆå§‹åŒ–å…¶ä»–ç»„ä»¶
            with ThreadPoolExecutor(max_workers=5) as executor:
                # æäº¤å…¶ä»–åˆå§‹åŒ–ä»»åŠ¡ï¼ˆæ’é™¤æ„å›¾åˆ†æå™¨ï¼‰
                future_to_component = {
                    executor.submit(self._init_data_processor_safe): ("æ•°æ®å¤„ç†å™¨", safe_print),
                    executor.submit(self._init_pubmed_searcher_safe): ("PubMedæ£€ç´¢å™¨", safe_print),
                    executor.submit(self._init_literature_filter_safe): ("æ–‡çŒ®ç­›é€‰å™¨", safe_print),
                    executor.submit(self._init_outline_generator_safe): ("å¤§çº²ç”Ÿæˆå™¨", safe_print),
                    executor.submit(self._init_review_generator_safe): ("æ–‡ç« ç”Ÿæˆå™¨", safe_print)
                }
                
                results = {"æ„å›¾åˆ†æå™¨": intent_success}  # é¢„è®¾æ„å›¾åˆ†æå™¨ç»“æœ
                errors = [] if intent_success else ["æ„å›¾åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥"]
                
                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_component):
                    component_name, print_func = future_to_component[future]
                    try:
                        result = future.result()
                        results[component_name] = result
                        progress_tracker.update(component_name, "åˆå§‹åŒ–æˆåŠŸ")
                    except Exception as e:
                        results[component_name] = False
                        error_msg = f"{component_name}åˆå§‹åŒ–å¤±è´¥: {str(e)}"
                        errors.append(error_msg)
                        progress_tracker.update(component_name, "åˆå§‹åŒ–å¤±è´¥")
                        print_func(f"é”™è¯¯: {error_msg}")
            
            # æ£€æŸ¥å…³é”®ç»„ä»¶æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
            critical_components = ["æ„å›¾åˆ†æå™¨", "PubMedæ£€ç´¢å™¨", "æ–‡çŒ®ç­›é€‰å™¨"]
            failed_critical = [comp for comp in critical_components if not results.get(comp, False)]
            
            if failed_critical:
                error_msg = f"å…³é”®ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {', '.join(failed_critical)}"
                raise SystemError("ç³»ç»Ÿåˆå§‹åŒ–", "å…³é”®ç»„ä»¶å¤±è´¥", error_msg)
            
            # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
            print("\n[LIST] æ­£åœ¨æ˜¾ç¤ºç³»ç»Ÿé…ç½®ä¿¡æ¯...")
            self._display_model_configuration()
            
            init_time = self.performance_monitor.end_timing("ç»„ä»¶åˆå§‹åŒ–")
            print(f"\n[OK] ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼å¹¶è¡Œåˆå§‹åŒ–ç”¨æ—¶: {init_time:.2f}ç§’")
            print(f"æˆåŠŸ: {len([r for r in results.values() if r])}/{len(results)} ä¸ªç»„ä»¶")
            
            # ç¡®ä¿è¾“å‡ºç«‹å³åˆ·æ–°
            import sys
            sys.stdout.flush()
            
            return True
            
        except SystemError:
            raise
        except Exception as e:
            init_time = self.performance_monitor.end_timing("ç»„ä»¶åˆå§‹åŒ–")
            error_msg = f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}"
            solution = "æ£€æŸ¥ä¾èµ–åŒ…å’Œé…ç½®æ–‡ä»¶ï¼Œæˆ–ä½¿ç”¨è°ƒè¯•æ¨¡å¼æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"
            raise SystemError("ç³»ç»Ÿåˆå§‹åŒ–", "åˆå§‹åŒ–å¼‚å¸¸", error_msg, solution)
    
    def _init_data_processor(self) -> bool:
        """åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨"""
        try:
            self.data_processor = JournalDataProcessor()
            return True
        except FileNotFoundError:
            print("[WARN]  æœŸåˆŠæ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨åŸºç¡€ç­›é€‰åŠŸèƒ½")
            self.data_processor = None
            return True
    
    def _init_data_processor_safe(self) -> bool:
        """çº¿ç¨‹å®‰å…¨çš„æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–"""
        try:
            self.performance_monitor.start_timing("æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–", is_parallel=True)
            self.data_processor = JournalDataProcessor()
            self.performance_monitor.end_timing("æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–")
            return True
        except FileNotFoundError:
            self.performance_monitor.end_timing("æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–")
            return True  # é™é»˜å¤„ç†æ–‡ä»¶æœªæ‰¾åˆ°é”™è¯¯  # éå…³é”®ç»„ä»¶ï¼Œå…è®¸å¤±è´¥
        except Exception as e:
            self.performance_monitor.end_timing("æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–")
            raise SystemError("æ•°æ®å¤„ç†å™¨", "åˆå§‹åŒ–å¤±è´¥", str(e))
    
    def _init_intent_analyzer(self) -> bool:
        """åˆå§‹åŒ–æ„å›¾åˆ†æå™¨"""
        try:
            self.intent_analyzer = IntentAnalyzer(
                config_name=self.ai_config_name, 
                interactive=self.interactive_mode
            )
            return True
        except Exception as e:
            raise SystemError("æ„å›¾åˆ†æå™¨", "åˆå§‹åŒ–å¤±è´¥", str(e))
    
    def _init_intent_analyzer_safe(self) -> bool:
        """çº¿ç¨‹å®‰å…¨çš„æ„å›¾åˆ†æå™¨åˆå§‹åŒ–"""
        try:
            self.intent_analyzer = IntentAnalyzer(
                config_name=self.ai_config_name, 
                interactive=False  # å¼ºåˆ¶éäº¤äº’æ¨¡å¼
            )
            return True
        except Exception as e:
            raise SystemError("æ„å›¾åˆ†æå™¨", "åˆå§‹åŒ–å¤±è´¥", str(e))
    
    def _init_pubmed_searcher(self) -> bool:
        """åˆå§‹åŒ–PubMedæ£€ç´¢å™¨"""
        try:
            self.pubmed_searcher = PubMedSearcher()
            return True
        except Exception as e:
            raise SystemError("PubMedæ£€ç´¢å™¨", "åˆå§‹åŒ–å¤±è´¥", str(e))
    
    def _init_literature_filter(self) -> bool:
        """åˆå§‹åŒ–æ–‡çŒ®ç­›é€‰å™¨"""
        try:
            # ä½¿ç”¨çº¿ç¨‹æ¥é™åˆ¶åˆå§‹åŒ–æ—¶é—´ï¼Œé¿å…é˜»å¡
            import threading
            import time
            
            result = {'success': False, 'error': None, 'filter': None}
            
            def init_filter():
                try:
                    filter_obj = LiteratureFilter()
                    result['filter'] = filter_obj
                    result['success'] = True
                except Exception as e:
                    result['error'] = str(e)
                    result['success'] = False
            
            # å¯åŠ¨åˆå§‹åŒ–çº¿ç¨‹
            init_thread = threading.Thread(target=init_filter)
            init_thread.daemon = True
            init_thread.start()
            
            # ç­‰å¾…æœ€å¤š30ç§’
            init_thread.join(timeout=30)
            
            if init_thread.is_alive():
                print("[WARN] æ–‡çŒ®ç­›é€‰å™¨åˆå§‹åŒ–è¶…æ—¶ï¼Œè·³è¿‡æœŸåˆŠæ•°æ®åŠ è½½")
                # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç­›é€‰å™¨å®ä¾‹
                self.literature_filter = LiteratureFilter.__new__(LiteratureFilter)
                self.literature_filter.zky_data = pd.DataFrame()
                self.literature_filter.jcr_data = pd.DataFrame()
                self.literature_filter.issn_to_journal_info = {}
                self.literature_filter.config = FilterConfig()
                self.literature_filter.journal_cache = JournalInfoCache(self.literature_filter.config)
                self.literature_filter.performance_stats = {
                    'total_articles_processed': 0,
                    'total_filter_time': 0,
                    'cache_hits': 0,
                    'parallel_batches': 0,
                    'memory_usage_mb': 0,
                    'errors': 0
                }
                return True
            elif result['success']:
                self.literature_filter = result['filter']
                return True
            else:
                raise SystemError("æ–‡çŒ®ç­›é€‰å™¨", "åˆå§‹åŒ–å¤±è´¥", result['error'])
                
        except Exception as e:
            raise SystemError("æ–‡çŒ®ç­›é€‰å™¨", "åˆå§‹åŒ–å¤±è´¥", str(e))
    
    def _init_outline_generator(self) -> bool:
        """åˆå§‹åŒ–å¤§çº²ç”Ÿæˆå™¨"""
        try:
            self.outline_generator = ReviewOutlineGenerator(self.ai_config_name)
            return True
        except Exception as e:
            raise SystemError("å¤§çº²ç”Ÿæˆå™¨", "åˆå§‹åŒ–å¤±è´¥", str(e))
    
    def _init_review_generator(self) -> bool:
        """åˆå§‹åŒ–æ–‡ç« ç”Ÿæˆå™¨"""
        try:
            # ä½¿ç”¨çº¿ç¨‹æ¥é™åˆ¶åˆå§‹åŒ–æ—¶é—´ï¼Œé¿å…é˜»å¡
            import threading
            import time
            
            result = {'success': False, 'error': None, 'generator': None}
            
            def init_generator():
                try:
                    generator = MedicalReviewGenerator(self.ai_config_name)
                    result['generator'] = generator
                    result['success'] = True
                except Exception as e:
                    result['error'] = str(e)
                    result['success'] = False
            
            # å¯åŠ¨åˆå§‹åŒ–çº¿ç¨‹
            init_thread = threading.Thread(target=init_generator)
            init_thread.daemon = True
            init_thread.start()
            
            # ç­‰å¾…æœ€å¤š10ç§’
            init_thread.join(timeout=10)
            
            if init_thread.is_alive():
                # çº¿ç¨‹è¿˜åœ¨è¿è¡Œï¼Œè¯´æ˜è¶…æ—¶äº†
                print("[WARN] æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–è¶…æ—¶ï¼Œè·³è¿‡æ­¤ç»„ä»¶")
                return False
            elif result['success']:
                # åˆå§‹åŒ–æˆåŠŸ
                self.review_generator = result['generator']
                return True
            else:
                # åˆå§‹åŒ–å¤±è´¥
                print(f"[WARN] æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {result['error']}")
                print("æç¤º: æ–‡ç« ç”ŸæˆåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†å…¶ä»–åŠŸèƒ½æ­£å¸¸")
                return False
                
        except Exception as e:
            print(f"[WARN] æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            print("æç¤º: æ–‡ç« ç”ŸæˆåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†å…¶ä»–åŠŸèƒ½æ­£å¸¸")
            return False
    
    def _init_pubmed_searcher_safe(self) -> bool:
        """çº¿ç¨‹å®‰å…¨çš„PubMedæ£€ç´¢å™¨åˆå§‹åŒ–"""
        try:
            self.performance_monitor.start_timing("PubMedæ£€ç´¢å™¨åˆå§‹åŒ–", is_parallel=True)
            self.pubmed_searcher = PubMedSearcher()
            self.performance_monitor.end_timing("PubMedæ£€ç´¢å™¨åˆå§‹åŒ–")
            return True
        except Exception as e:
            self.performance_monitor.end_timing("PubMedæ£€ç´¢å™¨åˆå§‹åŒ–")
            raise SystemError("PubMedæ£€ç´¢å™¨", "åˆå§‹åŒ–å¤±è´¥", str(e))
    
    def _init_literature_filter_safe(self) -> bool:
        """çº¿ç¨‹å®‰å…¨çš„æ–‡çŒ®ç­›é€‰å™¨åˆå§‹åŒ–"""
        try:
            self.performance_monitor.start_timing("æ–‡çŒ®ç­›é€‰å™¨åˆå§‹åŒ–", is_parallel=True)
            # ä½¿ç”¨çº¿ç¨‹æ¥é™åˆ¶åˆå§‹åŒ–æ—¶é—´ï¼Œé¿å…é˜»å¡
            import threading
            import time
            
            result = {'success': False, 'error': None, 'filter': None}
            
            def init_filter():
                try:
                    filter_obj = LiteratureFilter()
                    result['filter'] = filter_obj
                    result['success'] = True
                except Exception as e:
                    result['error'] = str(e)
                    result['success'] = False
            
            # å¯åŠ¨åˆå§‹åŒ–çº¿ç¨‹
            init_thread = threading.Thread(target=init_filter)
            init_thread.daemon = True
            init_thread.start()
            
            # ç­‰å¾…æœ€å¤š30ç§’
            init_thread.join(timeout=30)
            
            if init_thread.is_alive():
                # è¶…æ—¶ï¼Œåˆ›å»ºç®€å•ç­›é€‰å™¨
                self.literature_filter = LiteratureFilter.__new__(LiteratureFilter)
                self.literature_filter.zky_data = pd.DataFrame()
                self.literature_filter.jcr_data = pd.DataFrame()
                self.literature_filter.issn_to_journal_info = {}
                self.literature_filter.config = FilterConfig()
                self.literature_filter.journal_cache = JournalInfoCache(self.literature_filter.config)
                self.literature_filter.performance_stats = {
                    'total_articles_processed': 0,
                    'total_filter_time': 0,
                    'cache_hits': 0,
                    'parallel_batches': 0,
                    'memory_usage_mb': 0,
                    'errors': 0
                }
                self.performance_monitor.end_timing("æ–‡çŒ®ç­›é€‰å™¨åˆå§‹åŒ–")
                return True
            elif result['success']:
                self.literature_filter = result['filter']
                self.performance_monitor.end_timing("æ–‡çŒ®ç­›é€‰å™¨åˆå§‹åŒ–")
                return True
            else:
                self.performance_monitor.end_timing("æ–‡çŒ®ç­›é€‰å™¨åˆå§‹åŒ–")
                raise SystemError("æ–‡çŒ®ç­›é€‰å™¨", "åˆå§‹åŒ–å¤±è´¥", result['error'])
        except Exception as e:
            self.performance_monitor.end_timing("æ–‡çŒ®ç­›é€‰å™¨åˆå§‹åŒ–")
            raise SystemError("æ–‡çŒ®ç­›é€‰å™¨", "åˆå§‹åŒ–å¤±è´¥", str(e))
    
    def _init_outline_generator_safe(self) -> bool:
        """çº¿ç¨‹å®‰å…¨çš„å¤§çº²ç”Ÿæˆå™¨åˆå§‹åŒ–"""
        try:
            self.performance_monitor.start_timing("å¤§çº²ç”Ÿæˆå™¨åˆå§‹åŒ–", is_parallel=True)
            self.outline_generator = ReviewOutlineGenerator(self.ai_config_name)
            self.performance_monitor.end_timing("å¤§çº²ç”Ÿæˆå™¨åˆå§‹åŒ–")
            return True
        except Exception as e:
            print(f"è­¦å‘Š: å¤§çº²ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€å•å¤§çº²ç”Ÿæˆ: {e}")
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å¤§çº²ç”Ÿæˆå™¨ä½œä¸ºå¤‡é€‰
            self.outline_generator = SimpleOutlineGenerator()
            self.performance_monitor.end_timing("å¤§çº²ç”Ÿæˆå™¨åˆå§‹åŒ–")
            return True
    
    def _init_review_generator_safe(self) -> bool:
        """çº¿ç¨‹å®‰å…¨çš„æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–"""
        try:
            self.performance_monitor.start_timing("æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–", is_parallel=True)
            # ä½¿ç”¨çº¿ç¨‹æ¥é™åˆ¶åˆå§‹åŒ–æ—¶é—´ï¼Œé¿å…é˜»å¡
            import threading
            import time
            
            result = {'success': False, 'error': None, 'generator': None}
            
            def init_generator():
                try:
                    generator = MedicalReviewGenerator(self.ai_config_name)
                    result['generator'] = generator
                    result['success'] = True
                except Exception as e:
                    result['error'] = str(e)
                    result['success'] = False
            
            # å¯åŠ¨åˆå§‹åŒ–çº¿ç¨‹
            init_thread = threading.Thread(target=init_generator)
            init_thread.daemon = True
            init_thread.start()
            
            # ç­‰å¾…æœ€å¤š10ç§’
            init_thread.join(timeout=10)
            
            if init_thread.is_alive():
                # è¶…æ—¶ï¼Œè·³è¿‡æ­¤ç»„ä»¶
                self.performance_monitor.end_timing("æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–")
                return False
            elif result['success']:
                self.review_generator = result['generator']
                self.performance_monitor.end_timing("æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–")
                return True
            else:
                # åˆå§‹åŒ–å¤±è´¥ï¼Œé™é»˜å¤„ç†
                self.performance_monitor.end_timing("æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–")
                return False
        except Exception as e:
            # é™é»˜å¤„ç†å¼‚å¸¸ï¼Œä¸æ‰“å°é”™è¯¯ä¿¡æ¯
            self.performance_monitor.end_timing("æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–")
            return False
    
    def _display_model_configuration(self):
        """æ˜¾ç¤ºå„ç»„ä»¶ä½¿ç”¨çš„æ¨¡å‹é…ç½®"""
        cache_file = "ai_model_cache.json"
        
        print("\n[AI] AIæ¨¡å‹é…ç½®ä¿¡æ¯:")
        print("=" * 50)
        
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                    print("[LIST] ç»Ÿä¸€æ¨¡å‹é…ç½®:")
                    print(f"   é…ç½®æœåŠ¡: {config.get('config_name', 'æœªçŸ¥')}")
                    print(f"   ä½¿ç”¨æ¨¡å‹: {config.get('model_id', 'æœªçŸ¥')}")
                    
                    params = config.get('parameters', {})
                    print(f"   ç»Ÿä¸€å‚æ•°: temperature={params.get('temperature', 'N/A')}, ")
                    print(f"              max_tokens={params.get('max_tokens', 'N/A')}")
                    
                    print(f"   æ„å›¾åˆ†æå™¨: ä½¿ç”¨ç»Ÿä¸€å‚æ•° + stream=True")
                    print(f"   å¤§çº²ç”Ÿæˆå™¨: ä½¿ç”¨ç»Ÿä¸€å‚æ•° + stream=True") 
                    print(f"   æ–‡ç« ç”Ÿæˆå™¨: ä½¿ç”¨ç»Ÿä¸€å‚æ•° + stream=True")
                    print("   [OK] æ‰€æœ‰ç»„ä»¶ä½¿ç”¨å®Œå…¨ç›¸åŒçš„AIæœåŠ¡ã€æ¨¡å‹ã€å‚æ•°å’Œæµå¼è¾“å‡º")
                    
                    # æ˜¾ç¤ºæ€§èƒ½ä¼˜åŒ–ä¿¡æ¯
                    if self.enable_cache:
                        print("   [START] ç¼“å­˜ç³»ç»Ÿ: å·²å¯ç”¨ (AIå“åº”å’Œæœç´¢ç»“æœç¼“å­˜)")
                    if self.enable_state:
                        print("   [SAVE] çŠ¶æ€ç®¡ç†: å·²å¯ç”¨ (æ–­ç‚¹ç»­ä¼ æ”¯æŒ)")
                    
            except Exception as e:
                print(f"   [WARN]  æ— æ³•è¯»å–æ¨¡å‹é…ç½®: {e}")
                if self.enable_cache:
                    print("   [START] ç¼“å­˜ç³»ç»Ÿ: å·²å¯ç”¨")
                if self.enable_state:
                    print("   [SAVE] çŠ¶æ€ç®¡ç†: å·²å¯ç”¨")
        else:
            print("   [WARN]  æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ç¼“å­˜æ–‡ä»¶")
            print("   [INFO] æç¤º: é¦–æ¬¡è¿è¡Œæ—¶å°†è‡ªåŠ¨ç”Ÿæˆé…ç½®ç¼“å­˜")
            if self.enable_cache:
                print("   [START] ç¼“å­˜ç³»ç»Ÿ: å·²å¯ç”¨")
            if self.enable_state:
                print("   [SAVE] çŠ¶æ€ç®¡ç†: å·²å¯ç”¨")
        
        print("=" * 50)
    
    def get_search_count_only(self, query: str) -> Optional[int]:
        """
        ä»…è·å–æœç´¢ç»“æœæ•°é‡ï¼Œä¸è·å–è¯¦ç»†å†…å®¹
        
        Args:
            query: PubMedæœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
            
        Returns:
            æœç´¢ç»“æœæ€»æ•°ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            if not self.pubmed_searcher:
                print("PubMedæ£€ç´¢å™¨æœªåˆå§‹åŒ–")
                return None
                
            print(f"æ­£åœ¨ä¼°ç®—æ–‡çŒ®æ•°é‡...")
            
            # ä½¿ç”¨retmax=0æ¥åªè·å–è®¡æ•°ï¼Œä¸è·å–PMIDåˆ—è¡¨ï¼Œé¿å…ä¸´æ—¶ä¿®æ”¹é…ç½®
            import requests
            import time
            
            base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
            params = {
                'db': 'pubmed',
                'term': query,
                'retmode': 'json',
                'retmax': 0  # åªè¿”å›è®¡æ•°ï¼Œä¸è¿”å›IDåˆ—è¡¨
            }
            
            try:
                response = requests.get(base_url, params=params, timeout=30)
                response.raise_for_status()
                
                data = response.json()
                count = int(data.get('esearchresult', {}).get('count', 0))
                
                if count > 0:
                    print(f"[OK] ä¼°ç®—å®Œæˆ: å…±æ‰¾åˆ° {count} ç¯‡ç›¸å…³æ–‡çŒ®")
                else:
                    print("[WARN] æœªæ‰¾åˆ°ç›¸å…³æ–‡çŒ®")
                
                return count
                
            except Exception as e:
                print(f"[FAIL] ä¼°ç®—å¤±è´¥: {e}")
                return None
                
        except Exception as e:
            print(f"è·å–æ–‡çŒ®æ•°é‡å¤±è´¥: {e}")
            return None
    
    async def run_complete_workflow(self, user_query: str, max_results: int = 50, 
                            target_articles: int = 20, 
                            enable_resume: bool = True) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„å·¥ä½œæµç¨‹
        
        Args:
            user_query: ç”¨æˆ·æ£€ç´¢éœ€æ±‚
            max_results: æœ€å¤§æ£€ç´¢ç»“æœæ•°
            target_articles: ç›®æ ‡ç­›é€‰æ–‡ç« æ•°
            enable_resume: æ˜¯å¦å¯ç”¨æ–­ç‚¹ç»­ä¼ 
            
        Returns:
            åŒ…å«æ‰€æœ‰ç»“æœçš„å­—å…¸
        """
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¢å¤ä¹‹å‰çš„ä»»åŠ¡
        if enable_resume and self.state_manager and self.state_manager.can_resume():
            resume_result = self._try_resume_workflow()
            if resume_result:
                return resume_result
        
        # å¼€å§‹æ–°çš„å·¥ä½œæµç¨‹
        print(f"å¼€å§‹å¤„ç†ç”¨æˆ·éœ€æ±‚: {user_query}")
        print("=" * 60)
        
        # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
        progress_tracker = ProgressTracker(4, "æ–‡çŒ®æ£€ç´¢ä¸ç»¼è¿°ç”Ÿæˆ")
        
        # ä¿å­˜åˆå§‹çŠ¶æ€
        if self.state_manager:
            self.state_manager.save_state({
                'user_query': user_query,
                'max_results': max_results,
                'target_articles': target_articles,
                'current_step': 0,
                'processing': True,
                'start_time': datetime.now().isoformat()
            })
        
        self.performance_monitor.start_timing("å®Œæ•´å·¥ä½œæµç¨‹")
        
        # ç¬¬1æ­¥ï¼šæ„å›¾åˆ†æ
        print("\nç¬¬1æ­¥ï¼šåˆ†æç”¨æˆ·æ„å›¾...")
        self.performance_monitor.start_timing("æ„å›¾åˆ†æ")
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"intent_analysis_{hash(user_query)}"
            cached_result = None
            if self.cache_system:
                cached_result = self.cache_system.get_cached_ai_response(cache_key)
            
            if cached_result:
                print("ä½¿ç”¨ç¼“å­˜çš„æ„å›¾åˆ†æç»“æœ")
                # è¿™é‡Œéœ€è¦ä»ç¼“å­˜ç»“æœä¸­é‡æ„SearchCriteriaå¯¹è±¡
                # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä»ç„¶é‡æ–°åˆ†æï¼Œä½†åç»­å¯ä»¥æ”¹è¿›ç¼“å­˜ç»“æ„
                
            self.search_criteria = self.intent_analyzer.analyze_intent(user_query)
            self.intent_analyzer.print_analysis_result(self.search_criteria)
            
            # ç¼“å­˜ç»“æœ
            if self.cache_system:
                criteria_str = str(self.search_criteria.__dict__)
                self.cache_system.cache_ai_response(cache_key, criteria_str)
            
            analysis_time = self.performance_monitor.end_timing("æ„å›¾åˆ†æ")
            progress_tracker.update("ç”¨æˆ·æ„å›¾åˆ†æ", f"å®Œæˆ (ç”¨æ—¶: {analysis_time:.1f}s)")
            
            # ä¿å­˜çŠ¶æ€
            if self.state_manager:
                self.state_manager.save_state({
                    'current_step': 1,
                    'search_criteria': self.search_criteria.__dict__ if self.search_criteria else None
                })
                
        except Exception as e:
            self.performance_monitor.end_timing("æ„å›¾åˆ†æ")
            error_msg = f"æ„å›¾åˆ†æå¤±è´¥: {str(e)}"
            solution = "æ£€æŸ¥AIæœåŠ¡é…ç½®å’Œç½‘ç»œè¿æ¥"
            print(error_msg)
            print(f"è§£å†³æ–¹æ¡ˆ: {solution}")
            return {"success": False, "error": "æ„å›¾åˆ†æå¤±è´¥", "details": str(e)}
        
        # ç¬¬2æ­¥ï¼šæ–‡çŒ®æ£€ç´¢
        print("\nç¬¬2æ­¥ï¼šPubMedæ–‡çŒ®æ£€ç´¢...")
        self.performance_monitor.start_timing("æ–‡çŒ®æ£€ç´¢")
        
        try:
            pubmed_query = self.intent_analyzer.build_pubmed_query(self.search_criteria)
            print(f"æ£€ç´¢è¡¨è¾¾å¼: {pubmed_query}")
            
            # åœ¨äº¤äº’æ¨¡å¼ä¸‹ï¼Œå…ˆè·å–æ€»æ–‡çŒ®æ•°ï¼Œè®©ç”¨æˆ·å†³å®šè¦è·å–å¤šå°‘ç¯‡
            if self.interactive_mode:
                total_count = self.get_search_count_only(pubmed_query)
                if total_count is not None:
                    print(f"\n[STAT] æ ¹æ®æ‚¨çš„æ£€ç´¢éœ€æ±‚ï¼Œå…±æ‰¾åˆ°çº¦ {total_count} ç¯‡ç›¸å…³æ–‡çŒ®")
                    print("=" * 50)
                    
                    # è¯¢é—®ç”¨æˆ·è¦è·å–å¤šå°‘ç¯‡æ–‡ç« 
                    while True:
                        try:
                            user_max = input(f"è¯·è¾“å…¥è¦è·å–çš„æ–‡çŒ®æ•°é‡ (1-{total_count}, å»ºè®®50-200): ").strip()
                            if not user_max:
                                user_max = min(100, total_count)  # é»˜è®¤å€¼
                            else:
                                user_max = int(user_max)
                            
                            if user_max <= 0:
                                print("[FAIL] æ•°é‡å¿…é¡»å¤§äº0")
                            elif user_max > total_count:
                                print(f"[WARN] æ£€ç´¢ç»“æœåªæœ‰{total_count}ç¯‡ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸º{total_count}ç¯‡")
                                user_max = total_count
                            else:
                                break
                        except ValueError:
                            print("[FAIL] è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                    
                    max_results = user_max
                    print(f"[OK] å°†è·å– {max_results} ç¯‡æ–‡çŒ®")
                else:
                    print("[WARN] æ— æ³•è·å–æ€»æ–‡çŒ®æ•°ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
            
            # æ£€æŸ¥æœç´¢ç¼“å­˜
            cached_search = None
            if self.cache_system:
                cached_search = self.cache_system.get_cached_search(pubmed_query, max_results)
            
            if cached_search:
                print("ä½¿ç”¨ç¼“å­˜çš„æ–‡çŒ®æ£€ç´¢ç»“æœ")
                pmid_list = cached_search['results']
            else:
                # å…ˆè·å–PMIDåˆ—è¡¨
                pmid_list = self.pubmed_searcher.search_articles(
                    query=pubmed_query,
                    max_results=max_results
                )
                
                # ç¼“å­˜æœç´¢ç»“æœ
                if self.cache_system and pmid_list:
                    self.cache_system.cache_search_result(pubmed_query, max_results, pmid_list)
            
            if not pmid_list:
                print("æœªæ£€ç´¢åˆ°æ–‡çŒ®ç»“æœ")
                return {"success": False, "error": "æœªæ£€ç´¢åˆ°æ–‡çŒ®"}
            
            print(f"è·å–åˆ° {len(pmid_list)} ä¸ªPMID")
            
            # ç¬¬ä¸€æ­¥ï¼šåªè·å–ISSN/EISSNä¿¡æ¯è¿›è¡Œåˆæ­¥ç­›é€‰
            print("\n[STEP 1] è·å–ISSN/EISSNä¿¡æ¯è¿›è¡Œåˆæ­¥ç­›é€‰...")
            issn_results = []
            total_batches = (len(pmid_list) + self.chunk_size - 1) // self.chunk_size
            
            for i in range(0, len(pmid_list), self.chunk_size):
                batch = pmid_list[i:i + self.chunk_size]
                batch_num = i // self.chunk_size + 1
                print(f"æ­£åœ¨å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ISSN/EISSNä¿¡æ¯ ({len(batch)} ç¯‡)...")
                
                batch_issn_results = self.pubmed_searcher.fetch_article_issn_only(batch)
                if batch_issn_results:
                    issn_results.extend(batch_issn_results)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (len(issn_results) / len(pmid_list)) * 100
                progress_tracker.update_progress_only("PubMedæ–‡çŒ®æ£€ç´¢", f"ISSN/EISSNç­›é€‰ä¸­ ({len(issn_results)}/{len(pmid_list)})", progress)
                
                # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼ˆæœ€åä¸€æ‰¹ä¸å»¶è¿Ÿï¼‰
                if i + self.chunk_size < len(pmid_list):
                    print(f"ç­‰å¾… {self.batch_delay} ç§’åå¤„ç†ä¸‹ä¸€æ‰¹...")
                    time.sleep(self.batch_delay)
            
            if not issn_results:
                print("æœªè·å–åˆ°ISSN/EISSNä¿¡æ¯")
                return {"success": False, "error": "æœªè·å–åˆ°ISSN/EISSNä¿¡æ¯"}
            
            print(f"ISSN/EISSNä¿¡æ¯è·å–å®Œæˆ: {len(issn_results)} ç¯‡")
            
            # ç¬¬äºŒæ­¥ï¼šåŒ¹é…æœŸåˆŠè´¨é‡ä¿¡æ¯
            print("\n[STEP 2] åŒ¹é…æœŸåˆŠè´¨é‡ä¿¡æ¯...")
            enriched_results = self._enrich_with_journal_info(issn_results, self.search_criteria)
            
            # ç¬¬ä¸‰æ­¥ï¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚ç­›é€‰
            print("\n[STEP 3] æ ¹æ®ç”¨æˆ·éœ€æ±‚ç­›é€‰...")
            filtered_pmids = self._filter_by_user_criteria(enriched_results, self.search_criteria)
            
            if not filtered_pmids:
                print("ç”¨æˆ·éœ€æ±‚ç­›é€‰åæ— ç¬¦åˆæ¡ä»¶çš„æ–‡çŒ®")
                return {"success": False, "error": "ç”¨æˆ·éœ€æ±‚ç­›é€‰åæ— ç¬¦åˆæ¡ä»¶çš„æ–‡çŒ®"}
            
            print(f"ç”¨æˆ·éœ€æ±‚ç­›é€‰åå‰©ä½™: {len(filtered_pmids)} ç¯‡")
            
            # ç¬¬å››æ­¥ï¼šè·å–ç­›é€‰åæ–‡çŒ®çš„å®Œæ•´ä¿¡æ¯
            print(f"\n[STEP 4] è·å–ç­›é€‰å {len(filtered_pmids)} ç¯‡æ–‡çŒ®çš„å®Œæ•´ä¿¡æ¯...")
            self.literature_results = []
            total_detail_batches = (len(filtered_pmids) + self.chunk_size - 1) // self.chunk_size
            
            for i in range(0, len(filtered_pmids), self.chunk_size):
                batch = filtered_pmids[i:i + self.chunk_size]
                batch_num = i // self.chunk_size + 1
                print(f"æ­£åœ¨å¤„ç†ç¬¬ {batch_num}/{total_detail_batches} æ‰¹å®Œæ•´ä¿¡æ¯ ({len(batch)} ç¯‡)...")
                
                batch_results = self.pubmed_searcher.fetch_article_details(batch)
                if batch_results:
                    self.literature_results.extend(batch_results)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (len(self.literature_results) / len(filtered_pmids)) * 100
                progress_tracker.update_progress_only("PubMedæ–‡çŒ®æ£€ç´¢", f"è·å–å®Œæ•´ä¿¡æ¯ ({len(self.literature_results)}/{len(filtered_pmids)})", progress)
                
                # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼ˆæœ€åä¸€æ‰¹ä¸å»¶è¿Ÿï¼‰
                if i + self.chunk_size < len(filtered_pmids):
                    print(f"ç­‰å¾… {self.batch_delay} ç§’åå¤„ç†ä¸‹ä¸€æ‰¹...")
                    time.sleep(self.batch_delay)
            
            if not self.literature_results:
                print("æœªè·å–åˆ°æ–‡çŒ®è¯¦ç»†ä¿¡æ¯")
                return {"success": False, "error": "æœªè·å–åˆ°æ–‡çŒ®è¯¦ç»†ä¿¡æ¯"}
            
            search_time = self.performance_monitor.end_timing("æ–‡çŒ®æ£€ç´¢")
            print(f"ä¼˜åŒ–æ£€ç´¢å®Œæˆ: åŸå§‹{len(pmid_list)}ç¯‡ -> æœŸåˆŠä¿¡æ¯åŒ¹é…å{len(enriched_results)}ç¯‡ -> ç”¨æˆ·ç­›é€‰å{len(filtered_pmids)}ç¯‡ -> æœ€ç»ˆ{len(self.literature_results)}ç¯‡ (ç”¨æ—¶: {search_time:.1f}s)")
            
            # ä¿å­˜çŠ¶æ€
            if self.state_manager:
                self.state_manager.save_state({
                    'current_step': 2,
                    'pmid_count': len(pmid_list),
                    'literature_count': len(self.literature_results)
                })
            
        except Exception as e:
            print(f"[FAIL] æ–‡çŒ®æ£€ç´¢å¤±è´¥: {e}")
            return {"success": False, "error": "æ–‡çŒ®æ£€ç´¢å¤±è´¥"}
        
        # ç¬¬2æ­¥å·²ç»å®Œæˆäº†ç”¨æˆ·éœ€æ±‚ç­›é€‰ï¼Œç›´æ¥ä½¿ç”¨ç­›é€‰åçš„ç»“æœ
        self.filtered_results = self.literature_results
        print(f"[OK] æ–‡çŒ®æ£€ç´¢å®Œæˆï¼Œå…±è·å– {len(self.filtered_results)} ç¯‡ç¬¦åˆæ¡ä»¶æ–‡çŒ®")
        
        progress_tracker.update("æ–‡çŒ®æ£€ç´¢", f"å®Œæˆ (è·å– {len(self.filtered_results)} ç¯‡)")
        
        # ç«‹å³ä¿å­˜ç­›é€‰åçš„æ–‡çŒ®ä¸ºCSVæ ¼å¼ï¼ˆåœ¨ç”¨æˆ·ç¡®è®¤ä¹‹å‰ï¼‰
        print("\nä¿å­˜ç­›é€‰åçš„æ–‡çŒ®ç»“æœ...")
        self._save_literature_csv(user_query, self.filtered_results, "ç­›é€‰ç»“æœ")
        
        # ç”¨æˆ·ç¡®è®¤æ–­ç‚¹ï¼šæ˜¯å¦ç»§ç»­ç”Ÿæˆç»¼è¿°å¤§çº²
        if not self._ask_user_continue():
            print("è¿”å›åˆ°ç”¨æˆ·è¾“å…¥...")
            if self.state_manager:
                self.state_manager.clear_state()
            return {"success": False, "restart": True}
        
        # ç¬¬3æ­¥ï¼šç”Ÿæˆç»¼è¿°å¤§çº²
        print("\nç¬¬3æ­¥ï¼šç”Ÿæˆç»¼è¿°å¤§çº²...")
        self.performance_monitor.start_timing("å¤§çº²ç”Ÿæˆ")
        
        try:
            # ä½¿ç”¨æ™ºèƒ½æ ‡é¢˜æå–ï¼Œåªä¿ç•™æ ¸å¿ƒç ”ç©¶ä¸»é¢˜å’Œæ—¶é—´èŒƒå›´
            research_topic = self._extract_core_research_topic(user_query)
            print(f"æ ¸å¿ƒç ”ç©¶ä¸»é¢˜æå–: '{user_query}' â†’ '{research_topic}'")
            
            # æ£€æŸ¥å¤§çº²ç¼“å­˜
            outline_cache_key = f"outline_{hash(research_topic + str(len(self.filtered_results)))}"
            cached_outline = None
            if self.cache_system:
                cached_outline = self.cache_system.get_cached_ai_response(outline_cache_key)
            
            if cached_outline:
                print("ä½¿ç”¨ç¼“å­˜çš„ç»¼è¿°å¤§çº²")
                self.outline_content = cached_outline
            else:
                self.outline_content = self.outline_generator.generate_outline_from_data(
                    self.filtered_results, research_topic
                )
                
                # ç¼“å­˜å¤§çº²ç»“æœ
                if self.cache_system and self.outline_content:
                    self.cache_system.cache_ai_response(outline_cache_key, self.outline_content)
            
            # éªŒè¯å¤§çº²å†…å®¹æ˜¯å¦æœ‰æ•ˆ
            if not self.outline_content or "é”™è¯¯" in self.outline_content or len(self.outline_content.strip()) < 50:
                print(f"å¤§çº²ç”Ÿæˆè¿”å›æ— æ•ˆå†…å®¹: {self.outline_content[:100]}...")
                return {"success": False, "error": "å¤§çº²ç”Ÿæˆè¿”å›æ— æ•ˆå†…å®¹"}
            
            outline_time = self.performance_monitor.end_timing("å¤§çº²ç”Ÿæˆ")
            print(f"ç»¼è¿°å¤§çº²ç”Ÿæˆå®Œæˆ (ç”¨æ—¶: {outline_time:.1f}s)")
            
            # ä¿å­˜å¤§çº²åˆ°æ–‡ä»¶
            outline_file = self._save_outline_to_file(user_query, research_topic)
            if outline_file:
                progress_tracker.update("ç»¼è¿°å¤§çº²ç”Ÿæˆ", f"å®Œæˆ (ä¿å­˜è‡³: {outline_file})")
            else:
                progress_tracker.update("ç»¼è¿°å¤§çº²ç”Ÿæˆ", f"å®Œæˆ (å¤§çº²é•¿åº¦: {len(self.outline_content)} å­—ç¬¦)")
            
            # ä¿å­˜çŠ¶æ€å’Œæ–‡ä»¶è·¯å¾„
            if self.state_manager:
                self.state_manager.save_state({
                    'current_step': 4,
                    'outline_generated': True,
                    'outline_file': outline_file
                })
            
            # ä¿å­˜å¤§çº²æ–‡ä»¶è·¯å¾„ä¾›æœ€ç»ˆç»“æœä½¿ç”¨
            self.final_outline_file = outline_file
                
        except Exception as e:
            self.performance_monitor.end_timing("å¤§çº²ç”Ÿæˆ")
            print(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {e}")
            return {"success": False, "error": "å¤§çº²ç”Ÿæˆå¤±è´¥", "details": str(e)}
        
        # ç¬¬4æ­¥ï¼šç”Ÿæˆç»¼è¿°æ–‡ç« 
        print("\nç¬¬4æ­¥ï¼šç”Ÿæˆç»¼è¿°æ–‡ç« ...")
        self.performance_monitor.start_timing("æ–‡ç« ç”Ÿæˆ")
        
        try:
            # æ£€æŸ¥æ–‡ç« ç”Ÿæˆå™¨æ˜¯å¦å¯ç”¨
            if self.review_generator is None:
                print("æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆç»¼è¿°æ–‡ç« ")
                return {"success": False, "error": "æ–‡ç« ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥", 
                       "details": "AIé…ç½®é—®é¢˜æˆ–ç»„ä»¶åˆå§‹åŒ–è¶…æ—¶ï¼Œè¯·æ£€æŸ¥AIæœåŠ¡é…ç½®"}
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶ä¾›æ–‡ç« ç”Ÿæˆå™¨ä½¿ç”¨
            temp_outline_file = self._save_temp_outline()
            temp_literature_file = self._save_temp_literature()
            
            review_title = f"{research_topic}ï¼šç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°"
            output_file = self._generate_output_filename(research_topic)
            
            # æ£€æŸ¥æ–‡ç« ç¼“å­˜
            article_cache_key = f"article_{hash(review_title + str(len(self.filtered_results)))}"
            cached_article = None
            if self.cache_system:
                cached_article = self.cache_system.get_cached_ai_response(article_cache_key)
            
            if cached_article:
                print("ä½¿ç”¨ç¼“å­˜çš„ç»¼è¿°æ–‡ç« ")
                review_content = cached_article
                success = True
            else:
                md_path, docx_path = self.review_generator.generate_from_files(
                    outline_file=temp_outline_file,
                    literature_file=temp_literature_file,
                    title=review_title,
                    output_filename=output_file,
                    user_input=user_query,
                    export_docx=True  # é»˜è®¤å¯¼å‡ºDOCXæ ¼å¼
                )
                
                success = bool(md_path)  # å¦‚æœMDæ–‡ä»¶ç”ŸæˆæˆåŠŸå°±ç®—æˆåŠŸ
                
                if not success:
                    print("ç»¼è¿°æ–‡ç« ç”Ÿæˆå¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
                    # å°è¯•ç›´æ¥è¿”å›ç”Ÿæˆçš„å†…å®¹
                    try:
                        review_content = self.review_generator.generate_complete_review_article(
                            temp_outline_file, temp_literature_file, review_title
                        )
                        if review_content:
                            success = True
                            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                            os.makedirs("ç»¼è¿°æ–‡ç« ", exist_ok=True)
                            full_path = os.path.join("ç»¼è¿°æ–‡ç« ", output_file)
                            
                            # ä¿å­˜ç”Ÿæˆçš„å†…å®¹
                            with open(full_path, 'w', encoding='utf-8') as f:
                                f.write(review_content)
                            print(f"ç»¼è¿°æ–‡ç« å·²ä¿å­˜ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰: {full_path}")
                            
                            # ç¼“å­˜æ–‡ç« ç»“æœ
                            if self.cache_system:
                                self.cache_system.cache_ai_response(article_cache_key, review_content)
                        else:
                            return {"success": False, "error": "ç»¼è¿°æ–‡ç« ç”Ÿæˆå¤±è´¥"}
                    except Exception as e:
                        print(f"å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
                        return {"success": False, "error": "ç»¼è¿°æ–‡ç« ç”Ÿæˆå¤±è´¥"}
            
            if success:
                # ç¡®ä¿ç»¼è¿°æ–‡ç« æ–‡ä»¶å­˜åœ¨
                full_path = os.path.join("ç»¼è¿°æ–‡ç« ", output_file)
                if os.path.exists(full_path):
                    print(f"ç»¼è¿°æ–‡ç« ç”Ÿæˆå®Œæˆ: {full_path}")
                else:
                    print("ä¸»æ–¹æ³•ç”Ÿæˆå®Œæˆä½†æœªæ‰¾åˆ°æ–‡ä»¶")
            else:
                return {"success": False, "error": "ç»¼è¿°æ–‡ç« ç”Ÿæˆå¤±è´¥"}
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files([temp_outline_file, temp_literature_file])
            
            generation_time = self.performance_monitor.end_timing("æ–‡ç« ç”Ÿæˆ")
            print(f"ç»¼è¿°æ–‡ç« ç”Ÿæˆå®Œæˆ (ç”¨æ—¶: {generation_time:.1f}s)")
            
            progress_tracker.update("ç»¼è¿°æ–‡ç« ç”Ÿæˆ", f"å®Œæˆ (ä¿å­˜è‡³: {output_file})")
            
        except Exception as e:
            self.performance_monitor.end_timing("æ–‡ç« ç”Ÿæˆ")
            print(f"æ–‡ç« ç”Ÿæˆå¤±è´¥: {e}")
            return {"success": False, "error": "æ–‡ç« ç”Ÿæˆå¤±è´¥", "details": str(e)}
        
        # æ¸…ç†çŠ¶æ€
        if self.state_manager:
            self.state_manager.clear_state()
        
        # è¿”å›å®Œæ•´ç»“æœ
        workflow_time = self.performance_monitor.end_timing("å®Œæ•´å·¥ä½œæµç¨‹")
        performance_report = self.performance_monitor.get_performance_report()
        
        result = {
            "success": True,
            "user_query": user_query,
            "search_criteria": self.search_criteria.__dict__ if self.search_criteria else None,
            "total_found": len(self.literature_results),
            "filtered_count": len(self.filtered_results),
            "outline_file": getattr(self, 'final_outline_file', None),
            "review_file": os.path.join("ç»¼è¿°æ–‡ç« ", output_file) if 'output_file' in locals() else None,
            "docx_file": docx_path if 'docx_path' in locals() and docx_path else None,
            "processing_time": workflow_time,
            "performance_report": performance_report
        }
        
        print("\nå®Œæ•´å·¥ä½œæµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
        print("=" * 60)
        self._print_summary(result)
        self._print_performance_summary(performance_report)
        
        return result
        
        return result
    
    def _save_temp_outline(self) -> str:
        """ä¿å­˜ä¸´æ—¶å¤§çº²æ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        temp_file = f"temp_outline_{timestamp}.md"
        
        with open(temp_file, 'w', encoding='utf-8') as f:
            f.write(self.outline_content)
            
        return temp_file
    
    def _save_outline_to_file(self, user_query: str, research_topic: str) -> str:
        """
        ä¿å­˜ç»¼è¿°å¤§çº²åˆ°å·¥ä½œç›®å½•çš„ç»¼è¿°å¤§çº²æ–‡ä»¶å¤¹
        
        Args:
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢å†…å®¹
            research_topic: ç ”ç©¶ä¸»é¢˜
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        try:
            import re
            import os
            from datetime import datetime
            
            # åˆ›å»ºç»¼è¿°å¤§çº²ç›®å½•
            outline_dir = "ç»¼è¿°å¤§çº²"
            os.makedirs(outline_dir, exist_ok=True)
            
            # æ¸…ç†ç”¨æˆ·è¾“å…¥å†…å®¹ç”¨äºæ–‡ä»¶å
            safe_user_input = re.sub(r'[^\w\s\u4e00-\u9fff\-]', '', user_query)
            safe_user_input = re.sub(r'\s+', '_', safe_user_input.strip())
            safe_user_input = safe_user_input[:50]  # é™åˆ¶é•¿åº¦
            
            # ç”Ÿæˆæ—¶é—´æˆ³
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # æ„å»ºæ–‡ä»¶åï¼šç»¼è¿°å¤§çº²-ç”¨æˆ·è¾“å…¥å†…å®¹-æ—¶é—´æˆ³.md
            filename = f"ç»¼è¿°å¤§çº²-{safe_user_input}-{timestamp}.md"
            file_path = os.path.join(outline_dir, filename)
            
            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(self.outline_content)
            
            print(f"ç»¼è¿°å¤§çº²å·²ä¿å­˜: {file_path}")
            return file_path
            
        except Exception as e:
            print(f"ä¿å­˜ç»¼è¿°å¤§çº²å¤±è´¥: {e}")
            return None
    
    def _save_temp_literature(self) -> str:
        """ä¿å­˜ä¸´æ—¶æ–‡çŒ®æ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        temp_file = f"temp_literature_{timestamp}.json"
        
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(self.filtered_results, f, ensure_ascii=False, indent=2)
            
        return temp_file
    
    def _generate_output_filename(self, topic: str) -> str:
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼ˆä»…æ–‡ä»¶åï¼Œä¸åŒ…å«è·¯å¾„ï¼‰"""
        import re
        safe_topic = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', topic)  # ä¿ç•™ä¸­æ–‡å­—ç¬¦
        safe_topic = re.sub(r'\s+', '_', safe_topic.strip())[:30]  # æ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿ï¼Œé™åˆ¶é•¿åº¦
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        return f"ç»¼è¿°-{safe_topic}-{timestamp}.md"
    
    def _cleanup_temp_files(self, files: List[str]):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        for file_path in files:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def _save_literature_csv(self, user_query: str, literature_data: List[Dict], file_type: str = "æ£€ç´¢ç»“æœ"):
        """
        ä¿å­˜æ–‡çŒ®æ£€ç´¢ç»“æœä¸ºCSVæ ¼å¼
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢å†…å®¹
            literature_data: æ–‡çŒ®æ•°æ®åˆ—è¡¨
            file_type: æ–‡ä»¶ç±»å‹æ ‡è¯†ï¼ˆå¦‚"æ£€ç´¢ç»“æœ"æˆ–"ç­›é€‰ç»“æœ"ï¼‰
        """
        import csv
        import re
        
        if not literature_data:
            return
            
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = "æ–‡çŒ®æ£€ç´¢ç»“æœ"
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶åï¼šæ–‡çŒ®åˆ—è¡¨-ç”¨æˆ·è¾“å…¥å†…å®¹-æ—¶é—´æˆ³
        safe_user_input = re.sub(r'[^\w\s\u4e00-\u9fff\-]', '', user_query)
        safe_user_input = re.sub(r'\s+', '_', safe_user_input.strip())
        safe_user_input = safe_user_input[:50]  # é™åˆ¶é•¿åº¦
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"æ–‡çŒ®åˆ—è¡¨-{safe_user_input}-{timestamp}.csv"
        filepath = os.path.join(output_dir, filename)
        
        try:
            with open(filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
                # å®šä¹‰CSVå­—æ®µ - æ·»åŠ æœŸåˆŠè´¨é‡æŒ‡æ ‡å’Œå·æœŸé¡µä¿¡æ¯
                fieldnames = [
                    'åºå·', 'æ ‡é¢˜', 'ä½œè€…', 'æœŸåˆŠ', 'å·', 'æœŸ', 'é¡µç ', 'å‘è¡¨å¹´ä»½', 'PMID', 'DOI', 
                    'ISSN', 'eISSN', 'ä¸­ç§‘é™¢åˆ†åŒº', 'JCRåˆ†åŒº', 'å½±å“å› å­', 
                    'æ‘˜è¦', 'å…³é”®è¯', 'URL'
                ]
                
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                # å†™å…¥æ•°æ®
                for i, article in enumerate(literature_data, 1):
                    # å¤„ç†ä½œè€…åˆ—è¡¨
                    authors = article.get('authors', [])
                    if isinstance(authors, list):
                        authors_str = '; '.join(authors)
                    else:
                        authors_str = str(authors) if authors else ''
                    
                    # å¤„ç†å…³é”®è¯
                    keywords = article.get('keywords', [])
                    if isinstance(keywords, list):
                        keywords_str = '; '.join(keywords)
                    else:
                        keywords_str = str(keywords) if keywords else ''
                    
                    # è·å–æœŸåˆŠè´¨é‡ä¿¡æ¯
                    issn = article.get('issn', '')
                    eissn = article.get('eissn', '')
                    journal_info = self.literature_filter.get_journal_info(issn, eissn)
                    
                    # æ„å»ºCSVè¡Œæ•°æ®
                    row_data = {
                        'åºå·': i,
                        'æ ‡é¢˜': article.get('title', ''),
                        'ä½œè€…': authors_str,
                        'æœŸåˆŠ': article.get('journal', ''),
                        'å·': article.get('volume', ''),
                        'æœŸ': article.get('issue', ''),
                        'é¡µç ': article.get('pages', ''),
                        'å‘è¡¨å¹´ä»½': article.get('publication_date', ''),
                        'PMID': article.get('pmid', ''),
                        'DOI': article.get('doi', ''),
                        'ISSN': issn,
                        'eISSN': eissn,
                        'ä¸­ç§‘é™¢åˆ†åŒº': journal_info.get('cas_zone', ''),
                        'JCRåˆ†åŒº': journal_info.get('jcr_quartile', ''),
                        'å½±å“å› å­': journal_info.get('impact_factor', ''),
                        'æ‘˜è¦': article.get('abstract', ''),
                        'å…³é”®è¯': keywords_str,
                        'URL': article.get('url', '')
                    }
                    
                    writer.writerow(row_data)
            
            print(f"[FILE] æ–‡çŒ®æ£€ç´¢ç»“æœå·²ä¿å­˜è‡³: {filepath}")
            
        except Exception as e:
            print(f"[FAIL] ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
    
    def _print_filtered_summary(self):
        """æ˜¾ç¤ºç­›é€‰ç»“æœæ‘˜è¦"""
        if not self.filtered_results:
            return
            
        print("\n[STAT] ç­›é€‰ç»“æœæ‘˜è¦:")
        print("=" * 40)
        
        # æ˜¾ç¤ºå‰å‡ ç¯‡æ–‡çŒ®çš„åŸºæœ¬ä¿¡æ¯
        for i, article in enumerate(self.filtered_results[:3], 1):
            title = article.get('title', 'æ— æ ‡é¢˜')[:50] + "..." if len(article.get('title', '')) > 50 else article.get('title', 'æ— æ ‡é¢˜')
            journal = article.get('journal', 'æœªçŸ¥æœŸåˆŠ')
            year = article.get('publication_date', 'æœªçŸ¥å¹´ä»½')
            authors = article.get('authors', 'æœªçŸ¥ä½œè€…')
            
            print(f"{i}. æ ‡é¢˜: {title}")
            print(f"   æœŸåˆŠ: {journal} ({year})")
            print(f"   ä½œè€…: {authors[:30]}..." if len(authors) > 30 else f"   ä½œè€…: {authors}")
            print()
        
        if len(self.filtered_results) > 3:
            print(f"... è¿˜æœ‰ {len(self.filtered_results) - 3} ç¯‡æ–‡çŒ®")
        print("=" * 40)
    
    def _ask_user_continue(self) -> bool:
        """
        è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­ç”Ÿæˆç»¼è¿°å¤§çº²
        
        Returns:
            bool: Trueè¡¨ç¤ºç»§ç»­ï¼ŒFalseè¡¨ç¤ºè¿”å›é‡æ–°è¾“å…¥
        """
        if not self.interactive_mode:
            # éäº¤äº’æ¨¡å¼é»˜è®¤ç»§ç»­
            return True
        
        print(f"\nâ“ åŸºäºä»¥ä¸Š {len(self.filtered_results)} ç¯‡æ–‡çŒ®ï¼Œæ˜¯å¦ç»§ç»­ç”Ÿæˆç»¼è¿°å¤§çº²ï¼Ÿ")
        print("   [y] ç»§ç»­ç”Ÿæˆç»¼è¿°å¤§çº²å’Œæ–‡ç« ")
        print("   [n] è¿”å›é‡æ–°è¾“å…¥æ£€ç´¢éœ€æ±‚")
        print("   [s] æ˜¾ç¤ºæ›´å¤šç­›é€‰ç»“æœè¯¦æƒ…")
        
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹© (y/n/s) [y]: ").strip().lower()
                
                if choice in ['', 'y', 'yes']:
                    print("[OK] ç»§ç»­ç”Ÿæˆç»¼è¿°å¤§çº²...")
                    return True
                elif choice in ['n', 'no']:
                    return False
                elif choice in ['s', 'show']:
                    self._show_detailed_results()
                    print(f"\nâ“ åŸºäºä»¥ä¸Š {len(self.filtered_results)} ç¯‡æ–‡çŒ®ï¼Œæ˜¯å¦ç»§ç»­ç”Ÿæˆç»¼è¿°å¤§çº²ï¼Ÿ")
                    print("   [y] ç»§ç»­ç”Ÿæˆç»¼è¿°å¤§çº²å’Œæ–‡ç« ")
                    print("   [n] è¿”å›é‡æ–°è¾“å…¥æ£€ç´¢éœ€æ±‚")
                    continue
                else:
                    print("è¯·è¾“å…¥ yã€n æˆ– s")
                    continue
                    
            except (EOFError, KeyboardInterrupt):
                print("\n[WARN]  ç”¨æˆ·ä¸­æ–­ï¼Œè¿”å›è¾“å…¥...")
                return False
    
    def _show_detailed_results(self):
        """æ˜¾ç¤ºè¯¦ç»†çš„ç­›é€‰ç»“æœ"""
        print("\nğŸ“š è¯¦ç»†ç­›é€‰ç»“æœ:")
        print("=" * 60)
        
        for i, article in enumerate(self.filtered_results, 1):
            title = article.get('title', 'æ— æ ‡é¢˜')
            journal = article.get('journal', 'æœªçŸ¥æœŸåˆŠ')
            year = article.get('publication_date', 'æœªçŸ¥å¹´ä»½')
            authors = article.get('authors', 'æœªçŸ¥ä½œè€…')
            abstract = article.get('abstract', 'æ— æ‘˜è¦')
            
            print(f"{i}. ã€{journal}ã€‘ {title}")
            print(f"   ä½œè€…: {authors}")
            print(f"   å¹´ä»½: {year}")
            
            # æ˜¾ç¤ºæ‘˜è¦å‰150å­—ç¬¦
            if abstract and len(abstract) > 10:
                abstract_preview = abstract[:150] + "..." if len(abstract) > 150 else abstract
                print(f"   æ‘˜è¦: {abstract_preview}")
            
            print("-" * 60)
    
    def _try_resume_workflow(self) -> Optional[Dict]:
        """å°è¯•æ¢å¤ä¹‹å‰çš„å·¥ä½œæµç¨‹"""
        if not self.state_manager:
            return None
        
        state = self.state_manager.load_state()
        if not state or not state.get('processing', False):
            return None
        
        print("\nå‘ç°æœªå®Œæˆçš„ä»»åŠ¡ï¼Œå°è¯•æ¢å¤...")
        print(f"ä»»åŠ¡ä¿¡æ¯: {state.get('user_query', 'æœªçŸ¥')}")
        print(f"ä¸Šæ¬¡è¿›åº¦: ç¬¬ {state.get('current_step', 0)} æ­¥")
        
        if self.interactive_mode:
            try:
                choice = input("æ˜¯å¦æ¢å¤ä¹‹å‰çš„ä»»åŠ¡? (y/n) [y]: ").strip().lower()
                if choice in ['', 'y', 'yes']:
                    print("æ­£åœ¨æ¢å¤ä»»åŠ¡...")
                    # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æ¢å¤é€»è¾‘
                    # ç›®å‰ç®€å•è¿”å›Noneï¼Œè®©ç”¨æˆ·é‡æ–°å¼€å§‹
                else:
                    self.state_manager.clear_state()
                    print("å·²æ¸…é™¤ä¹‹å‰çš„ä»»åŠ¡çŠ¶æ€")
                    return None
            except (EOFError, KeyboardInterrupt):
                print("ç”¨æˆ·ä¸­æ–­")
                return None
        
        return None
    
    def _print_performance_summary(self, performance_report: Dict):
        """æ‰“å°ä¼˜åŒ–çš„æ€§èƒ½æ‘˜è¦"""
        print("\næ€§èƒ½åˆ†ææŠ¥å‘Š:")
        print("-" * 50)
        
        # æ˜¾ç¤ºå®é™…æ€»æ—¶é—´ï¼ˆå¢™é’Ÿæ—¶é—´ï¼‰
        actual_time = performance_report.get('actual_total_time', 0)
        print(f"å®é™…æ€»å¤„ç†æ—¶é—´: {actual_time:.2f}ç§’")
        
        # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
        serial_time = performance_report.get('serial_total_time', 0)
        parallel_time = performance_report.get('parallel_total_time', 0)
        
        print(f"ä¸²è¡Œæ“ä½œæ€»æ—¶é—´: {serial_time:.2f}ç§’")
        print(f"å¹¶è¡Œæ“ä½œæœ€å¤§æ—¶é—´: {parallel_time:.2f}ç§’")
        
        print("\nå„ç¯èŠ‚è¯¦ç»†è€—æ—¶:")
        categories = performance_report.get('operation_categories', {})
        
        # æŒ‰ç±»åˆ«æ˜¾ç¤ºæ“ä½œ
        for category, operations in categories.items():
            if not operations:
                continue
                
            category_names = {
                'workflow': 'å·¥ä½œæµç¨‹',
                'serial': 'ä¸²è¡Œæ“ä½œ', 
                'parallel': 'å¹¶è¡Œæ“ä½œ',
                'component': 'ç»„ä»¶åˆå§‹åŒ–'
            }
            
            print(f"\n  {category_names.get(category, category)}:")
            for operation in operations:
                duration = performance_report['operation_times'].get(operation, 0)
                count = performance_report['operation_counts'].get(operation, 1)
                avg_time = performance_report['average_times'].get(operation, duration)
                
                # æ ‡è®°å¹¶è¡Œæ“ä½œ
                parallel_mark = " [å¹¶è¡Œ]" if category == 'parallel' else ""
                print(f"    {operation}: {duration:.2f}ç§’ (å¹³å‡: {avg_time:.2f}ç§’ x {count}æ¬¡){parallel_mark}")
        
        # æ€§èƒ½ç“¶é¢ˆåˆ†æ
        bottlenecks = performance_report.get('bottlenecks', [])
        if bottlenecks:
            print(f"\næ€§èƒ½ç“¶é¢ˆ: {', '.join(bottlenecks)}")
            print("å»ºè®®: ä¼˜åŒ–ä¸Šè¿°ç¯èŠ‚ä»¥æå‡æ•´ä½“æ€§èƒ½")
        
        print("-" * 50)
    
    def _get_processing_time(self) -> str:
        """è·å–å¤„ç†æ—¶é—´ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        return datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    def _enrich_with_journal_info(self, issn_results: List[Dict], search_criteria) -> List[Dict]:
        """
        ä¸ºISSN/EISSNä¿¡æ¯åŒ¹é…æœŸåˆŠè´¨é‡ä¿¡æ¯
        
        Args:
            issn_results: åŒ…å«ISSN/EISSNä¿¡æ¯çš„æ–‡ç« åˆ—è¡¨
            search_criteria: æœç´¢æ¡ä»¶
        
        Returns:
            åŒ…å«æœŸåˆŠè´¨é‡ä¿¡æ¯çš„æ–‡ç« åˆ—è¡¨
        """
        if not issn_results or not self.literature_filter:
            return issn_results
        
        enriched_results = []
        total_count = len(issn_results)
        
        print(f"å¼€å§‹åŒ¹é…æœŸåˆŠè´¨é‡ä¿¡æ¯ï¼Œå…± {total_count} ç¯‡æ–‡çŒ®...")
        
        for i, article in enumerate(issn_results):
            issn = article.get('issn', '')
            eissn = article.get('eissn', '')
            
            # è·å–æœŸåˆŠè´¨é‡ä¿¡æ¯
            journal_info = self.literature_filter.get_journal_info(issn, eissn)
            
            # æ·»åŠ æœŸåˆŠä¿¡æ¯åˆ°æ–‡ç« æ•°æ®ä¸­
            enriched_article = article.copy()
            enriched_article['journal_info'] = journal_info
            
            enriched_results.append(enriched_article)
            
            # æ˜¾ç¤ºè¿›åº¦
            if (i + 1) % 50 == 0:
                print(f"æœŸåˆŠä¿¡æ¯åŒ¹é…è¿›åº¦: {i + 1}/{total_count}")
        
        print(f"æœŸåˆŠä¿¡æ¯åŒ¹é…å®Œæˆï¼ŒæˆåŠŸåŒ¹é…: {len([r for r in enriched_results if r['journal_info']])}/{total_count} ç¯‡")
        return enriched_results
    
    def _filter_by_user_criteria(self, enriched_results: List[Dict], search_criteria) -> List[str]:
        """
        æ ¹æ®ç”¨æˆ·éœ€æ±‚è¿›è¡Œç­›é€‰
        
        Args:
            enriched_results: åŒ…å«æœŸåˆŠè´¨é‡ä¿¡æ¯çš„æ–‡ç« åˆ—è¡¨
            search_criteria: æœç´¢æ¡ä»¶
        
        Returns:
            ç­›é€‰åçš„PMIDåˆ—è¡¨
        """
        filtered_pmids = []
        total_count = len(enriched_results)
        
        print(f"å¼€å§‹æ ¹æ®ç”¨æˆ·éœ€æ±‚ç­›é€‰ï¼Œå…± {total_count} ç¯‡æ–‡çŒ®...")
        
        # ä»æœç´¢æ¡ä»¶ä¸­æå–ç­›é€‰æ ‡å‡†
        min_impact_factor = getattr(search_criteria, 'min_if', 0) or 0
        target_zones = getattr(search_criteria, 'cas_zones', [])
        target_quartiles = getattr(search_criteria, 'jcr_quartiles', [])
        
            
        for i, article in enumerate(enriched_results):
            pmid = article.get('pmid', '')
            journal_info = article.get('journal_info', {})
            
            # é»˜è®¤ä¸ä¿ç•™æ²¡æœ‰æœŸåˆŠä¿¡æ¯çš„æ–‡ç« 
            should_include = bool(journal_info)
            
            if journal_info:
                # æ£€æŸ¥å½±å“å› å­æ¡ä»¶
                if min_impact_factor > 0:
                    impact_factor = journal_info.get('impact_factor')
                    if not impact_factor or float(impact_factor) < min_impact_factor:
                        should_include = False
                
                # æ£€æŸ¥ä¸­ç§‘é™¢åˆ†åŒºæ¡ä»¶
                if should_include and target_zones:
                    cas_zone = journal_info.get('cas_zone')
                    if not cas_zone or cas_zone not in target_zones:
                        should_include = False
                
                # æ£€æŸ¥JCRåˆ†åŒºæ¡ä»¶
                if should_include and target_quartiles:
                    jcr_quartile = journal_info.get('jcr_quartile')
                    if not jcr_quartile or jcr_quartile not in target_quartiles:
                        should_include = False
            
            if should_include:
                filtered_pmids.append(pmid)
            
            # æ˜¾ç¤ºè¿›åº¦
            if (i + 1) % 50 == 0:
                print(f"ç”¨æˆ·éœ€æ±‚ç­›é€‰è¿›åº¦: {i + 1}/{total_count} (å·²ç­›é€‰: {len(filtered_pmids)} ç¯‡)")
        
        print(f"ç”¨æˆ·éœ€æ±‚ç­›é€‰å®Œæˆ: {total_count} ç¯‡ -> {len(filtered_pmids)} ç¯‡")
        return filtered_pmids
    
    def _extract_core_research_topic(self, user_input: str) -> str:
        """
        ä»ç”¨æˆ·è¾“å…¥ä¸­æå–æ ¸å¿ƒç ”ç©¶ä¸»é¢˜ï¼Œç§»é™¤ç­›é€‰æ¡ä»¶
        
        Args:
            user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
            
        Returns:
            str: æå–çš„æ ¸å¿ƒç ”ç©¶ä¸»é¢˜
        """
        import re
        
        # å®šä¹‰éœ€è¦ç§»é™¤çš„ç­›é€‰æ¡ä»¶å…³é”®è¯ï¼ˆæ·»åŠ é«˜åˆ†æ–‡ç« è¯†åˆ«ï¼‰
        filter_patterns = [
            # æœŸåˆŠåˆ†åŒºç›¸å…³ - å®Œæ•´ç§»é™¤
            r'ä¸­ç§‘é™¢[1-4ä¸€äºŒä¸‰å››]?åŒº?[1-4ä¸€äºŒä¸‰å››]?åŒº?[æœŸåˆŠ]*',
            r'ä¸­ç§‘é™¢.*?åˆ†åŒº', r'CAS.*?åˆ†åŒº', 
            r'JCR.*?åˆ†åŒº', r'JCR.*?Q[1-4]', r'Q[1-4]åŒº?',
            r'[1-4ä¸€äºŒä¸‰å››]åŒº[2-4äºŒä¸‰å››]?åŒº?',
            r'åˆ†åŒº[1-4ä¸€äºŒä¸‰å››\-\s]+åŒº?',
            
            # å½±å“å› å­ç›¸å…³ - ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
            r'å½±å“å› å­.*?[>ï¼å¤§äºé«˜äºè¶…è¿‡å°äºä½äº<ï¼œ]\s*\d+\.?\d*åˆ†?',
            r'é«˜å½±å“å› å­', r'é¡¶çº§å½±å“å› å­', r'ä½å½±å“å› å­',
            r'IF\s*[>ï¼<ï¼œ]\s*\d+\.?\d*',
            r'[>ï¼å¤§äºé«˜äºè¶…è¿‡å°äºä½äº<ï¼œ]\s*\d+\.?\d*åˆ†?',
            
            # æœŸåˆŠè´¨é‡ç›¸å…³ - åŠ å¼ºæœŸåˆŠè¿‡æ»¤
            r'é¡¶çº§æœŸåˆŠ', r'é«˜è´¨é‡æœŸåˆŠ', r'æƒå¨æœŸåˆŠ', r'æ ¸å¿ƒæœŸåˆŠ',
            r'SCIæœŸåˆŠ', r'SSCIæœŸåˆŠ', r'EIæœŸåˆŠ',
            r'high\s+impact\s+factor', r'journals?', r'æœŸåˆŠ',
            r'JCR\s*Q[1-4]\s*æœŸåˆŠ', r'Q[1-4]\s*æœŸåˆŠ',
            
            # æ–‡ç« è´¨é‡ç›¸å…³ - æ–°å¢é«˜åˆ†æ–‡ç« è¯†åˆ«
            r'é«˜åˆ†æ–‡ç« ', r'é«˜è´¨é‡æ–‡ç« ', r'é¡¶çº§æ–‡ç« ', r'æƒå¨æ–‡ç« ',
            r'é«˜åˆ†', r'é«˜è´¨é‡', r'é¡¶çº§', r'æƒå¨',
            
            # ç»“å°¾çš„ä¿®é¥°è¯
            r'çš„?ç ”ç©¶$', r'çš„?æ–‡çŒ®$', r'çš„?ç»¼è¿°$', r'è¿›å±•$',
            r'research$', r'study$', r'studies$',
        ]
        
        # æå–æ—¶é—´èŒƒå›´ï¼ˆå…ˆæå–ï¼Œåé¢é‡æ–°æ·»åŠ ï¼‰
        time_patterns = [
            r'è¿‘\d+å¹´', r'æœ€è¿‘\d+å¹´', r'è¿‡å»\d+å¹´', r'å‰\d+å¹´',
            r'è¿‘å‡ å¹´', r'æœ€è¿‘å‡ å¹´', r'è¿‘å¹´æ¥', r'æœ€è¿‘', r'è¿‘æœŸ',
            r'\d{4}å¹´?[-åˆ°è‡³]\d{4}å¹´?', r'\d{4}å¹´?ä»¥æ¥', r'\d{4}å¹´?è‡³ä»Š'
        ]
        
        time_range = ""
        for pattern in time_patterns:
            match = re.search(pattern, user_input)
            if match:
                time_range = match.group()
                break
        
        # å¼€å§‹æ¸…ç†
        clean_topic = user_input.strip()
        
        # æ£€æµ‹æ˜¯å¦åŒ…å«è‹±æ–‡å†…å®¹
        is_english_content = re.search(r'[a-zA-Z]', clean_topic)
        
        # ç§»é™¤ç­›é€‰æ¡ä»¶å…³é”®è¯
        for pattern in filter_patterns:
            clean_topic = re.sub(pattern, '', clean_topic, flags=re.IGNORECASE)
        
        # ç‰¹æ®Šå¤„ç†ï¼šç§»é™¤æ•°å­—+åŒºçš„ç»„åˆï¼ˆå¦‚"1-2åŒº"ï¼‰
        clean_topic = re.sub(r'\d+[-\s]*\d*åŒº', '', clean_topic)
        
        # æ¸…ç†è¿ç»­çš„æ ‡ç‚¹ç¬¦å·
        clean_topic = re.sub(r'[,ï¼Œã€ï¼›;]+', '', clean_topic)
        clean_topic = re.sub(r'^[å’Œä¸åŠçš„]', '', clean_topic)
        
        # é¢å¤–å¤„ç†ï¼š"çš„"å­—ç»“å°¾æ¸…ç†
        clean_topic = re.sub(r'çš„$', '', clean_topic)
        
        # å¤„ç†è‹±æ–‡è¾“å…¥çš„ç‰¹æ®Šæƒ…å†µï¼ˆåœ¨ç§»é™¤ç©ºæ ¼ä¹‹å‰ï¼‰
        if is_english_content:
            # è‹±æ–‡è¾“å…¥ï¼Œä¿ç•™ä¸»è¦å•è¯ï¼Œç§»é™¤ä¿®é¥°è¯
            english_filter_words = ['high', 'impact', 'factor', 'journals', 'journal', 'Q1', 'Q2', 'Q3', 'Q4']
            # å…ˆæ ‡å‡†åŒ–ç©ºæ ¼
            clean_topic = re.sub(r'\s+', ' ', clean_topic)
            words = clean_topic.split()
            filtered_words = [word for word in words if word.lower() not in english_filter_words]
            if filtered_words:
                clean_topic = ' '.join(filtered_words)
        else:
            # çº¯ä¸­æ–‡å†…å®¹ï¼Œç§»é™¤å¤šä½™ç©ºæ ¼ä½†ä¿ç•™å¿…è¦çš„åˆ†éš”
            clean_topic = re.sub(r'\s+', '', clean_topic)
        
        clean_topic = clean_topic.strip()
        
        # ç‰¹æ®Šæƒ…å†µå¤„ç†ï¼šå¦‚æœåªå‰©ä¸‹"æœŸåˆŠ"æˆ–ç±»ä¼¼çš„æ— æ„ä¹‰è¯æ±‡ï¼Œåˆ™å›é€€åˆ°é»˜è®¤å¤„ç†
        meaningless_keywords = ['æœŸåˆŠ', 'journals', 'journal', 'ç ”ç©¶', 'æ–‡çŒ®', 'ç»¼è¿°']
        if clean_topic in meaningless_keywords:
            clean_topic = ""
        
        # å¦‚æœæ¸…ç†åå¤ªçŸ­ï¼Œå°è¯•ä»åŸå§‹è¾“å…¥ä¸­æå–æ ¸å¿ƒæ¦‚å¿µ
        if len(clean_topic) < 3:
            # å®šä½æ ¸å¿ƒåŒ»å­¦æ¦‚å¿µ
            medical_concepts = re.findall(r'ç³–å°¿ç—…|é«˜è¡€å‹|å¿ƒè¡€ç®¡|è‚¿ç˜¤|ç™Œç—‡|COVID-19|ç–«è‹—|æ²»ç–—|è¯Šæ–­|æœºå™¨å­¦ä¹ ', user_input)
            if medical_concepts:
                clean_topic = medical_concepts[0]
            else:
                # è‹±æ–‡æ¦‚å¿µæå–
                english_concepts = re.findall(r'\b(?:diabetes|COVID-19|cancer|treatment|therapy|diagnosis|machine\s+learning|vaccine)\b', user_input, re.IGNORECASE)
                if english_concepts:
                    clean_topic = english_concepts[0]
        
        # é‡æ–°æ·»åŠ æ—¶é—´èŒƒå›´ï¼Œæ³¨æ„é¡ºåº
        if time_range and time_range not in clean_topic:
            # æ£€æŸ¥æ—¶é—´èŒƒå›´åœ¨åŸå§‹è¾“å…¥ä¸­çš„ä½ç½®
            time_pos = user_input.find(time_range) if time_range in user_input else -1
            
            # æ£€æŸ¥æ ¸å¿ƒåŒ»å­¦æ¦‚å¿µåœ¨åŸå§‹è¾“å…¥ä¸­çš„ä½ç½®
            core_medical_pos = -1
            if clean_topic:
                # å°è¯•æ‰¾åˆ°æ ¸å¿ƒä¸»é¢˜åœ¨åŸå§‹è¾“å…¥ä¸­çš„ä½ç½®
                core_medical_pos = user_input.find(clean_topic.replace(time_range, '').strip())
            
            if is_english_content:
                if time_pos != -1 and (core_medical_pos == -1 or time_pos < core_medical_pos):
                    # æ—¶é—´èŒƒå›´åœ¨å‰é¢
                    clean_topic = time_range + ' ' + clean_topic
                else:
                    # æ—¶é—´èŒƒå›´åœ¨åé¢
                    clean_topic = clean_topic + ' ' + time_range
            else:
                # ä¸­æ–‡å¤„ç†ï¼šç‰¹æ®Šå¤„ç†"è¿‘å¹´æ¥"ç­‰å‰ç½®æ—¶é—´è¯
                if time_range in ['è¿‘å¹´æ¥', 'æœ€è¿‘', 'è¿‘æœŸ'] and time_pos != -1 and (core_medical_pos == -1 or time_pos < core_medical_pos):
                    # å‰ç½®æ—¶é—´è¯ï¼Œå¦‚"è¿‘å¹´æ¥ç³–å°¿ç—…ç ”ç©¶" -> "ç³–å°¿ç—…è¿‘å¹´æ¥"
                    clean_topic = clean_topic + time_range
                else:
                    # æ—¶é—´èŒƒå›´åœ¨åé¢ï¼Œå¦‚"ç³–å°¿ç—…æ²»ç–—è¿‘5å¹´"
                    clean_topic = clean_topic + time_range
        
        # æœ€ç»ˆæ¸…ç†
        clean_topic = clean_topic.strip()
        
        # å¦‚æœä»ç„¶ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œä½¿ç”¨é»˜è®¤ä¸»é¢˜
        if not clean_topic or len(clean_topic) < 2:
            clean_topic = "åŒ»å­¦ç ”ç©¶"
        
        return clean_topic

    def _print_summary(self, result: Dict):
        """æ‰“å°å¤„ç†ç»“æœæ‘˜è¦"""
        print(f"å¤„ç†ç»“æœæ‘˜è¦:")
        print(f"   ç”¨æˆ·éœ€æ±‚: {result['user_query']}")
        print(f"   æ£€ç´¢åˆ°æ–‡çŒ®: {result['total_found']} ç¯‡")
        print(f"   ç­›é€‰åæ–‡çŒ®: {result['filtered_count']} ç¯‡")
        print(f"   ç”Ÿæˆæ–‡ä»¶: {result['review_file']}")
        
        # æ˜¾ç¤ºDOCXæ–‡ä»¶ä¿¡æ¯
        if result.get('docx_file'):
            print(f"   DOCXç‰ˆæœ¬: {result['docx_file']}")
        else:
            print(f"   DOCXç‰ˆæœ¬: æœªå¯¼å‡º (éœ€è¦å®‰è£…Pandoc)")
            
        print(f"   å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    try:
        # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
        asyncio.run(main_async())
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nç³»ç»Ÿè¿è¡Œå‡ºç°å¼‚å¸¸: {e}")
        if '--debug' in sys.argv:
            traceback.print_exc()
        sys.exit(1)


async def main_async():
    """å¼‚æ­¥ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ™ºèƒ½æ–‡çŒ®æ£€ç´¢ä¸ç»¼è¿°ç”Ÿæˆç³»ç»Ÿ v2.0',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # äº¤äº’å¼æ¨¡å¼
  python intelligent_literature_system.py
  
  # å‘½ä»¤è¡Œæ¨¡å¼
  python intelligent_literature_system.py -q "ç³–å°¿ç—…æ²»ç–—è¿‘5å¹´è¿›å±•" --max-results 100 --target 30
  
  # æŒ‡å®šAIé…ç½®
  python intelligent_literature_system.py -q "COVID-19ç–«è‹—æ•ˆæœ" --ai-config aiwave_gemini
  
  # æ€§èƒ½ä¼˜åŒ–é€‰é¡¹
  python intelligent_literature_system.py --no-cache --no-state --debug
  
  # æ–­ç‚¹ç»­ä¼ 
  python intelligent_literature_system.py --resume
        """
    )
    
    parser.add_argument('-q', '--query', help='ç”¨æˆ·æ£€ç´¢éœ€æ±‚')
    parser.add_argument('--max-results', type=int, default=50, help='æœ€å¤§æ£€ç´¢ç»“æœæ•° (é»˜è®¤: 50)')
    parser.add_argument('--target', type=int, default=20, help='ç›®æ ‡ç­›é€‰æ–‡ç« æ•° (é»˜è®¤: 20)')
    parser.add_argument('--ai-config', help='AIé…ç½®åç§°')
    parser.add_argument('--non-interactive-ai', action='store_true', help='éäº¤äº’å¼AIé…ç½®ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹å’Œå‚æ•°ï¼‰')
    
    # æ–°å¢ä¼˜åŒ–é€‰é¡¹
    parser.add_argument('--no-cache', action='store_true', help='ç¦ç”¨ç¼“å­˜ç³»ç»Ÿ')
    parser.add_argument('--no-state', action='store_true', help='ç¦ç”¨çŠ¶æ€ç®¡ç†')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--resume', action='store_true', help='å°è¯•æ¢å¤ä¹‹å‰çš„ä»»åŠ¡')
    parser.add_argument('--clear-cache', action='store_true', help='æ¸…é™¤æ‰€æœ‰ç¼“å­˜')
    
    args = parser.parse_args()
    
    # æ¸…é™¤ç¼“å­˜
    if args.clear_cache:
        cache_system = IntelligentCache()
        cache_system.clear_cache()
        state_manager = StateManager()
        state_manager.clear_state()
        print("ç¼“å­˜å’ŒçŠ¶æ€å·²æ¸…é™¤")
        return
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        system = IntelligentLiteratureSystem(
            ai_config_name=args.ai_config,
            interactive_mode=not args.non_interactive_ai,
            enable_cache=not args.no_cache,
            enable_state=not args.no_state
        )
        
        # åˆå§‹åŒ–ç»„ä»¶
        if not await system.initialize_components():
            print("ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            sys.exit(1)
        
        # è·å–ç”¨æˆ·æŸ¥è¯¢
        print("\n" + "="*60)
        print("[FIND] ç³»ç»Ÿå·²å°±ç»ªï¼Œè¯·è¾“å…¥æ‚¨çš„æ£€ç´¢éœ€æ±‚")
        print("="*60)
        
        while True:  # æ·»åŠ å¾ªç¯æ”¯æŒé‡æ–°è¾“å…¥
            if args.query:
                user_query = args.query
                args.query = None  # æ¸…é™¤å‘½ä»¤è¡Œå‚æ•°ï¼Œé¿å…é‡å¤ä½¿ç”¨
            else:
                # äº¤äº’å¼è¾“å…¥
                print("\nè¯·è¾“å…¥æ‚¨çš„æ£€ç´¢éœ€æ±‚ï¼ˆä¾‹å¦‚ï¼šç³–å°¿ç—…æ²»ç–—è¿‘5å¹´é«˜å½±å“å› å­ç ”ç©¶ï¼‰:")
                print(">>> ", end="", flush=True)
                try:
                    user_query = input().strip()
                except (EOFError, KeyboardInterrupt):
                    print("\nç”¨æˆ·è¾“å…¥ä¸­æ–­")
                    break
                
                if not user_query:
                    print("[FAIL] è¯·æä¾›æœ‰æ•ˆçš„æ£€ç´¢éœ€æ±‚")
                    continue
            
            # è¿è¡Œå®Œæ•´å·¥ä½œæµç¨‹
            result = await system.run_complete_workflow(
                user_query=user_query,
                max_results=args.max_results,
                target_articles=args.target,
                enable_resume=args.resume
            )
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è¾“å…¥
            if result.get("restart"):
                print("\n" + "="*50)
                continue  # é‡æ–°å¼€å§‹å¾ªç¯
            elif result["success"]:
                print("\nç³»ç»Ÿè¿è¡ŒæˆåŠŸå®Œæˆï¼")
                
                # æ˜¾ç¤ºæ€§èƒ½æŠ¥å‘Š
                if 'performance_report' in result:
                    print("\næ€§èƒ½åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ")
                    if args.debug:
                        system._print_performance_summary(result['performance_report'])
                
                sys.exit(0)
            else:
                print(f"\nç³»ç»Ÿè¿è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                if args.debug and 'details' in result:
                    print(f"è¯¦ç»†ä¿¡æ¯: {result['details']}")
                
                # è¯¢é—®æ˜¯å¦é‡è¯•
                if not args.non_interactive_ai:
                    try:
                        retry = input("æ˜¯å¦é‡æ–°è¾“å…¥æ£€ç´¢éœ€æ±‚ï¼Ÿ(y/n) [y]: ").strip().lower()
                        if retry in ['', 'y', 'yes']:
                            continue
                    except (EOFError, KeyboardInterrupt):
                        pass
                sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nç³»ç»Ÿè¿è¡Œå‡ºç°å¼‚å¸¸: {e}")
        if args.debug:
            traceback.print_exc()
        sys.exit(1)
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        system = IntelligentLiteratureSystem(
            ai_config_name=args.ai_config,
            interactive_mode=not args.non_interactive_ai
        )
        
        # åˆå§‹åŒ–ç»„ä»¶
        if not await system.initialize_components():
            sys.exit(1)
        
        # è·å–ç”¨æˆ·æŸ¥è¯¢
        while True:  # æ·»åŠ å¾ªç¯æ”¯æŒé‡æ–°è¾“å…¥
            if args.query:
                user_query = args.query
                args.query = None  # æ¸…é™¤å‘½ä»¤è¡Œå‚æ•°ï¼Œé¿å…é‡å¤ä½¿ç”¨
            else:
                # äº¤äº’å¼è¾“å…¥
                print("è¯·è¾“å…¥æ‚¨çš„æ£€ç´¢éœ€æ±‚ï¼ˆä¾‹å¦‚ï¼šç³–å°¿ç—…æ²»ç–—è¿‘5å¹´é«˜å½±å“å› å­ç ”ç©¶ï¼‰:")
                user_query = input(">>> ").strip()
                
                if not user_query:
                    print("[FAIL] è¯·æä¾›æœ‰æ•ˆçš„æ£€ç´¢éœ€æ±‚")
                    continue
            
            # è¿è¡Œå®Œæ•´å·¥ä½œæµç¨‹
            result = system.run_complete_workflow(
                user_query=user_query,
                max_results=args.max_results,
                target_articles=args.target
            )
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è¾“å…¥
            if result.get("restart"):
                print("\n" + "="*50)
                continue  # é‡æ–°å¼€å§‹å¾ªç¯
            elif result["success"]:
                print("\n[TARGET] ç³»ç»Ÿè¿è¡ŒæˆåŠŸå®Œæˆï¼")
                sys.exit(0)
            else:
                print(f"\n[FAIL] ç³»ç»Ÿè¿è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                # è¯¢é—®æ˜¯å¦é‡è¯•
                if not args.non_interactive_ai:
                    try:
                        retry = input("æ˜¯å¦é‡æ–°è¾“å…¥æ£€ç´¢éœ€æ±‚ï¼Ÿ(y/n) [y]: ").strip().lower()
                        if retry in ['', 'y', 'yes']:
                            continue
                    except (EOFError, KeyboardInterrupt):
                        pass
                sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\n[WARN]  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"\n[FAIL] ç³»ç»Ÿè¿è¡Œå‡ºç°å¼‚å¸¸: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()