#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”¨æˆ·æ„å›¾åˆ†æå’Œæ£€ç´¢è¯æ„å»ºæ¨¡å— v2.0
åŸºäºAIå¤§æ¨¡å‹åˆ†æç”¨æˆ·è¾“å…¥ï¼Œç”ŸæˆPubMedæ£€ç´¢è¯å’Œç­›é€‰æ¡ä»¶
ä¼˜åŒ–ç‰¹æ€§ï¼šæ™ºèƒ½ç¼“å­˜ã€å¼‚æ­¥å¤„ç†ã€å¢å¼ºé”™è¯¯å¤„ç†ã€é…ç½®ç®¡ç†ä¼˜åŒ–
"""

import json
import os
import re
import time
import asyncio
import hashlib
import threading
from typing import Dict, List, Optional, Tuple, Any, TYPE_CHECKING
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
from ai_client import AIClient, ConfigManager, ChatMessage
from prompts_manager import PromptsManager
from dataclasses import dataclass, asdict


@dataclass
class AIModelConfig:
    """AIæ¨¡å‹é…ç½®ç¼“å­˜"""
    config_name: str
    model_id: str
    parameters: Dict
    
    def to_dict(self):
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict):
        return cls(**data)


class IntentAnalysisCache:
    """æ„å›¾åˆ†æç»“æœç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_size: int = 500, ttl: int = 3600):
        self.cache_size = cache_size
        self.ttl = ttl
        self.cache = {}
        self.access_times = {}
        self.lock = threading.Lock()
        self.stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0
        }
    
    def _generate_cache_key(self, user_input: str, model_id: str, parameters: Dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{user_input}:{model_id}:{json.dumps(parameters, sort_keys=True)}"
        return hashlib.sha256(content.encode('utf-8')).hexdigest()
    
    def get(self, user_input: str, model_id: str, parameters: Dict) -> Optional['SearchCriteria']:
        """è·å–ç¼“å­˜çš„æ„å›¾åˆ†æç»“æœ"""
        cache_key = self._generate_cache_key(user_input, model_id, parameters)
        
        with self.lock:
            if cache_key in self.cache:
                cache_data = self.cache[cache_key]
                if time.time() - cache_data['timestamp'] < self.ttl:
                    self.access_times[cache_key] = time.time()
                    self.stats['hits'] += 1
                    return cache_data['criteria']
                else:
                    # æ¸…é™¤è¿‡æœŸç¼“å­˜
                    del self.cache[cache_key]
                    if cache_key in self.access_times:
                        del self.access_times[cache_key]
                    self.stats['evictions'] += 1
        
        self.stats['misses'] += 1
        return None
    
    def put(self, user_input: str, model_id: str, parameters: Dict, criteria: 'SearchCriteria'):
        """ç¼“å­˜æ„å›¾åˆ†æç»“æœ"""
        cache_key = self._generate_cache_key(user_input, model_id, parameters)
        
        with self.lock:
            # LRUç¼“å­˜æ¸…ç†
            if len(self.cache) >= self.cache_size:
                oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
                del self.cache[oldest_key]
                del self.access_times[oldest_key]
                self.stats['evictions'] += 1
            
            self.cache[cache_key] = {
                'criteria': criteria,
                'timestamp': time.time(),
                'user_input': user_input,
                'model_id': model_id,
                'parameters': parameters
            }
            self.access_times[cache_key] = time.time()
    
    def clear(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        with self.lock:
            self.cache.clear()
            self.access_times.clear()
            self.stats = {'hits': 0, 'misses': 0, 'evictions': 0}
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            total_requests = self.stats['hits'] + self.stats['misses']
            hit_rate = self.stats['hits'] / total_requests if total_requests > 0 else 0
            
            return {
                'cache_size': len(self.cache),
                'max_cache_size': self.cache_size,
                'hit_rate': hit_rate,
                'hits': self.stats['hits'],
                'misses': self.stats['misses'],
                'evictions': self.stats['evictions']
            }


class ConfigManagerPool:
    """é…ç½®ç®¡ç†å™¨æ±  - é¿å…é‡å¤åˆå§‹åŒ–"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.config_managers = {}
            self.ai_clients = {}
            self.adapters = {}
            self.lock = threading.Lock()
            self._initialized = True
    
    def get_config_manager(self, config_file: str = "ai_config.yaml") -> ConfigManager:
        """è·å–é…ç½®ç®¡ç†å™¨å®ä¾‹"""
        with self.lock:
            if config_file not in self.config_managers:
                self.config_managers[config_file] = ConfigManager(config_file)
            return self.config_managers[config_file]
    
    def get_ai_client(self, config_file: str = "ai_config.yaml", 
                     enable_cache: bool = True, enable_retry: bool = True) -> AIClient:
        """è·å–AIå®¢æˆ·ç«¯å®ä¾‹"""
        key = f"{config_file}:{enable_cache}:{enable_retry}"
        with self.lock:
            if key not in self.ai_clients:
                self.ai_clients[key] = AIClient(enable_cache, enable_retry)
            return self.ai_clients[key]
    
    def clear_all(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜çš„å®ä¾‹"""
        with self.lock:
            self.config_managers.clear()
            self.ai_clients.clear()
            self.adapters.clear()


@dataclass
class SearchCriteria:
    """æœç´¢æ¡ä»¶æ•°æ®ç±»"""
    query: str  # PubMedæ£€ç´¢è¯
    year_start: Optional[int] = None  # èµ·å§‹å¹´ä»½
    year_end: Optional[int] = None  # ç»“æŸå¹´ä»½
    min_if: Optional[float] = None  # æœ€å°å½±å“å› å­
    max_if: Optional[float] = None  # æœ€å¤§å½±å“å› å­
    cas_zones: List[int] = None  # ä¸­ç§‘é™¢åˆ†åŒºé™åˆ¶ [1,2,3,4]
    jcr_quartiles: List[str] = None  # JCRåˆ†åŒºé™åˆ¶ ["Q1","Q2","Q3","Q4"]
    keywords: List[str] = None  # å…³é”®è¯è¿‡æ»¤
    
    def __post_init__(self):
        if self.cas_zones is None:
            self.cas_zones = []
        if self.jcr_quartiles is None:
            self.jcr_quartiles = []
        if self.keywords is None:
            self.keywords = []


class IntentAnalyzer:
    """ç”¨æˆ·æ„å›¾åˆ†æå™¨ v2.0 - ä¼˜åŒ–ç‰ˆ"""
    
    CONFIG_CACHE_FILE = "ai_model_cache.json"
    
    def __init__(self, config_name: str = None, interactive: bool = True, 
                 enable_cache: bool = True, enable_async: bool = True, 
                 validate_cache: bool = True):
        """
        åˆå§‹åŒ–æ„å›¾åˆ†æå™¨
        
        Args:
            config_name: AIé…ç½®åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨é…ç½®
            interactive: æ˜¯å¦äº¤äº’å¼é€‰æ‹©æ¨¡å‹å’Œå‚æ•°
            enable_cache: æ˜¯å¦å¯ç”¨æ„å›¾åˆ†æç¼“å­˜
            enable_async: æ˜¯å¦å¯ç”¨å¼‚æ­¥å¤„ç†èƒ½åŠ›
            validate_cache: æ˜¯å¦éªŒè¯ç¼“å­˜æ¨¡å‹çš„æœ‰æ•ˆæ€§
        """
        # ä½¿ç”¨é…ç½®ç®¡ç†å™¨æ± é¿å…é‡å¤åˆå§‹åŒ–
        self.config_pool = ConfigManagerPool()
        self.config_manager = self.config_pool.get_config_manager()
        self.ai_client = self.config_pool.get_ai_client()
        
        self.config_name = config_name
        self.interactive = interactive
        self.enable_cache = enable_cache
        self.enable_async = enable_async
        self.validate_cache = validate_cache  # æ·»åŠ ç¼“å­˜éªŒè¯æ§åˆ¶å‚æ•°
        self.model_id = None
        self.model_parameters = {
            "temperature": 0.1, 
            "stream": True,  # å¯ç”¨æµå¼è¾“å‡º
            "max_tokens": None  # ä¸é™åˆ¶tokenæ•°é‡
        }
        
        # åˆå§‹åŒ–æ™ºèƒ½ç¼“å­˜
        self.analysis_cache = IntentAnalysisCache(cache_size=500, ttl=3600) if enable_cache else None
        
        # åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨
        self.prompts_manager = PromptsManager()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_analyses': 0,
            'cache_hits': 0,
            'ai_calls': 0,
            'total_latency': 0.0,
            'errors': 0
        }
        
        # çº¿ç¨‹æ± ç”¨äºå¼‚æ­¥å¤„ç†
        self.thread_pool = ThreadPoolExecutor(max_workers=4) if enable_async else None
        
        # é€‰æ‹©AIé…ç½®
        self.config = self._select_config()
        if self.config:
            self.adapter = self.ai_client.create_adapter(self.config)
            
            if self.interactive:
                # äº¤äº’å¼é€‰æ‹©æ¨¡å‹å’Œå‚æ•°ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
                self._interactive_setup_with_cache()
            else:
                # éäº¤äº’æ¨¡å¼ï¼šæ€»æ˜¯è¯¢é—®æ˜¯å¦ä½¿ç”¨ç¼“å­˜æ¨¡å‹
                self._non_interactive_setup_with_cache()
        else:
            raise RuntimeError("æœªæ‰¾åˆ°å¯ç”¨çš„AIé…ç½®")
    
    def _non_interactive_setup_with_cache(self):
        """éäº¤äº’æ¨¡å¼ä¸‹çš„ç¼“å­˜é…ç½®å¤„ç†"""
        print("\n[AI] AIæ„å›¾åˆ†æå™¨è®¾ç½®")
        print("=" * 30)
        
        # å°è¯•åŠ è½½ç¼“å­˜é…ç½®
        cached_config = self._load_cached_config()
        
        if cached_config:
            print(f"[OK] å‘ç°ä¸Šæ¬¡é…ç½®:")
            print(f"   é…ç½®: {cached_config.config_name}")
            print(f"   æ¨¡å‹: {cached_config.model_id}")
            print(f"   å‚æ•°: temperature={cached_config.parameters.get('temperature', 0.1)}, max_tokens={cached_config.parameters.get('max_tokens', 'None')}")
            
            # éäº¤äº’æ¨¡å¼ä¸‹è‡ªåŠ¨ä½¿ç”¨ç¼“å­˜é…ç½®
            self.model_id = cached_config.model_id
            self.model_parameters.update(cached_config.parameters)
            print(f"[OK] è‡ªåŠ¨ä½¿ç”¨ç¼“å­˜é…ç½®: {self.model_id}")
            print("ä¿æŒå½“å‰å‚æ•°é…ç½®")
            return
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œè·å–æ–°æ¨¡å‹
        print("[FIND] ä»ç«¯ç‚¹è·å–å¯ç”¨æ¨¡å‹...")
        self.model_id = self._get_default_model()
        if self.model_id:
            print(f"[OK] è·å–åˆ°æ¨¡å‹: {self.model_id}")
            print("ä½¿ç”¨é»˜è®¤å‚æ•°")
            
            # ä¿å­˜æ–°é…ç½®åˆ°ç¼“å­˜
            new_config = AIModelConfig(
                config_name=self.config.name,
                model_id=self.model_id,
                parameters={**self.model_parameters, 'stream': True}  # ç¡®ä¿æµå¼è¾“å‡º
            )
            self._save_config_cache(new_config)
        else:
            print("\n" + "="*60)
            print("[ERROR] AIèŠ‚ç‚¹è¿æ¥å¤±è´¥")
            print("="*60)
            print("æ— æ³•ä»è¿œç«¯è·å–AIæ¨¡å‹åˆ—è¡¨ï¼Œè¿™é€šå¸¸è¡¨ç¤ºï¼š")
            print("1. AIæœåŠ¡é…ç½®å¯èƒ½æœ‰è¯¯ï¼ˆAPIå¯†é’¥ã€ç«¯ç‚¹URLç­‰ï¼‰")
            print("2. ç½‘ç»œè¿æ¥é—®é¢˜æˆ–æœåŠ¡ä¸å¯ç”¨")
            print("3. APIé…é¢å·²ç”¨å®Œæˆ–æƒé™ä¸è¶³")
            print("\nè¯·æ£€æŸ¥æ‚¨çš„AIé…ç½®æ–‡ä»¶ (ai_config.yaml) å¹¶ç¡®ä¿ï¼š")
            print("- APIå¯†é’¥æ­£ç¡®ä¸”æœ‰æ•ˆ")
            print("- ç«¯ç‚¹URLæ­£ç¡®") 
            print("- ç½‘ç»œè¿æ¥æ­£å¸¸")
            print("="*60)
            print("\næŒ‰ä»»æ„é”®é€€å‡ºç¨‹åº...")
            try:
                input()
            except (EOFError, KeyboardInterrupt):
                pass
            import sys
            sys.exit(1)
    
    def _load_cached_config(self) -> Optional[AIModelConfig]:
        """åŠ è½½ç¼“å­˜çš„AIé…ç½®å¹¶éªŒè¯æœ‰æ•ˆæ€§"""
        if os.path.exists(self.CONFIG_CACHE_FILE):
            try:
                with open(self.CONFIG_CACHE_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if data.get('config_name') == self.config.name:
                        # æ£€æŸ¥ç¼“å­˜æ—¶é—´ï¼ˆé»˜è®¤7å¤©è¿‡æœŸï¼‰
                        cached_at = data.get('cached_at', 0)
                        cache_age_days = (time.time() - cached_at) / (24 * 3600)
                        
                        if cache_age_days > 7:
                            print(f"[INFO] ç¼“å­˜å·²è¿‡æœŸ ({cache_age_days:.1f}å¤©)ï¼Œå°†é‡æ–°è·å–æ¨¡å‹")
                            os.remove(self.CONFIG_CACHE_FILE)
                            return None
                        
                        # åˆ›å»ºAIModelConfigå¯¹è±¡æ—¶è¿‡æ»¤æ‰æ—¶é—´æˆ³å­—æ®µ
                        config_data = {k: v for k, v in data.items() if k != 'cached_at'}
                        cached_config = AIModelConfig.from_dict(config_data)
                        
                        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦éªŒè¯ç¼“å­˜æ¨¡å‹çš„æœ‰æ•ˆæ€§
                        if self.validate_cache:
                            if self._validate_cached_model(cached_config):
                                print(f"[OK] ç¼“å­˜æ¨¡å‹éªŒè¯é€šè¿‡ (ç¼“å­˜æ—¶é—´: {cache_age_days:.1f}å¤©)")
                                return cached_config
                            else:
                                print(f"[WARN] ç¼“å­˜æ¨¡å‹ {cached_config.model_id} å·²å¤±æ•ˆï¼Œå°†é‡æ–°è·å–")
                                # åˆ é™¤æ— æ•ˆçš„ç¼“å­˜æ–‡ä»¶
                                os.remove(self.CONFIG_CACHE_FILE)
                                return None
                        else:
                            print(f"[INFO] è·³è¿‡ç¼“å­˜éªŒè¯ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜æ¨¡å‹ {cached_config.model_id} (ç¼“å­˜æ—¶é—´: {cache_age_days:.1f}å¤©)")
                            return cached_config
            except Exception as e:
                print(f"åŠ è½½é…ç½®ç¼“å­˜å¤±è´¥: {e}")
                # åˆ é™¤æŸåçš„ç¼“å­˜æ–‡ä»¶
                try:
                    os.remove(self.CONFIG_CACHE_FILE)
                except:
                    pass
        return None
    
    def _validate_cached_model(self, cached_config: AIModelConfig) -> bool:
        """éªŒè¯ç¼“å­˜æ¨¡å‹æ˜¯å¦ä»ç„¶æœ‰æ•ˆ"""
        try:
            print(f"[VALIDATE] éªŒè¯ç¼“å­˜æ¨¡å‹ {cached_config.model_id} çš„æœ‰æ•ˆæ€§...")
            
            # 1. é¦–å…ˆæ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿˜åœ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­
            available_models = self.adapter.get_available_models()
            if not available_models:
                print("[VALIDATE] æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œè·³è¿‡ç¼“å­˜éªŒè¯")
                return False
            
            # æ£€æŸ¥æ¨¡å‹IDæ˜¯å¦åœ¨å¯ç”¨åˆ—è¡¨ä¸­
            cached_model_available = any(
                model.id == cached_config.model_id for model in available_models
            )
            
            if not cached_model_available:
                print(f"[VALIDATE] æ¨¡å‹ {cached_config.model_id} ä¸åœ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­")
                return False
            
            print(f"[VALIDATE] æ¨¡å‹ {cached_config.model_id} åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œè·³è¿‡APIæµ‹è¯•ä»¥èŠ‚çœæˆæœ¬")
            return True
            
            # æ³¨é‡Šæ‰çš„ä»£ç ï¼šå¦‚æœéœ€è¦æ›´ä¸¥æ ¼çš„éªŒè¯ï¼Œå¯ä»¥å¯ç”¨å®é™…çš„APIè°ƒç”¨æµ‹è¯•
            # ä½†è¿™ä¼šäº§ç”ŸAPIè°ƒç”¨æˆæœ¬ï¼Œå»ºè®®åªåœ¨å¿…è¦æ—¶å¯ç”¨
            """
            # 2. å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚éªŒè¯æ¨¡å‹æ˜¯å¦çœŸæ­£å¯ç”¨
            test_messages = [ChatMessage(role="user", content="æµ‹è¯•")]
            test_params = {
                "temperature": 0.1,
                "max_tokens": 10  # é™åˆ¶tokenæ•°é‡ä»¥å‡å°‘æˆæœ¬
            }
            
            # è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´è¿›è¡Œå¿«é€ŸéªŒè¯
            response = self.adapter.send_message(
                test_messages, 
                cached_config.model_id, 
                test_params
            )
            
            # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
            if response and len(str(response).strip()) > 0:
                print(f"[VALIDATE] æ¨¡å‹ {cached_config.model_id} éªŒè¯æˆåŠŸ")
                return True
            else:
                print(f"[VALIDATE] æ¨¡å‹ {cached_config.model_id} å“åº”æ— æ•ˆ")
                return False
            """
                
        except Exception as e:
            print(f"[VALIDATE] æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            return False
    
    def _save_config_cache(self, model_config: AIModelConfig):
        """ä¿å­˜AIé…ç½®åˆ°ç¼“å­˜"""
        try:
            # ç¡®ä¿streamå‚æ•°å§‹ç»ˆä¸ºTrue
            model_config.parameters['stream'] = True
            
            # æ·»åŠ ç¼“å­˜æ—¶é—´æˆ³
            cache_data = model_config.to_dict()
            cache_data['cached_at'] = time.time()  # æ·»åŠ ç¼“å­˜æ—¶é—´æˆ³
            
            with open(self.CONFIG_CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜é…ç½®ç¼“å­˜å¤±è´¥: {e}")
    
    def _interactive_setup_with_cache(self):
        """æ”¯æŒç¼“å­˜çš„äº¤äº’å¼è®¾ç½®æ¨¡å‹å’Œå‚æ•°"""
        print("\n[AI] AIæ„å›¾åˆ†æå™¨è®¾ç½®")
        print("=" * 30)
        
        # å°è¯•åŠ è½½ç¼“å­˜é…ç½®
        cached_config = self._load_cached_config()
        
        if cached_config:
            print(f"[OK] å‘ç°ä¸Šæ¬¡é…ç½®:")
            print(f"   é…ç½®: {cached_config.config_name}")
            print(f"   æ¨¡å‹: {cached_config.model_id}")
            print(f"   å‚æ•°: temperature={cached_config.parameters.get('temperature', 0.1)}, "
                  f"max_tokens={cached_config.parameters.get('max_tokens', 'None')}")
            
            use_cached = input("\næ˜¯å¦ä½¿ç”¨ä¸Šæ¬¡çš„é…ç½®? (y/n) [y]: ").strip().lower()
            
            if use_cached in ['', 'y', 'yes']:
                self.model_id = cached_config.model_id
                self.model_parameters = cached_config.parameters
                print("[OK] ä½¿ç”¨ç¼“å­˜é…ç½®")
                
                # å³ä½¿ä½¿ç”¨ç¼“å­˜é…ç½®ï¼Œä¹Ÿè¯¢é—®æ˜¯å¦è¦é‡æ–°è°ƒèŠ‚å‚æ•°
                print(f"\nå½“å‰æ¨¡å‹: {self.model_id}")
                config_params = input("æ˜¯å¦é‡æ–°é…ç½®æ¨¡å‹å‚æ•°? (y/n) [n]: ").strip().lower()
                
                if config_params in ['y', 'yes']:
                    # é‡æ–°é…ç½®å‚æ•°
                    self.model_parameters = self.ai_client.configure_parameters(
                        self.adapter, self.model_id
                    )
                    # ä¿å­˜æ–°é…ç½®åˆ°ç¼“å­˜
                    new_config = AIModelConfig(
                        config_name=self.config.name,
                        model_id=self.model_id,
                        parameters={**self.model_parameters, 'stream': True}  # ç¡®ä¿æµå¼è¾“å‡º
                    )
                    self._save_config_cache(new_config)
                    print("[SAVE] æ–°å‚æ•°é…ç½®å·²ä¿å­˜")
                else:
                    print("ä¿æŒå½“å‰å‚æ•°é…ç½®")
                
                return
            else:
                print("[CONFIG]  é‡æ–°é…ç½®...")
        
        # è¿›è¡Œæ–°çš„é…ç½®
        self._perform_interactive_setup()
        
        # ä¿å­˜æ–°é…ç½®åˆ°ç¼“å­˜
        new_config = AIModelConfig(
            config_name=self.config.name,
            model_id=self.model_id,
            parameters={**self.model_parameters, 'stream': True}  # ç¡®ä¿æµå¼è¾“å‡º
        )
        self._save_config_cache(new_config)
        print("[SAVE] é…ç½®å·²ä¿å­˜ï¼Œä¸‹æ¬¡å°†è‡ªåŠ¨ä½¿ç”¨")
    
    def _perform_interactive_setup(self):
        """æ‰§è¡Œäº¤äº’å¼é…ç½®è¿‡ç¨‹"""
        # é€‰æ‹©æ¨¡å‹
        self.model_id = self._get_default_model()
        if not self.model_id:
            print("[WARN]  é‡è¯•è·å–æ¨¡å‹")
            self.model_id = self._get_default_model()
            if not self.model_id:
                print("\n" + "="*60)
                print("[ERROR] AIèŠ‚ç‚¹è¿æ¥å¤±è´¥")
                print("="*60)
                print("æ— æ³•ä»è¿œç«¯è·å–AIæ¨¡å‹åˆ—è¡¨ï¼Œè¿™é€šå¸¸è¡¨ç¤ºï¼š")
                print("1. AIæœåŠ¡é…ç½®å¯èƒ½æœ‰è¯¯ï¼ˆAPIå¯†é’¥ã€ç«¯ç‚¹URLç­‰ï¼‰")
                print("2. ç½‘ç»œè¿æ¥é—®é¢˜æˆ–æœåŠ¡ä¸å¯ç”¨")
                print("3. APIé…é¢å·²ç”¨å®Œæˆ–æƒé™ä¸è¶³")
                print("\nè¯·æ£€æŸ¥æ‚¨çš„AIé…ç½®æ–‡ä»¶ (ai_config.yaml) å¹¶ç¡®ä¿ï¼š")
                print("- APIå¯†é’¥æ­£ç¡®ä¸”æœ‰æ•ˆ")
                print("- ç«¯ç‚¹URLæ­£ç¡®") 
                print("- ç½‘ç»œè¿æ¥æ­£å¸¸")
                print("="*60)
                print("\næŒ‰ä»»æ„é”®é€€å‡ºç¨‹åº...")
                try:
                    input()
                except (EOFError, KeyboardInterrupt):
                    pass
                import sys
                sys.exit(1)
        
        # è¯¢é—®æ˜¯å¦é…ç½®å‚æ•°
        print(f"\nå½“å‰æ¨¡å‹: {self.model_id}")
        config_params = input("æ˜¯å¦é…ç½®æ¨¡å‹å‚æ•°? (y/n) [n]: ").strip().lower()
        
        if config_params in ['y', 'yes']:
            # é…ç½®å‚æ•°
            self.model_parameters = self.ai_client.configure_parameters(
                self.adapter, self.model_id
            )
        else:
            print("ä½¿ç”¨é»˜è®¤å‚æ•°")
        
        print("[OK] AIåˆ†æå™¨è®¾ç½®å®Œæˆ\n")
    
    def clear_config_cache(self):
        """æ¸…é™¤é…ç½®ç¼“å­˜"""
        try:
            if os.path.exists(self.CONFIG_CACHE_FILE):
                os.remove(self.CONFIG_CACHE_FILE)
                print("[OK] é…ç½®ç¼“å­˜å·²æ¸…é™¤")
            else:
                print("â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°é…ç½®ç¼“å­˜æ–‡ä»¶")
        except Exception as e:
            print(f"[FAIL] æ¸…é™¤é…ç½®ç¼“å­˜å¤±è´¥: {e}")
    
    @classmethod
    def show_cached_config(cls):
        """æ˜¾ç¤ºå½“å‰ç¼“å­˜çš„é…ç½®"""
        if os.path.exists(cls.CONFIG_CACHE_FILE):
            try:
                with open(cls.CONFIG_CACHE_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    print(f"\n[LIST] å½“å‰ç¼“å­˜é…ç½®:")
                    print(f"   é…ç½®: {data.get('config_name', 'unknown')}")
                    print(f"   æ¨¡å‹: {data.get('model_id', 'unknown')}")
                    params = data.get('parameters', {})
                    print(f"   å‚æ•°: temperature={params.get('temperature', 'unknown')}, "
                          f"max_tokens={params.get('max_tokens', 'unknown')}")
            except Exception as e:
                print(f"[FAIL] è¯»å–ç¼“å­˜é…ç½®å¤±è´¥: {e}")
        else:
            print("â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°é…ç½®ç¼“å­˜æ–‡ä»¶")
    
    def _select_config(self):
        """é€‰æ‹©AIé…ç½®"""
        configs = self.config_manager.list_configs()
        
        if not configs:
            return None
        
        if self.config_name:
            return self.config_manager.get_config(self.config_name)
        else:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨é…ç½®
            return self.config_manager.get_config(configs[0])
    
    def _get_default_model(self):
        """ä»ç«¯ç‚¹è·å–æ¨¡å‹å¹¶è®©ç”¨æˆ·é€‰æ‹©"""
        try:
            models = self.adapter.get_available_models()
            if not models:
                print("[FAIL] ç«¯ç‚¹æœªè¿”å›å¯ç”¨æ¨¡å‹")
                return None
            
            # æŸ¥æ‰¾ gemini-2.5-pro æ¨¡å‹çš„ç´¢å¼•
            preferred_index = None
            for i, model in enumerate(models):
                if "gemini-2.5-pro" in model.id.lower():
                    preferred_index = i + 1  # æ˜¾ç¤ºçš„åºå·æ˜¯ä»1å¼€å§‹çš„
                    break
            
            print(f"\n{'='*50}")
            print(f"[FIND] ä»ç«¯ç‚¹è·å–åˆ° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹:")
            print('='*50)
            for i, model in enumerate(models, 1):
                prefix = "ğŸŒŸ " if preferred_index == i else "  "
                print(f"{prefix}{i}. {model.id}")
            print('='*50)
            
            # è®¾ç½®é»˜è®¤é€‰é¡¹æç¤º
            default_choice = f"[{preferred_index}]" if preferred_index else "[1]"
            default_index = preferred_index - 1 if preferred_index else 0
            
            while True:
                try:
                    choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-{len(models)}) {default_choice}: ").strip()
                    if not choice:
                        selected_index = default_index  # é»˜è®¤é€‰æ‹©
                    else:
                        selected_index = int(choice) - 1
                    
                    if 0 <= selected_index < len(models):
                        selected_model = models[selected_index]
                        print(f"[OK] å·²é€‰æ‹©æ¨¡å‹: {selected_model.id}")
                        return selected_model.id
                    else:
                        print(f"è¯·è¾“å…¥ 1-{len(models)} ä¹‹é—´çš„æ•°å­—")
                except (ValueError, EOFError):
                    # å¦‚æœæ˜¯æ— è¾“å…¥ç¯å¢ƒæˆ–è¾“å…¥é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤é€‰æ‹©
                    selected_model = models[default_index]
                    print(f"[OK] è‡ªåŠ¨é€‰æ‹©é»˜è®¤æ¨¡å‹: {selected_model.id}")
                    return selected_model.id
                    
        except Exception as e:
            print(f"\n[ERROR] è·å–AIæ¨¡å‹å¤±è´¥: {e}")
            print("è¿™é€šå¸¸è¡¨ç¤ºAIæœåŠ¡è¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ‚¨çš„AIé…ç½®")
            return None
    
    def analyze_intent(self, user_input: str) -> SearchCriteria:
        """
        åˆ†æç”¨æˆ·æ„å›¾ï¼Œç”Ÿæˆæœç´¢æ¡ä»¶ - ä¼˜åŒ–ç‰ˆ
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            
        Returns:
            SearchCriteria: è§£æåçš„æœç´¢æ¡ä»¶
        """
        start_time = time.time()
        self.performance_stats['total_analyses'] += 1
        
        # æ£€æŸ¥ç¼“å­˜
        if self.enable_cache and self.analysis_cache:
            cached_result = self.analysis_cache.get(user_input, self.model_id, self.model_parameters)
            if cached_result:
                self.performance_stats['cache_hits'] += 1
                return cached_result
        
        # æ„å»ºæç¤ºè¯
        prompt = self._build_analysis_prompt(user_input)
        
        # æ„å»ºæ¶ˆæ¯
        messages = [ChatMessage(role="user", content=prompt)]
        
        # è°ƒç”¨AIåˆ†æ
        try:
            response = self.adapter.send_message(
                messages, 
                self.model_id, 
                self.model_parameters
            )
            
            self.performance_stats['ai_calls'] += 1
            
            # ç›´æ¥å¤„ç†å“åº”è§£æï¼Œä¸ä¾èµ–format_responseæ–¹æ³•
            ai_response = self._extract_response_content(response)
            
            # å¦‚æœå“åº”ä¸ºç©ºï¼Œä½¿ç”¨åŸºç¡€ç­–ç•¥
            if not ai_response or ai_response.strip() == "":
                print(f"è§£æAIå“åº”å¤±è´¥: æœåŠ¡å™¨è¿”å›ç©ºå“åº”")
                print(f"AIå“åº”å†…å®¹: (ç©º)")
                return SearchCriteria(query=user_input)
            
            criteria = self._parse_ai_response_with_validation(ai_response, user_input)
            
            # ç¼“å­˜ç»“æœ
            if self.enable_cache and self.analysis_cache and not criteria.query == user_input:
                self.analysis_cache.put(user_input, self.model_id, self.model_parameters, criteria)
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            latency = time.time() - start_time
            self.performance_stats['total_latency'] += latency
            
            return criteria
            
        except Exception as e:
            self.performance_stats['errors'] += 1
            print(f"AIåˆ†æå¤±è´¥: {e}")
            # è¿”å›åŸºç¡€æœç´¢æ¡ä»¶
            return SearchCriteria(query=user_input)
    
    async def analyze_intent_async(self, user_input: str) -> SearchCriteria:
        """
        å¼‚æ­¥åˆ†æç”¨æˆ·æ„å›¾
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            
        Returns:
            SearchCriteria: è§£æåçš„æœç´¢æ¡ä»¶
        """
        if not self.enable_async or not self.thread_pool:
            # å¦‚æœæœªå¯ç”¨å¼‚æ­¥ï¼Œç›´æ¥è°ƒç”¨åŒæ­¥æ–¹æ³•
            return self.analyze_intent(user_input)
        
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.thread_pool, self.analyze_intent, user_input)
    
    def analyze_batch_intents(self, user_inputs: List[str]) -> List[SearchCriteria]:
        """
        æ‰¹é‡åˆ†æç”¨æˆ·æ„å›¾
        
        Args:
            user_inputs: ç”¨æˆ·è¾“å…¥æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            List[SearchCriteria]: è§£æåçš„æœç´¢æ¡ä»¶åˆ—è¡¨
        """
        if not self.enable_async or not self.thread_pool:
            # åŒæ­¥æ‰¹é‡å¤„ç†
            return [self.analyze_intent(input_text) for input_text in user_inputs]
        
        # å¼‚æ­¥æ‰¹é‡å¤„ç†
        futures = []
        for input_text in user_inputs:
            future = self.thread_pool.submit(self.analyze_intent, input_text)
            futures.append(future)
        
        results = []
        for future in futures:
            try:
                result = future.result(timeout=60)  # 60ç§’è¶…æ—¶
                results.append(result)
            except Exception as e:
                print(f"æ‰¹é‡åˆ†æå¤±è´¥: {e}")
                # è¿”å›åŸºç¡€æœç´¢æ¡ä»¶
                results.append(SearchCriteria(query=input_text))
        
        return results
    
    def _build_analysis_prompt(self, user_input: str) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½æç¤ºè¯
        try:
            prompt_template = self.prompts_manager.get_intent_analysis_prompt(user_input)
            if prompt_template and len(prompt_template.strip()) > 100:  # ç¡®ä¿ä¸æ˜¯ç©ºçš„æˆ–å¤ªçŸ­çš„æ¨¡æ¿
                return prompt_template
        except Exception as e:
            print(f"[WARN]  ä½¿ç”¨é…ç½®æ–‡ä»¶æç¤ºè¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯: {e}")
        
        # å›é€€åˆ°é»˜è®¤æç¤ºè¯
        return self._build_default_analysis_prompt(user_input)
    
    def _build_default_analysis_prompt(self, user_input: str) -> str:
        """æ„å»ºé»˜è®¤åˆ†ææç¤ºè¯ï¼ˆå…¼å®¹æ€§ä¿è¯ï¼‰"""
        from datetime import datetime
        current_date = datetime.now()
        current_year = current_date.year
        current_month = current_date.month
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦æ–‡çŒ®æ£€ç´¢ä¸“å®¶ï¼Œéœ€è¦åˆ†æç”¨æˆ·çš„æ£€ç´¢éœ€æ±‚å¹¶ç”Ÿæˆç›¸åº”çš„PubMedæ£€ç´¢è¯å’Œç­›é€‰æ¡ä»¶ã€‚

å½“å‰æ—¥æœŸ: {current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} (ç¬¬{current_year}å¹´)
ç”¨æˆ·è¾“å…¥: "{user_input}"

è¯·åˆ†æç”¨æˆ·çš„æ„å›¾å¹¶ä»¥JSONæ ¼å¼è¾“å‡ºç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

1. **query**: PubMedæ£€ç´¢è¯ï¼ˆä½¿ç”¨å¸ƒå°”æ“ä½œç¬¦ANDã€ORã€NOTï¼Œä½¿ç”¨MeSHè¯æ±‡ï¼‰
2. **year_start**: èµ·å§‹å¹´ä»½ï¼ˆæ•´æ•°ï¼Œå¦‚æœç”¨æˆ·æåˆ°äº†å¹´ä»½é™åˆ¶ï¼‰
3. **year_end**: ç»“æŸå¹´ä»½ï¼ˆæ•´æ•°ï¼Œå¦‚æœç”¨æˆ·æåˆ°äº†å¹´ä»½é™åˆ¶ï¼‰  
4. **min_if**: æœ€å°å½±å“å› å­ï¼ˆæµ®ç‚¹æ•°ï¼Œå¦‚æœç”¨æˆ·æåˆ°å½±å“å› å­è¦æ±‚ï¼‰
5. **max_if**: æœ€å¤§å½±å“å› å­ï¼ˆæµ®ç‚¹æ•°ï¼Œå¦‚æœç”¨æˆ·æåˆ°å½±å“å› å­è¦æ±‚ï¼‰
6. **cas_zones**: ä¸­ç§‘é™¢åˆ†åŒºé™åˆ¶ï¼ˆæ•´æ•°åˆ—è¡¨ï¼Œ1-4åˆ†åŒºï¼Œå¦‚[1,2]è¡¨ç¤º1åŒºå’Œ2åŒºï¼‰
7. **jcr_quartiles**: JCRåˆ†åŒºé™åˆ¶ï¼ˆå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œå¦‚["Q1","Q2"]ï¼‰
8. **keywords**: å…³é”®è¯è¿‡æ»¤åˆ—è¡¨ï¼ˆä»ç”¨æˆ·è¾“å…¥ä¸­æå–çš„é‡è¦å…³é”®è¯ï¼‰

åˆ†æè§„åˆ™ï¼š
- è¯†åˆ«ç–¾ç—…åç§°ã€æ²»ç–—æ–¹æ³•ã€è¯ç‰©åç§°ç­‰åŒ»å­¦æ¦‚å¿µ
- å°†ä¸­æ–‡åŒ»å­¦æœ¯è¯­è½¬æ¢ä¸ºè‹±æ–‡å’ŒMeSHæœ¯è¯­
- è‡ªåŠ¨è¡¥å……ç›¸å…³çš„åŒä¹‰è¯å’Œç›¸å…³æœ¯è¯­
- **é‡è¦ï¼šåŸºäºå½“å‰æ—¥æœŸ({current_year}å¹´{current_month}æœˆ)ç²¾ç¡®è®¡ç®—å¹´ä»½é™åˆ¶**
  - "è¿‘1å¹´"ï¼š{current_year-1}-{current_year}å¹´
  - "è¿‘å¹´æ¥"æˆ–"æœ€è¿‘"ï¼š{current_year-2}-{current_year}å¹´
  - "è¿‘3å¹´"ï¼š{current_year-2}-{current_year}å¹´
  - "è¿‘5å¹´"ï¼š{current_year-4}-{current_year}å¹´
  - "è¿‘10å¹´"ï¼š{current_year-9}-{current_year}å¹´
  - "æœ€è¿‘å‡ å¹´"ï¼š{current_year-3}-{current_year}å¹´
  - "è¿‡å»5å¹´"ï¼š{current_year-4}-{current_year}å¹´
  - "2020å¹´ä»¥æ¥"ï¼š2020-{current_year}å¹´
  - "ç–«æƒ…æœŸé—´"æˆ–"COVIDæœŸé—´"ï¼š2020-{current_year}å¹´
- å½±å“å› å­ï¼šé«˜å½±å“å› å­=5.0ä»¥ä¸Šï¼Œé¡¶çº§æœŸåˆŠ=10.0ä»¥ä¸Š
- **é‡è¦åˆ†åŒºè§„åˆ™ï¼š**
  - ä»…å½“ç”¨æˆ·æ˜ç¡®æåˆ°"ä¸­ç§‘é™¢åˆ†åŒº"æˆ–"CASåˆ†åŒº"æ—¶ï¼Œæ‰è¾“å‡ºcas_zones
  - ä»…å½“ç”¨æˆ·æ˜ç¡®æåˆ°"JCRåˆ†åŒº"æˆ–"JCR quartile"æ—¶ï¼Œæ‰è¾“å‡ºjcr_quartiles
  - ç”¨æˆ·ä»…è¯´"é«˜å½±å“å› å­"æˆ–"é¡¶çº§æœŸåˆŠ"æ—¶ï¼Œåªè¾“å‡ºmin_ifï¼Œä¸è¦è‡ªåŠ¨æ·»åŠ åˆ†åŒºé™åˆ¶
  - ç”¨æˆ·æ˜ç¡®è¯´"ä¸­ç§‘é™¢1åŒº"æ—¶ï¼Œåªè¾“å‡ºcas_zones: [1]ï¼Œä¸è¦æ·»åŠ jcr_quartiles
  - ç”¨æˆ·æ˜ç¡®è¯´"JCR Q1"æ—¶ï¼Œåªè¾“å‡ºjcr_quartiles: ["Q1"]ï¼Œä¸è¦æ·»åŠ cas_zones

ç¤ºä¾‹1 - ä»…å½±å“å› å­è¦æ±‚ï¼š
ç”¨æˆ·è¾“å…¥ï¼š"ç³–å°¿ç—…æ²»ç–—çš„æœ€æ–°ç ”ç©¶ï¼Œè¦æ±‚æ˜¯è¿‘5å¹´çš„é«˜å½±å“å› å­æœŸåˆŠæ–‡çŒ®"
åŸºäºå½“å‰æ—¥æœŸ({current_year}å¹´)ï¼Œ"è¿‘5å¹´"åº”è§£æä¸º{current_year-4}-{current_year}å¹´
è¾“å‡ºï¼š
```json
{{
  "query": "(diabetes mellitus[MeSH Terms] OR diabetes[Title/Abstract]) AND (treatment[MeSH Terms] OR therapy[Title/Abstract] OR therapeutic[Title/Abstract])",
  "year_start": {current_year-4},
  "year_end": {current_year},
  "min_if": 5.0,
  "keywords": ["diabetes", "treatment", "therapy", "diabetes mellitus"]
}}
```

ç¤ºä¾‹2 - ä»…ä¸­ç§‘é™¢åˆ†åŒºè¦æ±‚ï¼š
ç”¨æˆ·è¾“å…¥ï¼š"é«˜è¡€å‹æ²»ç–—ï¼Œä¸­ç§‘é™¢1åŒºå’Œ2åŒºæœŸåˆŠ"
è¾“å‡ºï¼š
```json
{{
  "query": "(hypertension[MeSH Terms] OR high blood pressure[Title/Abstract]) AND (treatment[MeSH Terms] OR therapy[Title/Abstract])",
  "cas_zones": [1, 2],
  "keywords": ["hypertension", "treatment", "high blood pressure"]
}}
```

ç¤ºä¾‹3 - ä»…JCRåˆ†åŒºè¦æ±‚ï¼š
ç”¨æˆ·è¾“å…¥ï¼š"ç™Œç—‡å…ç–«æ²»ç–—ç ”ç©¶ï¼Œè¦æ±‚JCR Q1æœŸåˆŠ"
è¾“å‡ºï¼š
```json
{{
  "query": "(cancer[MeSH Terms] OR neoplasms[MeSH Terms]) AND (immunotherapy[MeSH Terms] OR immune therapy[Title/Abstract])",
  "jcr_quartiles": ["Q1"],
  "keywords": ["cancer", "immunotherapy", "immune therapy"]
}}
```

è¯·å¯¹ä¸Šè¿°ç”¨æˆ·è¾“å…¥è¿›è¡Œåˆ†æå¹¶è¾“å‡ºJSONæ ¼å¼ç»“æœï¼Œç¡®ä¿å¹´ä»½è®¡ç®—å‡†ç¡®ï¼š
"""
        return prompt
    
    def _extract_response_content(self, response: Dict[str, Any]) -> str:
        """ç›´æ¥ä»å“åº”ä¸­æå–å†…å®¹ï¼Œä¸ä¾èµ–å¤–éƒ¨format_response"""
        if 'error' in response:
            return f"é”™è¯¯: {response['error']}"
        
        try:
            if self.adapter.config.api_type.lower() == 'openai':
                choices = response.get('choices', [])
                if choices:
                    content = choices[0].get('message', {}).get('content', '')
                    if isinstance(content, list):
                        content = ' '.join(str(item) for item in content)
                    elif not isinstance(content, str):
                        content = str(content)
                    return content.strip()
            
            elif self.adapter.config.api_type.lower() == 'gemini':
                candidates = response.get('candidates', [])
                if candidates:
                    content = candidates[0].get('content', {})
                    parts = content.get('parts', [])
                    if parts:
                        text = parts[0].get('text', '')
                        if isinstance(text, list):
                            text = ' '.join(str(item) for item in text)
                        elif not isinstance(text, str):
                            text = str(text)
                        return text.strip()
            
        except (KeyError, IndexError, TypeError) as e:
            print(f"å“åº”å†…å®¹æå–å¤±è´¥: {e}")
            return ""
        
        # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""

    def _extract_json_from_response(self, ai_response: str) -> str:
        """ä»AIå“åº”ä¸­æå–å®Œæ•´çš„JSONå­—ç¬¦ä¸² - ä¿®å¤ç‰ˆ"""
        # æ–¹æ³•1: å¯»æ‰¾```jsonæ ‡è®°çš„ä»£ç å—
        json_start = ai_response.find('```json')
        if json_start != -1:
            json_end = ai_response.find('```', json_start + 7)  # 7 = len('```json')
            if json_end != -1:
                # æå–```jsonå’Œ```ä¹‹é—´çš„å†…å®¹
                json_content = ai_response[json_start + 7:json_end].strip()
                # ç›´æ¥è¿”å›æå–çš„JSONå†…å®¹ï¼Œç„¶åæ¸…ç†å’Œä¿®å¤
                if json_content.startswith('{') and json_content.endswith('}'):
                    # å…ˆå°è¯•ä¿®å¤å¼•å·é—®é¢˜
                    cleaned_json = self._clean_and_fix_json(json_content)
                    if cleaned_json and self._is_complete_json(cleaned_json):
                        return cleaned_json

                    # å¦‚æœä¿®å¤å¤±è´¥ï¼Œå°è¯•ç›´æ¥è§£æ
                    if self._is_complete_json(json_content):
                        return json_content

        # æ–¹æ³•2: å¯»æ‰¾ä»¥"json"å¼€å¤´çš„ä»£ç å—ï¼ˆå¤„ç†ç¼ºå°‘```çš„æƒ…å†µï¼‰
        # ç›´æ¥æŸ¥æ‰¾ "json" åé¢çš„ JSON å¯¹è±¡
        json_keyword_pos = ai_response.find('json')
        if json_keyword_pos != -1:
            # ä» "json" å…³é”®å­—åæŸ¥æ‰¾ç¬¬ä¸€ä¸ª {
            brace_start = ai_response.find('{', json_keyword_pos)
            if brace_start != -1:
                json_str = self._extract_balanced_json(ai_response, brace_start)
                if json_str and self._is_complete_json(json_str):
                    return json_str

        # æ–¹æ³•3: ä½¿ç”¨æ‹¬å·å¹³è¡¡ç®—æ³•æå–å®Œæ•´JSON
        json_start = ai_response.find('```json')
        if json_start != -1:
            # æ‰¾åˆ°JSONå¼€å§‹ä½ç½®
            brace_start = ai_response.find('{', json_start)
            if brace_start != -1:
                # ä½¿ç”¨æ‹¬å·å¹³è¡¡ç®—æ³•æ‰¾åˆ°å®Œæ•´çš„JSON
                json_str = self._extract_balanced_json(ai_response, brace_start)
                if json_str and self._is_complete_json(json_str):
                    return json_str

        # æ–¹æ³•4: ç›´æ¥åœ¨å“åº”ä¸­å¯»æ‰¾JSONå¯¹è±¡
        brace_start = ai_response.find('{')
        if brace_start != -1:
            json_str = self._extract_balanced_json(ai_response, brace_start)
            if json_str and self._is_complete_json(json_str):
                return json_str

        return ""

    def _extract_balanced_json(self, text: str, start_pos: int) -> str:
        """ä½¿ç”¨æ‹¬å·å¹³è¡¡ç®—æ³•æå–å®Œæ•´çš„JSONå­—ç¬¦ä¸²"""
        if start_pos >= len(text) or text[start_pos] != '{':
            return ""

        brace_count = 0
        in_string = False
        escape_next = False

        for i in range(start_pos, len(text)):
            char = text[i]

            if escape_next:
                escape_next = False
                continue

            if char == '\\':
                escape_next = True
                continue

            if char == '"':
                in_string = not in_string
                continue

            if not in_string:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        # æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡ï¼Œç„¶åæ¸…ç†å’Œä¿®å¤
                        raw_json = text[start_pos:i+1]
                        return self._clean_and_fix_json(raw_json)

        return ""

    def _clean_and_fix_json(self, json_str: str) -> str:
        """æ¸…ç†å’Œä¿®å¤JSONå­—ç¬¦ä¸²ä¸­çš„å¼•å·é—®é¢˜"""
        if not json_str or not json_str.strip():
            return json_str

        # ä¿®å¤JSONä¸­æœªè½¬ä¹‰çš„å¼•å·
        lines = json_str.split('\n')
        fixed_lines = []

        for line in lines:
            # å¦‚æœè¡ŒåŒ…å« "query": "..." æ ¼å¼ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if '"query":' in line:
                # æ‰¾åˆ°å€¼éƒ¨åˆ†
                colon_pos = line.find('"query":')
                if colon_pos != -1:
                    prefix = line[:colon_pos + len('"query":')]
                    rest = line[colon_pos + len('"query":'):]

                    # æ‰¾åˆ°å€¼çš„å¼€å§‹å¼•å·
                    quote_start = rest.find('"')
                    if quote_start != -1:
                        before_value = rest[:quote_start + 1]  # åŒ…å«å¼€å§‹å¼•å·
                        value_and_after = rest[quote_start + 1:]  # å€¼å’Œåé¢çš„å†…å®¹

                        # æ‰¾åˆ°å€¼çš„ç»“æŸå¼•å·ï¼ˆæœ€åä¸€ä¸ªå¼•å·ï¼Œé€šå¸¸åœ¨è¡Œæœ«çš„é€—å·å‰ï¼‰
                        if value_and_after.endswith('",') or value_and_after.endswith('"'):
                            # ä»åå¾€å‰æ‰¾æœ€åä¸€ä¸ªå¼•å·
                            last_quote = value_and_after.rfind('"')
                            if last_quote != -1:
                                value_part = value_and_after[:last_quote]
                                after_value = value_and_after[last_quote:]

                                # è½¬ä¹‰å€¼ä¸­çš„å¼•å·
                                escaped_value = value_part.replace('"', '\\"')

                                # é‡æ–°ç»„è£…è¡Œ
                                fixed_line = prefix + before_value + escaped_value + after_value
                                fixed_lines.append(fixed_line)
                                continue

            # å…¶ä»–è¡Œä¿æŒä¸å˜
            fixed_lines.append(line)

        result = '\n'.join(fixed_lines)
        return result if result.strip() else json_str

    def _is_complete_json(self, json_str: str) -> bool:
        """éªŒè¯JSONå­—ç¬¦ä¸²æ˜¯å¦å®Œæ•´ä¸”æœ‰æ•ˆ"""
        if not json_str or not json_str.strip():
            return False

        try:
            json.loads(json_str)
            return True
        except json.JSONDecodeError:
            return False

    def _parse_ai_response_with_validation(self, ai_response: str, original_input: str) -> SearchCriteria:
        """è§£æAIå“åº” - å¢å¼ºéªŒè¯å’Œé”™è¯¯æ¢å¤"""
        try:
            # æå–JSONéƒ¨åˆ† - ä½¿ç”¨æ”¹è¿›çš„æå–æ–¹æ³•
            json_str = self._extract_json_from_response(ai_response)

            if not json_str:
                # å¦‚æœæå–å¤±è´¥ï¼Œè¿”å›åŸºç¡€æœç´¢æ¡ä»¶
                return SearchCriteria(query=original_input)

            # è§£æJSON
            data = json.loads(json_str)
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            validated_data = self._validate_search_criteria(data, original_input)
            
            return SearchCriteria(
                query=validated_data.get('query', original_input),
                year_start=validated_data.get('year_start'),
                year_end=validated_data.get('year_end'),
                min_if=validated_data.get('min_if'),
                max_if=validated_data.get('max_if'),
                cas_zones=validated_data.get('cas_zones', []),
                jcr_quartiles=validated_data.get('jcr_quartiles', []),
                keywords=validated_data.get('keywords', [])
            )
            
        except (json.JSONDecodeError, KeyError) as e:
            print(f"è§£æAIå“åº”å¤±è´¥: {e}")
            print(f"AIå“åº”å†…å®¹: {ai_response[:500]}...")
            
            # å°è¯•ä½¿ç”¨æ›´å®½æ¾çš„è§£æç­–ç•¥
            return self._fallback_parse_response(ai_response, original_input)
    
    def _clean_json_string(self, json_str: str) -> str:
        """æ¸…ç†JSONå­—ç¬¦ä¸²"""
        # ç§»é™¤æ³¨é‡Š
        json_str = re.sub(r'//.*?\n', '\n', json_str)
        json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
        
        # ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
        json_str = json_str.replace("'", '"')  # å•å¼•å·è½¬åŒå¼•å·
        json_str = re.sub(r',\s*}', '}', json_str)  # ç§»é™¤å°¾éšé€—å·
        json_str = re.sub(r',\s*]', ']', json_str)  # ç§»é™¤æ•°ç»„å°¾éšé€—å·
        
        return json_str.strip()
    
    def _validate_search_criteria(self, data: Dict, original_input: str) -> Dict:
        """éªŒè¯å’Œä¿®å¤æœç´¢æ¡ä»¶æ•°æ®"""
        validated = {}
        
        # éªŒè¯queryå­—æ®µ
        query = data.get('query', '').strip()
        if not query or len(query) < 3:
            # å¦‚æœqueryä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œä½¿ç”¨åŸå§‹è¾“å…¥
            validated['query'] = original_input
        else:
            validated['query'] = query
        
        # éªŒè¯å¹´ä»½èŒƒå›´
        year_start = data.get('year_start')
        year_end = data.get('year_end')
        current_year = datetime.now().year
        
        # ç¡®ä¿å¹´ä»½æ˜¯æ•´æ•°ç±»å‹
        if year_start is not None:
            try:
                year_start = int(year_start)
            except (ValueError, TypeError):
                year_start = None
        
        if year_end is not None:
            try:
                year_end = int(year_end)
            except (ValueError, TypeError):
                year_end = None
        
        # éªŒè¯å¹´ä»½é€»è¾‘
        if year_start and year_end:
            if year_start > year_end:
                # äº¤æ¢èµ·å§‹å’Œç»“æŸå¹´ä»½
                year_start, year_end = year_end, year_start
            if year_end > current_year + 1:
                year_end = current_year
        
        validated['year_start'] = year_start
        validated['year_end'] = year_end
        
        # éªŒè¯å½±å“å› å­
        min_if = data.get('min_if')
        max_if = data.get('max_if')
        
        if min_if and max_if:
            if min_if > max_if:
                min_if, max_if = max_if, min_if
            if min_if < 0:
                min_if = 0
            if max_if > 100:
                max_if = 100
        
        validated['min_if'] = min_if
        validated['max_if'] = max_if
        
        # éªŒè¯åˆ†åŒºä¿¡æ¯
        cas_zones = data.get('cas_zones', [])
        if isinstance(cas_zones, list):
            # ç¡®ä¿è½¬æ¢ä¸ºæ•´æ•°å¹¶éªŒè¯èŒƒå›´
            validated_cas_zones = []
            for zone in cas_zones:
                try:
                    zone_int = int(zone)
                    if 1 <= zone_int <= 4:
                        validated_cas_zones.append(zone_int)
                except (ValueError, TypeError):
                    continue
            validated['cas_zones'] = validated_cas_zones
        else:
            validated['cas_zones'] = []
        
        jcr_quartiles = data.get('jcr_quartiles', [])
        if isinstance(jcr_quartiles, list):
            valid_quartiles = ['Q1', 'Q2', 'Q3', 'Q4']
            validated['jcr_quartiles'] = [q for q in jcr_quartiles if q in valid_quartiles]
        else:
            validated['jcr_quartiles'] = []
        
        # éªŒè¯å…³é”®è¯
        keywords = data.get('keywords', [])
        if isinstance(keywords, list):
            validated['keywords'] = [kw.strip() for kw in keywords if kw.strip()]
        else:
            validated['keywords'] = []
        
        return validated
    
    def _fallback_parse_response(self, ai_response: str, original_input: str) -> SearchCriteria:
        """å›é€€è§£æç­–ç•¥"""
        # å°è¯•æå–queryå­—æ®µ
        query_match = re.search(r'"query"\s*:\s*"([^"]+)"', ai_response)
        if query_match:
            query = query_match.group(1)
        else:
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–æŸ¥è¯¢è¯
            query = self._extract_basic_query(ai_response)
        
        # å°è¯•æå–å¹´ä»½ä¿¡æ¯
        year_start = None
        year_end = None
        year_matches = re.findall(r'(20\d{2})', ai_response)
        if year_matches:
            years = sorted(set(int(y) for y in year_matches))
            if len(years) >= 2:
                year_start = min(years)
                year_end = max(years)
        
        return SearchCriteria(
            query=query or original_input,
            year_start=year_start,
            year_end=year_end
        )
    
    def _extract_basic_query(self, response: str) -> str:
        """ä»å“åº”ä¸­æå–åŸºç¡€æŸ¥è¯¢è¯"""
        # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘
        lines = response.split('\n')
        for line in lines:
            if 'query' in line.lower() and ':' in line:
                parts = line.split(':', 1)
                if len(parts) > 1:
                    return parts[1].strip().strip('"')
        
        return response[:100]  # è¿”å›å‰100å­—ç¬¦ä½œä¸ºæŸ¥è¯¢è¯
    
    def build_pubmed_query(self, criteria: SearchCriteria) -> str:
        """æ„å»ºå®Œæ•´çš„PubMedæŸ¥è¯¢å­—ç¬¦ä¸²"""
        query_parts = [criteria.query]
        
        # æ·»åŠ å¹´ä»½é™åˆ¶
        if criteria.year_start or criteria.year_end:
            year_filter = ""
            if criteria.year_start and criteria.year_end:
                year_filter = f"(\"{criteria.year_start}\"[Date - Publication] : \"{criteria.year_end}\"[Date - Publication])"
            elif criteria.year_start:
                year_filter = f"\"{criteria.year_start}\"[Date - Publication] : 3000[Date - Publication]"
            elif criteria.year_end:
                year_filter = f"1800[Date - Publication] : \"{criteria.year_end}\"[Date - Publication]"
            
            if year_filter:
                query_parts.append(year_filter)
        
        # ç»„åˆæ‰€æœ‰æŸ¥è¯¢éƒ¨åˆ†
        final_query = " AND ".join(f"({part})" for part in query_parts if part.strip())
        
        return final_query
    
    def print_analysis_result(self, criteria: SearchCriteria):
        """æ‰“å°åˆ†æç»“æœ"""
        print("\n=== æ„å›¾åˆ†æç»“æœ ===")
        print(f"PubMedæ£€ç´¢è¯: {criteria.query}")
        
        if criteria.year_start or criteria.year_end:
            year_range = f"{criteria.year_start or 'ä¸é™'} - {criteria.year_end or 'ä¸é™'}"
            print(f"å¹´ä»½é™åˆ¶: {year_range}")
        
        if criteria.min_if or criteria.max_if:
            if_range = f"{criteria.min_if or 'ä¸é™'} - {criteria.max_if or 'ä¸é™'}"
            print(f"å½±å“å› å­èŒƒå›´: {if_range}")
        
        # åˆ†åˆ«æ˜¾ç¤ºåˆ†åŒºä¿¡æ¯ï¼Œé¿å…æ··æ·†
        if criteria.cas_zones:
            print(f"ä¸­ç§‘é™¢åˆ†åŒºé™åˆ¶: {', '.join(map(str, criteria.cas_zones))}åŒº")
        
        if criteria.jcr_quartiles:
            print(f"JCRåˆ†åŒºé™åˆ¶: {', '.join(criteria.jcr_quartiles)}")
        
        if criteria.keywords:
            print(f"å…³é”®è¯: {', '.join(criteria.keywords)}")
        
        print(f"å®Œæ•´æ£€ç´¢è¯: {self.build_pubmed_query(criteria)}")
        print("=" * 40)
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        total_analyses = self.performance_stats['total_analyses']
        
        report = {
            'performance_stats': self.performance_stats.copy(),
            'cache_enabled': self.enable_cache,
            'async_enabled': self.enable_async,
            'cache_stats': self.analysis_cache.get_stats() if self.analysis_cache else {},
            'analysis_rate': 0,
            'cache_hit_rate': 0,
            'error_rate': 0,
            'average_latency': 0
        }
        
        if total_analyses > 0:
            report['cache_hit_rate'] = (self.performance_stats['cache_hits'] / total_analyses) * 100
            report['error_rate'] = (self.performance_stats['errors'] / total_analyses) * 100
            report['average_latency'] = self.performance_stats['total_latency'] / total_analyses
        
        return report
    
    def print_performance_report(self):
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        report = self.get_performance_report()
        stats = report['performance_stats']
        
        print("\n=== æ„å›¾åˆ†æå™¨æ€§èƒ½æŠ¥å‘Š ===")
        print(f"æ€»åˆ†ææ¬¡æ•°: {stats['total_analyses']}")
        print(f"ç¼“å­˜å‘½ä¸­: {stats['cache_hits']}")
        print(f"AIè°ƒç”¨æ¬¡æ•°: {stats['ai_calls']}")
        print(f"é”™è¯¯æ¬¡æ•°: {stats['errors']}")
        print(f"ç¼“å­˜å‘½ä¸­ç‡: {report['cache_hit_rate']:.1f}%")
        print(f"é”™è¯¯ç‡: {report['error_rate']:.1f}%")
        print(f"å¹³å‡å»¶è¿Ÿ: {report['average_latency']:.2f}ç§’")
        
        if report['cache_stats']:
            cache_stats = report['cache_stats']
            print(f"ç¼“å­˜å¤§å°: {cache_stats['cache_size']}/{cache_stats['max_cache_size']}")
            print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']*100:.1f}%")
        
        print("=" * 40)
    
    def clear_cache(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        if self.analysis_cache:
            self.analysis_cache.clear()
        
        # æ¸…é™¤é…ç½®ç¼“å­˜
        try:
            if os.path.exists(self.CONFIG_CACHE_FILE):
                os.remove(self.CONFIG_CACHE_FILE)
        except Exception as e:
            print(f"æ¸…é™¤é…ç½®ç¼“å­˜å¤±è´¥: {e}")
        
        print("æ‰€æœ‰ç¼“å­˜å·²æ¸…é™¤")
    
    def optimize_for_batch(self, expected_batch_size: int):
        """ä¸ºæ‰¹é‡å¤„ç†ä¼˜åŒ–ç¼“å­˜å¤§å°"""
        if self.analysis_cache:
            # æ ¹æ®æ‰¹é‡å¤§å°åŠ¨æ€è°ƒæ•´ç¼“å­˜
            new_cache_size = max(500, expected_batch_size * 2)
            self.analysis_cache.cache_size = new_cache_size
            print(f"ç¼“å­˜å¤§å°å·²è°ƒæ•´ä¸º: {new_cache_size}")
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œæ¸…ç†èµ„æº"""
        if hasattr(self, 'thread_pool') and self.thread_pool:
            self.thread_pool.shutdown(wait=False)


def test_intent_analyzer():
    """æµ‹è¯•æ„å›¾åˆ†æå™¨ - ä¼˜åŒ–ç‰ˆ"""
    try:
        print("åˆå§‹åŒ–æ„å›¾åˆ†æå™¨...")
        analyzer = IntentAnalyzer(interactive=False, enable_cache=True, enable_async=True)
        
        # æµ‹è¯•ç”¨ä¾‹
        test_inputs = [
            "ç³–å°¿ç—…æ²»ç–—çš„æœ€æ–°ç ”ç©¶ï¼Œè¦æ±‚æ˜¯è¿‘5å¹´çš„é«˜å½±å“å› å­æœŸåˆŠæ–‡çŒ®",
            "æ–°å† è‚ºç‚COVID-19ç–«è‹—æ•ˆæœç ”ç©¶ï¼Œ2020-2023å¹´ï¼Œä¸­ç§‘é™¢1åŒºæœŸåˆŠ",
            "æœºå™¨å­¦ä¹ åœ¨åŒ»å­¦å½±åƒè¯Šæ–­ä¸­çš„åº”ç”¨ï¼Œå½±å“å› å­å¤§äº3ï¼ŒJCR Q1-Q2æœŸåˆŠ",
            "é˜¿å°”èŒ¨æµ·é»˜ç—…æ–°è¯ç‰©æ²»ç–—è¿›å±•"
        ]
        
        print("\n=== æµ‹è¯•åŒæ­¥åˆ†æ ===")
        for i, user_input in enumerate(test_inputs, 1):
            print(f"\næµ‹è¯•ç”¨ä¾‹ {i}: {user_input}")
            criteria = analyzer.analyze_intent(user_input)
            analyzer.print_analysis_result(criteria)
        
        # æµ‹è¯•ç¼“å­˜æ•ˆæœ
        print("\n=== æµ‹è¯•ç¼“å­˜æ•ˆæœ ===")
        start_time = time.time()
        for i, user_input in enumerate(test_inputs, 1):
            print(f"\nç¼“å­˜æµ‹è¯• {i}: {user_input}")
            criteria = analyzer.analyze_intent(user_input)  # åº”è¯¥å‘½ä¸­ç¼“å­˜
        cache_time = time.time() - start_time
        print(f"ç¼“å­˜åˆ†ææ€»è€—æ—¶: {cache_time:.2f}ç§’")
        
        # æµ‹è¯•æ‰¹é‡å¤„ç†
        print("\n=== æµ‹è¯•æ‰¹é‡å¤„ç† ===")
        analyzer.optimize_for_batch(len(test_inputs))
        start_time = time.time()
        batch_results = analyzer.analyze_batch_intents(test_inputs)
        batch_time = time.time() - start_time
        print(f"æ‰¹é‡åˆ†ææ€»è€—æ—¶: {batch_time:.2f}ç§’")
        print(f"å¹³å‡æ¯ä¸ªåˆ†æ: {batch_time/len(test_inputs):.2f}ç§’")
        
        # æ˜¾ç¤ºæ€§èƒ½æŠ¥å‘Š
        analyzer.print_performance_report()
        
        # æµ‹è¯•å¼‚æ­¥å¤„ç†ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if analyzer.enable_async:
            print("\n=== æµ‹è¯•å¼‚æ­¥å¤„ç† ===")
            import asyncio
            
            async def test_async():
                start_time = time.time()
                tasks = [analyzer.analyze_intent_async(input_text) for input_text in test_inputs]
                results = await asyncio.gather(*tasks)
                async_time = time.time() - start_time
                print(f"å¼‚æ­¥åˆ†ææ€»è€—æ—¶: {async_time:.2f}ç§’")
                return results
            
            asyncio.run(test_async())
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_intent_analyzer()